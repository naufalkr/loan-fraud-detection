{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZuNikg2EsAF6",
        "2p51TyFrddTO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "HDvhrDc1PxRD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp-2ymUuKTm2"
      },
      "outputs": [],
      "source": [
        "# !pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cred = {\"username\":\"irfanhakimm\",\"key\":\"a5b6d676c709f55fdcba23308fb010ba\"}"
      ],
      "metadata": {
        "id": "p_gVxEyoPgHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir ~/.kaggle/\n",
        "# !touch ~/.kaggle/kaggle.json\n",
        "\n",
        "# api_token = cred\n",
        "# import json\n",
        "\n",
        "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "#     json.dump(api_token, file)\n",
        "\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "oGTSmr_DPhur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle competitions download -c ristek-datathon-2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4nXtlupPk-1",
        "outputId": "562ca1ca-ac32-4fb3-b528-90d093b9078b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ristek-datathon-2024.zip to /content\n",
            " 99% 141M/143M [00:01<00:00, 94.2MB/s]\n",
            "100% 143M/143M [00:01<00:00, 80.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ristek-datathon-2024.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAu3xjrsPmT5",
        "outputId": "af742ef4-7074-4d77-dd68-9d47302eb774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ristek-datathon-2024.zip\n",
            "  inflating: loan_activities.csv     \n",
            "  inflating: non_borrower_user.csv   \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing Data"
      ],
      "metadata": {
        "id": "8TWeL3qeQLpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "EQ7U5tifmqeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00668a4-46c9-4bce-e24c-3d4af397089f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from sklearn.metrics import average_precision_score, classification_report\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "Zp_KnAvmQNAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/awslabs/datawig.git"
      ],
      "metadata": {
        "id": "fMpSadxizMXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas==0.25.3 scikit-learn==0.22.1 typing==3.6.6"
      ],
      "metadata": {
        "id": "G-3DEdwx3ydR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/awslabs/datawig"
      ],
      "metadata": {
        "id": "5rAHxBfj5Lm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd datawig"
      ],
      "metadata": {
        "id": "CFRQzJ6v5Unb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install ."
      ],
      "metadata": {
        "id": "mX66THwK5YE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall numpy\n",
        "# !pip install numpy==1.23.1"
      ],
      "metadata": {
        "id": "M5VrQE5I5qGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import datawig"
      ],
      "metadata": {
        "id": "e0NgIo-j5edN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "1TRlf3C7ZGM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "NQ7eA0MRZ6sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "56e4d723-8870-40fb-f090-dca336c1b249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                origin_host  origin_port  \\\n",
              "0        CkwI1TlUCRApPfcJl              103.255.15.27        45314   \n",
              "1       CBlrcc3dvtaHzyV4zj              103.255.15.27        45060   \n",
              "2       CdpSX33u29yjDvnVzi              103.255.15.23         3440   \n",
              "3       CT23VJ1KsoKeCdWpx2             103.255.15.150        56132   \n",
              "4       C6OJU51P50bwNKvnY6             103.255.15.150        43358   \n",
              "...                    ...                        ...          ...   \n",
              "416468  COacmK2gmfhhWCrh73             103.255.15.150        53314   \n",
              "416469   CUxjxWgzdF71Y5kXc              103.255.15.23        59005   \n",
              "416470  CUU9WM3olirlj8Absj              103.255.15.23         7978   \n",
              "416471  ChiYNu2wqDXFBTzHV4  fe80::c1a7:7791:969e:3c06        55784   \n",
              "416472   CGxFa3txgPqmwWDFh              103.255.15.23         5192   \n",
              "\n",
              "             response_host  response_port  flow_duration  \\\n",
              "0            103.255.15.23          42001       0.000090   \n",
              "1            103.255.15.23          42000       0.000033   \n",
              "2             52.45.16.192            443      61.977190   \n",
              "3                  8.8.8.8             53       0.024249   \n",
              "4                  8.8.8.8             53       0.027580   \n",
              "...                    ...            ...            ...   \n",
              "416468     128.199.242.104            443            NaN   \n",
              "416469             8.8.8.8             53            NaN   \n",
              "416470       128.199.88.81            443            NaN   \n",
              "416471  2600:1901:0:38d7::             80       0.000000   \n",
              "416472     128.199.242.104            443            NaN   \n",
              "\n",
              "        forward_packets_per_sec  backward_packets_per_sec  \\\n",
              "0                  11125.474801                       NaN   \n",
              "1                  30174.848921              30174.848921   \n",
              "2                      0.322699                  0.242025   \n",
              "3                           NaN                 82.478178   \n",
              "4                           NaN                       NaN   \n",
              "...                         ...                       ...   \n",
              "416468                28.153470                 36.599511   \n",
              "416469                      NaN                 80.762198   \n",
              "416470                46.391519                       NaN   \n",
              "416471                 0.000000                  0.000000   \n",
              "416472                      NaN                       NaN   \n",
              "\n",
              "        flow_packets_per_sec  down_up_ratio  ...  forward_bulk_packets  \\\n",
              "0               22250.949602       1.000000  ...                   0.0   \n",
              "1               60349.697842       1.000000  ...                   0.0   \n",
              "2                   0.564724       0.750000  ...                   NaN   \n",
              "3                 164.956355       1.000000  ...                   NaN   \n",
              "4                  72.516256            NaN  ...                   0.0   \n",
              "...                      ...            ...  ...                   ...   \n",
              "416468                   NaN       1.300000  ...                   0.0   \n",
              "416469                   NaN       1.000000  ...                   0.0   \n",
              "416470             90.658236       0.954198  ...                   NaN   \n",
              "416471              0.000000            NaN  ...                   0.0   \n",
              "416472             12.338441       0.928571  ...                   0.0   \n",
              "\n",
              "        backward_bulk_packets  forward_bulk_rate  backward_bulk_rate  \\\n",
              "0                         0.0                NaN        0.000000e+00   \n",
              "1                         0.0                0.0        0.000000e+00   \n",
              "2                         0.0                NaN        0.000000e+00   \n",
              "3                         0.0                0.0        0.000000e+00   \n",
              "4                         0.0                NaN        0.000000e+00   \n",
              "...                       ...                ...                 ...   \n",
              "416468                    5.0                0.0        1.092664e+08   \n",
              "416469                    0.0                NaN        0.000000e+00   \n",
              "416470                  113.0                0.0        2.262403e+05   \n",
              "416471                    0.0                0.0        0.000000e+00   \n",
              "416472                    0.0                0.0        0.000000e+00   \n",
              "\n",
              "              active          idle  forward_initial_window_size  \\\n",
              "0       8.988380e+01           NaN                      29200.0   \n",
              "1       3.314018e+01           NaN                      29200.0   \n",
              "2       4.010890e+05  9.861604e+06                      29200.0   \n",
              "3       2.424884e+04           NaN                          0.0   \n",
              "4       2.758002e+04  0.000000e+00                          0.0   \n",
              "...              ...           ...                          ...   \n",
              "416468  3.551960e+05  0.000000e+00                      29200.0   \n",
              "416469  2.476406e+04  0.000000e+00                          0.0   \n",
              "416470  2.823808e+06  0.000000e+00                          NaN   \n",
              "416471  0.000000e+00  0.000000e+00                      28800.0   \n",
              "416472  2.188294e+06           NaN                          NaN   \n",
              "\n",
              "        backward_initial_window_size  forward_last_window_size         traffic  \n",
              "0                                NaN                       NaN      Background  \n",
              "1                                0.0                       NaN      Background  \n",
              "2                                NaN                      90.0      Background  \n",
              "3                                NaN                       0.0          Benign  \n",
              "4                                NaN                       0.0          Benign  \n",
              "...                              ...                       ...             ...  \n",
              "416468                       65160.0                     402.0         Probing  \n",
              "416469                           0.0                       NaN          Benign  \n",
              "416470                       28960.0                       0.0          Benign  \n",
              "416471                           0.0                       NaN          Benign  \n",
              "416472                       65160.0                       NaN  Bruteforce-XML  \n",
              "\n",
              "[416473 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32e57d81-c966-4797-b9fc-cf131d24e8d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>origin_host</th>\n",
              "      <th>origin_port</th>\n",
              "      <th>response_host</th>\n",
              "      <th>response_port</th>\n",
              "      <th>flow_duration</th>\n",
              "      <th>forward_packets_per_sec</th>\n",
              "      <th>backward_packets_per_sec</th>\n",
              "      <th>flow_packets_per_sec</th>\n",
              "      <th>down_up_ratio</th>\n",
              "      <th>...</th>\n",
              "      <th>forward_bulk_packets</th>\n",
              "      <th>backward_bulk_packets</th>\n",
              "      <th>forward_bulk_rate</th>\n",
              "      <th>backward_bulk_rate</th>\n",
              "      <th>active</th>\n",
              "      <th>idle</th>\n",
              "      <th>forward_initial_window_size</th>\n",
              "      <th>backward_initial_window_size</th>\n",
              "      <th>forward_last_window_size</th>\n",
              "      <th>traffic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CkwI1TlUCRApPfcJl</td>\n",
              "      <td>103.255.15.27</td>\n",
              "      <td>45314</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>42001</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>11125.474801</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22250.949602</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.988380e+01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBlrcc3dvtaHzyV4zj</td>\n",
              "      <td>103.255.15.27</td>\n",
              "      <td>45060</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>42000</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>30174.848921</td>\n",
              "      <td>30174.848921</td>\n",
              "      <td>60349.697842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.314018e+01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CdpSX33u29yjDvnVzi</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>3440</td>\n",
              "      <td>52.45.16.192</td>\n",
              "      <td>443</td>\n",
              "      <td>61.977190</td>\n",
              "      <td>0.322699</td>\n",
              "      <td>0.242025</td>\n",
              "      <td>0.564724</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.010890e+05</td>\n",
              "      <td>9.861604e+06</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90.0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CT23VJ1KsoKeCdWpx2</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>56132</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>0.024249</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82.478178</td>\n",
              "      <td>164.956355</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.424884e+04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C6OJU51P50bwNKvnY6</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>43358</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>0.027580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.516256</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.758002e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416468</th>\n",
              "      <td>COacmK2gmfhhWCrh73</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>53314</td>\n",
              "      <td>128.199.242.104</td>\n",
              "      <td>443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.153470</td>\n",
              "      <td>36.599511</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.092664e+08</td>\n",
              "      <td>3.551960e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>65160.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>Probing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416469</th>\n",
              "      <td>CUxjxWgzdF71Y5kXc</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>59005</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80.762198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.476406e+04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416470</th>\n",
              "      <td>CUU9WM3olirlj8Absj</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>7978</td>\n",
              "      <td>128.199.88.81</td>\n",
              "      <td>443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.391519</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90.658236</td>\n",
              "      <td>0.954198</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.262403e+05</td>\n",
              "      <td>2.823808e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28960.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416471</th>\n",
              "      <td>ChiYNu2wqDXFBTzHV4</td>\n",
              "      <td>fe80::c1a7:7791:969e:3c06</td>\n",
              "      <td>55784</td>\n",
              "      <td>2600:1901:0:38d7::</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>28800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416472</th>\n",
              "      <td>CGxFa3txgPqmwWDFh</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>5192</td>\n",
              "      <td>128.199.242.104</td>\n",
              "      <td>443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.338441</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.188294e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65160.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bruteforce-XML</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>416473 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32e57d81-c966-4797-b9fc-cf131d24e8d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32e57d81-c966-4797-b9fc-cf131d24e8d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32e57d81-c966-4797-b9fc-cf131d24e8d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52db82ad-1c3d-457f-8e5c-957bc1d4ac40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52db82ad-1c3d-457f-8e5c-957bc1d4ac40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52db82ad-1c3d-457f-8e5c-957bc1d4ac40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dc320f31-8679-4222-bc4c-3d04a0327543\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc320f31-8679-4222-bc4c-3d04a0327543 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "tcXfq1IjaSyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "e6a07827-734e-49c6-c33a-a18a1929e370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id      origin_host  origin_port    response_host  \\\n",
              "0       ClDOIi3yLGMfeRPzAc    103.255.15.23        49188    13.227.228.83   \n",
              "1       C9chsd1cHTOBBHe6Q2  202.169.224.219         5678  255.255.255.255   \n",
              "2       CUOe3U1NC5Nln7cItf   103.255.15.150        32976          8.8.8.8   \n",
              "3       C6QhB04KTRUYOY2rMk   103.255.15.150        48606  128.199.242.104   \n",
              "4       C60oC51SZNEhCXlX6c   103.255.15.150        34794  128.199.242.104   \n",
              "...                    ...              ...          ...              ...   \n",
              "138800  CWXgM92AOvagYVekD3    103.255.15.67        52975    103.255.15.23   \n",
              "138801  CMmDuU3aNTnOz4ZwSi    103.255.15.27        37214    103.255.15.23   \n",
              "138802  CQO5h64B0lXTYRlsNf   103.255.15.150        38336          8.8.8.8   \n",
              "138803  CWZZN23jtBV7sZsBLi   103.255.15.150        37267          8.8.8.8   \n",
              "138804  CAYAeJ26bhNrdT6KVc   103.255.15.150        50399          8.8.8.8   \n",
              "\n",
              "        response_port  flow_duration  forward_packets_per_sec  \\\n",
              "0                 443       1.738424                 8.628505   \n",
              "1                5678       0.000000                 0.000000   \n",
              "2                  53            NaN                80.446972   \n",
              "3                 443            NaN                      NaN   \n",
              "4                 443       0.326490                30.628816   \n",
              "...               ...            ...                      ...   \n",
              "138800            161            NaN              7307.149826   \n",
              "138801          42001       0.000144              6944.211921   \n",
              "138802             53            NaN                      NaN   \n",
              "138803             53       0.025681                77.878530   \n",
              "138804             53       0.023551                84.922130   \n",
              "\n",
              "        backward_packets_per_sec  flow_packets_per_sec  down_up_ratio  ...  \\\n",
              "0                            NaN             16.681776            NaN  ...   \n",
              "1                       0.000000              0.000000            0.0  ...   \n",
              "2                            NaN                   NaN            1.0  ...   \n",
              "3                      51.891033             88.956056            NaN  ...   \n",
              "4                            NaN             70.446278            1.3  ...   \n",
              "...                          ...                   ...            ...  ...   \n",
              "138800                       NaN                   NaN            1.0  ...   \n",
              "138801                       NaN                   NaN            1.0  ...   \n",
              "138802                 33.424744                   NaN            1.0  ...   \n",
              "138803                       NaN            155.757060            NaN  ...   \n",
              "138804                 84.922130                   NaN            NaN  ...   \n",
              "\n",
              "        backward_bulk_bytes  forward_bulk_packets  backward_bulk_packets  \\\n",
              "0                       0.0                   0.0                    NaN   \n",
              "1                       NaN                   0.0                    NaN   \n",
              "2                       0.0                   NaN                    0.0   \n",
              "3                    4585.0                   0.0                    5.0   \n",
              "4                    4585.0                   0.0                    NaN   \n",
              "...                     ...                   ...                    ...   \n",
              "138800                  0.0                   0.0                    0.0   \n",
              "138801                  NaN                   NaN                    0.0   \n",
              "138802                  0.0                   0.0                    0.0   \n",
              "138803                  0.0                   0.0                    0.0   \n",
              "138804                  0.0                   0.0                    0.0   \n",
              "\n",
              "        forward_bulk_rate  backward_bulk_rate        active  idle  \\\n",
              "0                     NaN        0.000000e+00  1.738440e+06   NaN   \n",
              "1                     NaN                 NaN  0.000000e+00   0.0   \n",
              "2                     0.0        0.000000e+00  2.486110e+04   0.0   \n",
              "3                     0.0        1.544649e+07  2.697961e+05   0.0   \n",
              "4                     NaN        5.211622e+07           NaN   NaN   \n",
              "...                   ...                 ...           ...   ...   \n",
              "138800                0.0        0.000000e+00  1.368523e+02   0.0   \n",
              "138801                0.0        0.000000e+00           NaN   0.0   \n",
              "138802                0.0        0.000000e+00  2.991796e+04   0.0   \n",
              "138803                0.0        0.000000e+00  2.568102e+04   0.0   \n",
              "138804                0.0                 NaN  2.355099e+04   0.0   \n",
              "\n",
              "        forward_initial_window_size  backward_initial_window_size  \\\n",
              "0                           29200.0                       65535.0   \n",
              "1                               0.0                           0.0   \n",
              "2                               0.0                           0.0   \n",
              "3                           29200.0                           NaN   \n",
              "4                           29200.0                           NaN   \n",
              "...                             ...                           ...   \n",
              "138800                          0.0                           0.0   \n",
              "138801                      29200.0                           0.0   \n",
              "138802                          NaN                           0.0   \n",
              "138803                          0.0                           0.0   \n",
              "138804                          0.0                           0.0   \n",
              "\n",
              "        forward_last_window_size  \n",
              "0                           80.0  \n",
              "1                            0.0  \n",
              "2                            NaN  \n",
              "3                            NaN  \n",
              "4                          402.0  \n",
              "...                          ...  \n",
              "138800                       0.0  \n",
              "138801                   29200.0  \n",
              "138802                       NaN  \n",
              "138803                       0.0  \n",
              "138804                       0.0  \n",
              "\n",
              "[138805 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1982ab69-0b7f-4089-b7cc-58723eab3e95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>origin_host</th>\n",
              "      <th>origin_port</th>\n",
              "      <th>response_host</th>\n",
              "      <th>response_port</th>\n",
              "      <th>flow_duration</th>\n",
              "      <th>forward_packets_per_sec</th>\n",
              "      <th>backward_packets_per_sec</th>\n",
              "      <th>flow_packets_per_sec</th>\n",
              "      <th>down_up_ratio</th>\n",
              "      <th>...</th>\n",
              "      <th>backward_bulk_bytes</th>\n",
              "      <th>forward_bulk_packets</th>\n",
              "      <th>backward_bulk_packets</th>\n",
              "      <th>forward_bulk_rate</th>\n",
              "      <th>backward_bulk_rate</th>\n",
              "      <th>active</th>\n",
              "      <th>idle</th>\n",
              "      <th>forward_initial_window_size</th>\n",
              "      <th>backward_initial_window_size</th>\n",
              "      <th>forward_last_window_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ClDOIi3yLGMfeRPzAc</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>49188</td>\n",
              "      <td>13.227.228.83</td>\n",
              "      <td>443</td>\n",
              "      <td>1.738424</td>\n",
              "      <td>8.628505</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.681776</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.738440e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>65535.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C9chsd1cHTOBBHe6Q2</td>\n",
              "      <td>202.169.224.219</td>\n",
              "      <td>5678</td>\n",
              "      <td>255.255.255.255</td>\n",
              "      <td>5678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUOe3U1NC5Nln7cItf</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>32976</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80.446972</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.486110e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C6QhB04KTRUYOY2rMk</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>48606</td>\n",
              "      <td>128.199.242.104</td>\n",
              "      <td>443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.891033</td>\n",
              "      <td>88.956056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.544649e+07</td>\n",
              "      <td>2.697961e+05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C60oC51SZNEhCXlX6c</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>34794</td>\n",
              "      <td>128.199.242.104</td>\n",
              "      <td>443</td>\n",
              "      <td>0.326490</td>\n",
              "      <td>30.628816</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70.446278</td>\n",
              "      <td>1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.211622e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>402.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138800</th>\n",
              "      <td>CWXgM92AOvagYVekD3</td>\n",
              "      <td>103.255.15.67</td>\n",
              "      <td>52975</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>161</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7307.149826</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.368523e+02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138801</th>\n",
              "      <td>CMmDuU3aNTnOz4ZwSi</td>\n",
              "      <td>103.255.15.27</td>\n",
              "      <td>37214</td>\n",
              "      <td>103.255.15.23</td>\n",
              "      <td>42001</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>6944.211921</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138802</th>\n",
              "      <td>CQO5h64B0lXTYRlsNf</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>38336</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.424744</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.991796e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138803</th>\n",
              "      <td>CWZZN23jtBV7sZsBLi</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>37267</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>0.025681</td>\n",
              "      <td>77.878530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155.757060</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.568102e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138804</th>\n",
              "      <td>CAYAeJ26bhNrdT6KVc</td>\n",
              "      <td>103.255.15.150</td>\n",
              "      <td>50399</td>\n",
              "      <td>8.8.8.8</td>\n",
              "      <td>53</td>\n",
              "      <td>0.023551</td>\n",
              "      <td>84.922130</td>\n",
              "      <td>84.922130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.355099e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>138805 rows × 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1982ab69-0b7f-4089-b7cc-58723eab3e95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1982ab69-0b7f-4089-b7cc-58723eab3e95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1982ab69-0b7f-4089-b7cc-58723eab3e95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcd08d50-dec8-4569-a06c-15f89b600216\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcd08d50-dec8-4569-a06c-15f89b600216')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcd08d50-dec8-4569-a06c-15f89b600216 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_95c4590c-983e-4f19-8a9b-4055ee0bcbce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_95c4590c-983e-4f19-8a9b-4055ee0bcbce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "PMIfI5Uv4EwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.isna().sum())"
      ],
      "metadata": {
        "id": "JcdaUq6K7gvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508c446d-9876-4715-bb55-aab2ba1760d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                   0\n",
            "origin_host                          0\n",
            "origin_port                          0\n",
            "response_host                        0\n",
            "response_port                        0\n",
            "flow_duration                   117064\n",
            "forward_packets_per_sec         123392\n",
            "backward_packets_per_sec         92239\n",
            "flow_packets_per_sec            111750\n",
            "down_up_ratio                   123615\n",
            "flow_FIN_flags                  112049\n",
            "flow_SYN_flags                   91010\n",
            "flow_RST_flags                  105436\n",
            "forward_PSH_flags               116525\n",
            "backward_PSH_flags               63554\n",
            "flow_ACK_flags                  127531\n",
            "forward_URG_flags               104300\n",
            "backward_URG_flags               94548\n",
            "flow_CWR_flags                  139659\n",
            "flow_ECE_flags                   77302\n",
            "forward_pkts_payload            136281\n",
            "backward_pkts_payload           139662\n",
            "flow_pkts_payload                83341\n",
            "forward_iat                      69025\n",
            "backward_iat                    110264\n",
            "flow_iat                         98571\n",
            "payload_bytes_per_sec            93088\n",
            "forward_subflow_packets         116018\n",
            "backward_subflow_packets         88955\n",
            "forward_subflow_bytes            79998\n",
            "backward_subflow_bytes          119050\n",
            "forward_bulk_bytes              127097\n",
            "backward_bulk_bytes             125537\n",
            "forward_bulk_packets            149198\n",
            "backward_bulk_packets            52281\n",
            "forward_bulk_rate               138464\n",
            "backward_bulk_rate              121777\n",
            "active                           74264\n",
            "idle                             97757\n",
            "forward_initial_window_size      98630\n",
            "backward_initial_window_size    107751\n",
            "forward_last_window_size        112537\n",
            "traffic                              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqDaGgKJnsKx",
        "outputId": "e332f529-dfb9-4dc0-f113-7be32f0a676b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                  0\n",
            "origin_host                         0\n",
            "origin_port                         0\n",
            "response_host                       0\n",
            "response_port                       0\n",
            "flow_duration                   52025\n",
            "forward_packets_per_sec         42489\n",
            "backward_packets_per_sec        47667\n",
            "flow_packets_per_sec            48340\n",
            "down_up_ratio                   40014\n",
            "flow_FIN_flags                  23723\n",
            "flow_SYN_flags                  29906\n",
            "flow_RST_flags                  45122\n",
            "forward_PSH_flags               46350\n",
            "backward_PSH_flags              33820\n",
            "flow_ACK_flags                  39571\n",
            "forward_URG_flags               31030\n",
            "backward_URG_flags              41778\n",
            "flow_CWR_flags                  27383\n",
            "flow_ECE_flags                  45202\n",
            "forward_pkts_payload            35802\n",
            "backward_pkts_payload           33083\n",
            "flow_pkts_payload               41562\n",
            "forward_iat                     32005\n",
            "backward_iat                    33922\n",
            "flow_iat                        41747\n",
            "payload_bytes_per_sec           30745\n",
            "forward_subflow_packets         37943\n",
            "backward_subflow_packets        43095\n",
            "forward_subflow_bytes           43913\n",
            "backward_subflow_bytes          19250\n",
            "forward_bulk_bytes              46001\n",
            "backward_bulk_bytes             42374\n",
            "forward_bulk_packets            45636\n",
            "backward_bulk_packets           39609\n",
            "forward_bulk_rate               50775\n",
            "backward_bulk_rate              41253\n",
            "active                          40023\n",
            "idle                            31473\n",
            "forward_initial_window_size     36584\n",
            "backward_initial_window_size    21141\n",
            "forward_last_window_size        39157\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojTR29YVo2MW",
        "outputId": "b3510ac9-42ed-4e6e-8117-8c78f28a0d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 416473 entries, 0 to 416472\n",
            "Data columns (total 43 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   id                            416473 non-null  object \n",
            " 1   origin_host                   416473 non-null  object \n",
            " 2   origin_port                   416473 non-null  int64  \n",
            " 3   response_host                 416473 non-null  object \n",
            " 4   response_port                 416473 non-null  int64  \n",
            " 5   flow_duration                 299409 non-null  float64\n",
            " 6   forward_packets_per_sec       293081 non-null  float64\n",
            " 7   backward_packets_per_sec      324234 non-null  float64\n",
            " 8   flow_packets_per_sec          304723 non-null  float64\n",
            " 9   down_up_ratio                 292858 non-null  float64\n",
            " 10  flow_FIN_flags                304424 non-null  float64\n",
            " 11  flow_SYN_flags                325463 non-null  float64\n",
            " 12  flow_RST_flags                311037 non-null  float64\n",
            " 13  forward_PSH_flags             299948 non-null  float64\n",
            " 14  backward_PSH_flags            352919 non-null  float64\n",
            " 15  flow_ACK_flags                288942 non-null  float64\n",
            " 16  forward_URG_flags             312173 non-null  float64\n",
            " 17  backward_URG_flags            321925 non-null  float64\n",
            " 18  flow_CWR_flags                276814 non-null  float64\n",
            " 19  flow_ECE_flags                339171 non-null  float64\n",
            " 20  forward_pkts_payload          280192 non-null  float64\n",
            " 21  backward_pkts_payload         276811 non-null  float64\n",
            " 22  flow_pkts_payload             333132 non-null  float64\n",
            " 23  forward_iat                   347448 non-null  float64\n",
            " 24  backward_iat                  306209 non-null  float64\n",
            " 25  flow_iat                      317902 non-null  float64\n",
            " 26  payload_bytes_per_sec         323385 non-null  float64\n",
            " 27  forward_subflow_packets       300455 non-null  float64\n",
            " 28  backward_subflow_packets      327518 non-null  float64\n",
            " 29  forward_subflow_bytes         336475 non-null  float64\n",
            " 30  backward_subflow_bytes        297423 non-null  float64\n",
            " 31  forward_bulk_bytes            289376 non-null  float64\n",
            " 32  backward_bulk_bytes           290936 non-null  float64\n",
            " 33  forward_bulk_packets          267275 non-null  float64\n",
            " 34  backward_bulk_packets         364192 non-null  float64\n",
            " 35  forward_bulk_rate             278009 non-null  float64\n",
            " 36  backward_bulk_rate            294696 non-null  float64\n",
            " 37  active                        342209 non-null  float64\n",
            " 38  idle                          318716 non-null  float64\n",
            " 39  forward_initial_window_size   317843 non-null  float64\n",
            " 40  backward_initial_window_size  308722 non-null  float64\n",
            " 41  forward_last_window_size      303936 non-null  float64\n",
            " 42  traffic                       416473 non-null  object \n",
            "dtypes: float64(37), int64(2), object(4)\n",
            "memory usage: 136.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pgT3ffqo4NF",
        "outputId": "7ec29467-23e7-4123-f40c-2acb49cc6ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 138805 entries, 0 to 138804\n",
            "Data columns (total 42 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   id                            138805 non-null  object \n",
            " 1   origin_host                   138805 non-null  object \n",
            " 2   origin_port                   138805 non-null  int64  \n",
            " 3   response_host                 138805 non-null  object \n",
            " 4   response_port                 138805 non-null  int64  \n",
            " 5   flow_duration                 86780 non-null   float64\n",
            " 6   forward_packets_per_sec       96316 non-null   float64\n",
            " 7   backward_packets_per_sec      91138 non-null   float64\n",
            " 8   flow_packets_per_sec          90465 non-null   float64\n",
            " 9   down_up_ratio                 98791 non-null   float64\n",
            " 10  flow_FIN_flags                115082 non-null  float64\n",
            " 11  flow_SYN_flags                108899 non-null  float64\n",
            " 12  flow_RST_flags                93683 non-null   float64\n",
            " 13  forward_PSH_flags             92455 non-null   float64\n",
            " 14  backward_PSH_flags            104985 non-null  float64\n",
            " 15  flow_ACK_flags                99234 non-null   float64\n",
            " 16  forward_URG_flags             107775 non-null  float64\n",
            " 17  backward_URG_flags            97027 non-null   float64\n",
            " 18  flow_CWR_flags                111422 non-null  float64\n",
            " 19  flow_ECE_flags                93603 non-null   float64\n",
            " 20  forward_pkts_payload          103003 non-null  float64\n",
            " 21  backward_pkts_payload         105722 non-null  float64\n",
            " 22  flow_pkts_payload             97243 non-null   float64\n",
            " 23  forward_iat                   106800 non-null  float64\n",
            " 24  backward_iat                  104883 non-null  float64\n",
            " 25  flow_iat                      97058 non-null   float64\n",
            " 26  payload_bytes_per_sec         108060 non-null  float64\n",
            " 27  forward_subflow_packets       100862 non-null  float64\n",
            " 28  backward_subflow_packets      95710 non-null   float64\n",
            " 29  forward_subflow_bytes         94892 non-null   float64\n",
            " 30  backward_subflow_bytes        119555 non-null  float64\n",
            " 31  forward_bulk_bytes            92804 non-null   float64\n",
            " 32  backward_bulk_bytes           96431 non-null   float64\n",
            " 33  forward_bulk_packets          93169 non-null   float64\n",
            " 34  backward_bulk_packets         99196 non-null   float64\n",
            " 35  forward_bulk_rate             88030 non-null   float64\n",
            " 36  backward_bulk_rate            97552 non-null   float64\n",
            " 37  active                        98782 non-null   float64\n",
            " 38  idle                          107332 non-null  float64\n",
            " 39  forward_initial_window_size   102221 non-null  float64\n",
            " 40  backward_initial_window_size  117664 non-null  float64\n",
            " 41  forward_last_window_size      99648 non-null   float64\n",
            "dtypes: float64(37), int64(2), object(3)\n",
            "memory usage: 44.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = train_df.drop(['id', 'origin_host', 'response_host', 'traffic'], axis=1)\n",
        "correlation_matrix = temp.corr()\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title('Heatmap of Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rtG9XBsqobA8",
        "outputId": "3b923fbf-4639-475e-d5d7-2c1c7e0df901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Misalnya train_df sudah di-load\n",
        "# Misalnya: train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Pilih hanya kolom yang bertipe float atau integer\n",
        "numerical_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Subset dari dataframe hanya dengan kolom numerik\n",
        "numerical_data = train_df[numerical_cols]\n",
        "\n",
        "# Menggunakan KNNImputer untuk mengisi nilai yang hilang\n",
        "imputer = KNNImputer(n_neighbors=5)  # n_neighbors bisa disesuaikan\n",
        "imputed_data = imputer.fit_transform(numerical_data)\n",
        "\n",
        "# Mengubah kembali hasil imputasi menjadi DataFrame\n",
        "imputed_df = pd.DataFrame(imputed_data, columns=numerical_cols)\n",
        "\n",
        "# Menggabungkan kembali data yang telah diimputasi dengan kolom non-numerik\n",
        "train_df[numerical_cols] = imputed_df\n"
      ],
      "metadata": {
        "id": "WAF3iya326Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.impute import KNNImputer\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Prepare the data for imputation\n",
        "# columns_to_impute = ['loan_type_1']\n",
        "# impute_data = merged_test_df[columns_to_impute]\n",
        "\n",
        "# # Initialize KNN imputer\n",
        "# imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# # Fit the imputer and transform the data\n",
        "# imputed_data = imputer.fit_transform(impute_data)\n",
        "\n",
        "# # Convert the result back to a DataFrame\n",
        "# imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute)\n",
        "\n",
        "# # Replace the imputed 'loan_type_1' column in the original DataFrame\n",
        "# merged_test_df['loan_type_1'] = imputed_df['loan_type_1']\n",
        "\n",
        "# # Print the DataFrame to verify changes\n",
        "# print(merged_test_df.head())\n"
      ],
      "metadata": {
        "id": "aUl9sfYjufMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.impute import KNNImputer\n",
        "\n",
        "# # Pisahkan kolom user_id\n",
        "# user_ids = merged_train_df['user_id']\n",
        "\n",
        "# # Drop user_id sebelum menggunakan KNNImputer\n",
        "# features = merged_train_df.drop(columns=['user_id'])\n",
        "\n",
        "# # Inisialisasi KNNImputer\n",
        "# imputer = KNNImputer(n_neighbors=2)\n",
        "\n",
        "# # Mengisi nilai yang hilang\n",
        "# imputed_data = imputer.fit_transform(features)\n",
        "\n",
        "# # Membuat dataframe baru dari hasil imputasi\n",
        "# imputed_df = pd.DataFrame(imputed_data, columns=features.columns)\n",
        "\n",
        "# # Gabungkan kembali user_id dengan dataframe yang telah diimputasi\n",
        "# imputed_df['user_id'] = user_ids\n",
        "\n",
        "# # Membulatkan kolom label (karena ini adalah biner)\n",
        "# imputed_df['label'] = imputed_df['label'].round().astype(int)\n",
        "\n",
        "# # Mengubah kolom loan_type_1 dan loan_type_2 kembali menjadi boolean jika diperlukan\n",
        "# imputed_df[[ 'loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5', 'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']] = imputed_df[[ 'loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5', 'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']].astype(bool)\n",
        "# merged_train_df = imputed_df"
      ],
      "metadata": {
        "id": "1IA0Uo5EZA34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_train_df_imputed.to_csv('merged_train_df_imputed.csv', index=False)"
      ],
      "metadata": {
        "id": "zw3NsBJI-vep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.impute import KNNImputer\n",
        "# import numpy as np\n",
        "\n",
        "# # Fungsi untuk mendapatkan subset data di sekitar nilai yang hilang\n",
        "# def get_surrounding_data(df, missing_index, window=100):\n",
        "#     start_index = max(0, missing_index - window)\n",
        "#     end_index = min(len(df), missing_index + window + 1)\n",
        "#     return df.iloc[start_index:end_index]\n",
        "\n",
        "# # Proses imputasi untuk kolom 'label' di dataframe\n",
        "# def impute_label_knn(df, user_id_col='user_id', label_col='label', window=100, n_neighbors=2):\n",
        "#     # Pisahkan kolom user_i\n",
        "#     user_ids = df[user_id_col]\n",
        "\n",
        "#     # Pisahkan kolom label\n",
        "#     labels = df[label_col]\n",
        "\n",
        "#     # Drop user_id sebelum menggunakan KNNImputer\n",
        "#     # features = df.drop(columns=[user_id_col, label_col])\n",
        "\n",
        "#     # Cari indeks dari baris yang memiliki nilai hilang di kolom label\n",
        "#     missing_indices = np.where(labels.isnull())[0]\n",
        "\n",
        "#     # Inisialisasi dataframe untuk hasil imputasi\n",
        "#     imputed_labels = labels.copy()\n",
        "\n",
        "#     # Inisialisasi KNNImputer\n",
        "#     imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "\n",
        "#     # Imputasi nilai hilang dengan subset data\n",
        "#     for idx in missing_indices:\n",
        "#         surrounding_data = get_surrounding_data(df, idx, window)\n",
        "#         surrounding_labels = surrounding_data[[label_col]]\n",
        "#         surrounding_features = surrounding_data.drop(columns=[user_id_col, label_col])\n",
        "\n",
        "#         imputer.fit(surrounding_features)\n",
        "#         imputed_label = imputer.transform(surrounding_features)[0, -1]\n",
        "\n",
        "#         imputed_labels.iloc[idx] = imputed_label\n",
        "\n",
        "#     # Gabungkan kembali user_id dan label yang telah diimputasi ke dataframe asli\n",
        "#     df[label_col] = imputed_labels\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # Proses imputasi untuk merged_train_df\n",
        "# merged_train_df_imputed = impute_label_knn(merged_train_df)\n",
        "\n",
        "# # Membulatkan kolom label (karena ini adalah biner)\n",
        "# merged_train_df_imputed['label'] = merged_train_df_imputed['label'].round().astype(int)\n",
        "\n",
        "# # Mengubah kolom loan_type_1 hingga loan_type_11 kembali menjadi boolean jika diperlukan\n",
        "# # loan_type_columns = [f'loan_type_{i}' for i in range(1, 12)]\n",
        "# # merged_train_df_imputed[loan_type_columns] = merged_train_df_imputed[loan_type_columns].astype(bool)\n",
        "\n",
        "# # Proses imputasi untuk merged_test_df\n",
        "# # merged_test_df_imputed = impute_label_knn(merged_test_df)\n",
        "\n",
        "# # Mengubah kolom loan_type_1 hingga loan_type_11 kembali menjadi boolean jika diperlukan\n",
        "# # merged_test_df_imputed[loan_type_columns] = merged_test_df_imputed[loan_type_columns].astype(bool)\n"
      ],
      "metadata": {
        "id": "U4SYe_t7Orc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Train\n",
        "# # merged_train_df['loan_type'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['label'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['label'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['ts'].fillna(merged_train_df['ts'].mean(), inplace=True)\n",
        "# merged_train_df = merged_train_df.drop(['reference_contact'],axis=1)\n",
        "# # merged_train_df['loan_type_1'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_2'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_3'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_4'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_5'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_6'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_7'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_8'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_9'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_10'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_11'].fillna(method='ffill', inplace=True)\n",
        "# # merged_train_df['loan_type_1'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_2'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_3'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_4'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_5'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_6'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_7'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_8'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_9'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_10'].fillna(method='bfill', inplace=True)\n",
        "# # merged_train_df['loan_type_11'].fillna(method='bfill', inplace=True)\n",
        "\n",
        "# #Test\n",
        "# # merged_test_df['loan_type'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['ts'].fillna(merged_test_df['ts'].mean(), inplace=True)\n",
        "# merged_test_df = merged_test_df.drop(['reference_contact'],axis=1)\n",
        "# # merged_test_df['loan_type_1'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_2'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_3'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_4'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_5'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_6'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_7'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_8'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_9'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_10'].fillna(method='bfill', inplace=True)\n",
        "# # merged_test_df['loan_type_11'].fillna(method='bfill', inplace=True)\n"
      ],
      "metadata": {
        "id": "51ptqTvzC6zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAdEw8OlE6_q",
        "outputId": "71f325bb-f429-4693-dee2-ac8e817604d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 416473 entries, 0 to 416472\n",
            "Data columns (total 43 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   id                            416473 non-null  object \n",
            " 1   origin_host                   416473 non-null  object \n",
            " 2   origin_port                   416473 non-null  int64  \n",
            " 3   response_host                 416473 non-null  object \n",
            " 4   response_port                 416473 non-null  int64  \n",
            " 5   flow_duration                 299409 non-null  float64\n",
            " 6   forward_packets_per_sec       293081 non-null  float64\n",
            " 7   backward_packets_per_sec      324234 non-null  float64\n",
            " 8   flow_packets_per_sec          304723 non-null  float64\n",
            " 9   down_up_ratio                 292858 non-null  float64\n",
            " 10  flow_FIN_flags                304424 non-null  float64\n",
            " 11  flow_SYN_flags                325463 non-null  float64\n",
            " 12  flow_RST_flags                311037 non-null  float64\n",
            " 13  forward_PSH_flags             299948 non-null  float64\n",
            " 14  backward_PSH_flags            352919 non-null  float64\n",
            " 15  flow_ACK_flags                288942 non-null  float64\n",
            " 16  forward_URG_flags             312173 non-null  float64\n",
            " 17  backward_URG_flags            321925 non-null  float64\n",
            " 18  flow_CWR_flags                276814 non-null  float64\n",
            " 19  flow_ECE_flags                339171 non-null  float64\n",
            " 20  forward_pkts_payload          280192 non-null  float64\n",
            " 21  backward_pkts_payload         276811 non-null  float64\n",
            " 22  flow_pkts_payload             333132 non-null  float64\n",
            " 23  forward_iat                   347448 non-null  float64\n",
            " 24  backward_iat                  306209 non-null  float64\n",
            " 25  flow_iat                      317902 non-null  float64\n",
            " 26  payload_bytes_per_sec         323385 non-null  float64\n",
            " 27  forward_subflow_packets       300455 non-null  float64\n",
            " 28  backward_subflow_packets      327518 non-null  float64\n",
            " 29  forward_subflow_bytes         336475 non-null  float64\n",
            " 30  backward_subflow_bytes        297423 non-null  float64\n",
            " 31  forward_bulk_bytes            289376 non-null  float64\n",
            " 32  backward_bulk_bytes           290936 non-null  float64\n",
            " 33  forward_bulk_packets          267275 non-null  float64\n",
            " 34  backward_bulk_packets         364192 non-null  float64\n",
            " 35  forward_bulk_rate             278009 non-null  float64\n",
            " 36  backward_bulk_rate            294696 non-null  float64\n",
            " 37  active                        342209 non-null  float64\n",
            " 38  idle                          318716 non-null  float64\n",
            " 39  forward_initial_window_size   317843 non-null  float64\n",
            " 40  backward_initial_window_size  308722 non-null  float64\n",
            " 41  forward_last_window_size      303936 non-null  float64\n",
            " 42  traffic                       416473 non-null  object \n",
            "dtypes: float64(37), int64(2), object(4)\n",
            "memory usage: 136.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnTDCKx8n5GM",
        "outputId": "db3a173f-baf3-48e0-dd0b-fc5756f02f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 138805 entries, 0 to 138804\n",
            "Data columns (total 42 columns):\n",
            " #   Column                        Non-Null Count   Dtype  \n",
            "---  ------                        --------------   -----  \n",
            " 0   id                            138805 non-null  object \n",
            " 1   origin_host                   138805 non-null  object \n",
            " 2   origin_port                   138805 non-null  int64  \n",
            " 3   response_host                 138805 non-null  object \n",
            " 4   response_port                 138805 non-null  int64  \n",
            " 5   flow_duration                 86780 non-null   float64\n",
            " 6   forward_packets_per_sec       96316 non-null   float64\n",
            " 7   backward_packets_per_sec      91138 non-null   float64\n",
            " 8   flow_packets_per_sec          90465 non-null   float64\n",
            " 9   down_up_ratio                 98791 non-null   float64\n",
            " 10  flow_FIN_flags                115082 non-null  float64\n",
            " 11  flow_SYN_flags                108899 non-null  float64\n",
            " 12  flow_RST_flags                93683 non-null   float64\n",
            " 13  forward_PSH_flags             92455 non-null   float64\n",
            " 14  backward_PSH_flags            104985 non-null  float64\n",
            " 15  flow_ACK_flags                99234 non-null   float64\n",
            " 16  forward_URG_flags             107775 non-null  float64\n",
            " 17  backward_URG_flags            97027 non-null   float64\n",
            " 18  flow_CWR_flags                111422 non-null  float64\n",
            " 19  flow_ECE_flags                93603 non-null   float64\n",
            " 20  forward_pkts_payload          103003 non-null  float64\n",
            " 21  backward_pkts_payload         105722 non-null  float64\n",
            " 22  flow_pkts_payload             97243 non-null   float64\n",
            " 23  forward_iat                   106800 non-null  float64\n",
            " 24  backward_iat                  104883 non-null  float64\n",
            " 25  flow_iat                      97058 non-null   float64\n",
            " 26  payload_bytes_per_sec         108060 non-null  float64\n",
            " 27  forward_subflow_packets       100862 non-null  float64\n",
            " 28  backward_subflow_packets      95710 non-null   float64\n",
            " 29  forward_subflow_bytes         94892 non-null   float64\n",
            " 30  backward_subflow_bytes        119555 non-null  float64\n",
            " 31  forward_bulk_bytes            92804 non-null   float64\n",
            " 32  backward_bulk_bytes           96431 non-null   float64\n",
            " 33  forward_bulk_packets          93169 non-null   float64\n",
            " 34  backward_bulk_packets         99196 non-null   float64\n",
            " 35  forward_bulk_rate             88030 non-null   float64\n",
            " 36  backward_bulk_rate            97552 non-null   float64\n",
            " 37  active                        98782 non-null   float64\n",
            " 38  idle                          107332 non-null  float64\n",
            " 39  forward_initial_window_size   102221 non-null  float64\n",
            " 40  backward_initial_window_size  117664 non-null  float64\n",
            " 41  forward_last_window_size      99648 non-null   float64\n",
            "dtypes: float64(37), int64(2), object(3)\n",
            "memory usage: 44.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mengisi nilai yang hilang di merged_train_df dengan modus\n",
        "# for col in ['loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5',\n",
        "#             'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']:\n",
        "#     mode_value = merged_train_df[col].mode()[0]\n",
        "#     merged_train_df[col].fillna(mode_value, inplace=True)\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_test_df dengan modus\n",
        "# for col in ['loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5',\n",
        "#             'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']:\n",
        "#     mode_value = merged_test_df[col].mode()[0]\n",
        "#     merged_test_df[col].fillna(mode_value, inplace=True)"
      ],
      "metadata": {
        "id": "cnM_yGTBCj6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.impute import SimpleImputer\n",
        "\n",
        "# # Inisialisasi SimpleImputer dengan strategi modus\n",
        "# imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# # List kolom yang perlu diimputasi\n",
        "# columns_to_impute = ['loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5',\n",
        "#                      'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_train_df\n",
        "# merged_train_df[columns_to_impute] = imputer.fit_transform(merged_train_df[columns_to_impute])\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_test_df\n",
        "# merged_test_df[columns_to_impute] = imputer.transform(merged_test_df[columns_to_impute])\n"
      ],
      "metadata": {
        "id": "WSKjHN3jHgdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import datawig\n",
        "# import pandas as pd\n",
        "\n",
        "# # Select columns to be imputed\n",
        "# columns_to_impute = ['label']\n",
        "\n",
        "# # Extract the relevant subset of data\n",
        "# impute_data = merged_train_df[columns_to_impute + ['user_id']]  # Include user_id if it helps in the imputation\n",
        "\n",
        "# # Initialize the SimpleImputer\n",
        "# imputer = datawig.SimpleImputer(\n",
        "#     input_columns=[col for col in impute_data.columns if col != 'label'],\n",
        "#     output_column='label'\n",
        "# )\n",
        "\n",
        "# # Fit the imputer model\n",
        "# imputer.fit(train_df=impute_data)\n",
        "\n",
        "# # Impute missing values\n",
        "# imputed_data = imputer.predict(impute_data)\n",
        "\n",
        "# # Replace the imputed column in the original DataFrame\n",
        "# merged_train_df['label'] = imputed_data['label']\n",
        "\n",
        "# # Print the DataFrame to verify changes\n",
        "# print(merged_train_df.head())\n"
      ],
      "metadata": {
        "id": "nYdNMc6dxnsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from sklearn.impute import IterativeImputer\n",
        "# import pandas as pd\n",
        "\n",
        "# # Inisialisasi IterativeImputer\n",
        "# imputer = IterativeImputer(random_state=0)\n",
        "\n",
        "# # List kolom yang perlu diimputasi\n",
        "# columns_to_impute = ['label']\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_train_df\n",
        "# merged_train_df[columns_to_impute] = imputer.fit_transform(merged_train_df[columns_to_impute])\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_test_df\n",
        "# # merged_test_df[columns_to_impute] = imputer.fit_transform(merged_test_df[columns_to_impute])\n",
        "\n",
        "# # Cetak hasil imputasi\n",
        "# print(\"Hasil imputasi untuk merged_train_df:\")\n",
        "# print(merged_train_df)\n",
        "# print(\"\\nHasil imputasi untuk merged_test_df:\")\n",
        "# print(merged_test_df)"
      ],
      "metadata": {
        "id": "hy9ynI86GvcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from sklearn.impute import IterativeImputer\n",
        "# import pandas as pd\n",
        "\n",
        "# # Inisialisasi IterativeImputer\n",
        "# imputer = IterativeImputer(random_state=0)\n",
        "\n",
        "# # List kolom yang perlu diimputasi\n",
        "# columns_to_impute = ['reference_contact', 'ts']\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_train_df\n",
        "# # merged_train_df[columns_to_impute] = imputer.fit_transform(merged_train_df[columns_to_impute])\n",
        "\n",
        "# # Mengisi nilai yang hilang di merged_test_df\n",
        "# merged_test_df[columns_to_impute] = imputer.fit_transform(merged_test_df[columns_to_impute])\n",
        "\n",
        "# # Cetak hasil imputasi\n",
        "# print(\"Hasil imputasi untuk merged_train_df:\")\n",
        "# print(merged_train_df)\n",
        "# print(\"\\nHasil imputasi untuk merged_test_df:\")\n",
        "# print(merged_test_df)"
      ],
      "metadata": {
        "id": "6RYY2dOqFrAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List kolom yang perlu diubah nilai \"FALSE\" dan \"TRUE\"\n",
        "columns_to_convert = ['loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5',\n",
        "                     'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9', 'loan_type_10', 'loan_type_11']\n",
        "\n",
        "# Definisikan mapping untuk mengubah nilai \"FALSE\" dan \"TRUE\" menjadi 0 dan 1\n",
        "boolean_mapping = {\"FALSE\": 0, \"TRUE\": 1}\n",
        "\n",
        "# Loop melalui kolom-kolom yang perlu diubah\n",
        "for col in columns_to_convert:\n",
        "    # Mengubah nilai di merged_train_df\n",
        "    merged_train_df[col] = merged_train_df[col].map(boolean_mapping).fillna(merged_train_df[col])\n",
        "\n",
        "    # Mengubah nilai di merged_test_df\n",
        "    merged_test_df[col] = merged_test_df[col].map(boolean_mapping).fillna(merged_test_df[col])\n"
      ],
      "metadata": {
        "id": "0C7w-TxOOYhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_train_df.isna().sum())\n",
        "print(merged_test_df.isna().sum())"
      ],
      "metadata": {
        "id": "6gjIwIeqETpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53803eb-d445-4aa9-e4f4-8ddc9e924bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_id               0\n",
            "pc0                   0\n",
            "pc1                   0\n",
            "pc2                   0\n",
            "pc3                   0\n",
            "pc4                   0\n",
            "pc5                   0\n",
            "pc6                   0\n",
            "pc7                   0\n",
            "pc8                   0\n",
            "pc9                   0\n",
            "pc10                  0\n",
            "pc11                  0\n",
            "pc12                  0\n",
            "pc13                  0\n",
            "pc14                  0\n",
            "pc15                  0\n",
            "pc16                  0\n",
            "label                 0\n",
            "ts              1431594\n",
            "loan_type_1           0\n",
            "loan_type_2           0\n",
            "loan_type_3           0\n",
            "loan_type_4           0\n",
            "loan_type_5           0\n",
            "loan_type_6           0\n",
            "loan_type_7           0\n",
            "loan_type_8           0\n",
            "loan_type_9           0\n",
            "loan_type_10          0\n",
            "loan_type_11          0\n",
            "dtype: int64\n",
            "user_id             0\n",
            "pc0                 0\n",
            "pc1                 0\n",
            "pc2                 0\n",
            "pc3                 0\n",
            "pc4                 0\n",
            "pc5                 0\n",
            "pc6                 0\n",
            "pc7                 0\n",
            "pc8                 0\n",
            "pc9                 0\n",
            "pc10                0\n",
            "pc11                0\n",
            "pc12                0\n",
            "pc13                0\n",
            "pc14                0\n",
            "pc15                0\n",
            "pc16                0\n",
            "ts              78294\n",
            "loan_type_1         0\n",
            "loan_type_2         0\n",
            "loan_type_3         0\n",
            "loan_type_4         0\n",
            "loan_type_5         0\n",
            "loan_type_6         0\n",
            "loan_type_7         0\n",
            "loan_type_8         0\n",
            "loan_type_9         0\n",
            "loan_type_10        0\n",
            "loan_type_11        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = train_df.drop(['user_id'], axis=1)\n",
        "correlation_matrix = temp.corr()\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title('Heatmap of Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "29jGZSEKRNZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_context('notebook', font_scale= 1.2)\n",
        "fig, ax = plt.subplots(3, 1, figsize = (20, 13))\n",
        "\n",
        "plt.suptitle('Distribution of various features based on target variable', fontsize = 20)\n",
        "\n",
        "ax1 = sns.histplot(x ='ts', data= merged_train_df, hue= 'label', kde= True, ax= ax[0], palette='winter')\n",
        "ax1.set(xlabel = 'ts')\n",
        "\n",
        "ax2 = sns.histplot(x ='pc15', data= merged_train_df, hue= 'label', kde= True, ax= ax[1], palette='plasma')\n",
        "ax2.set(xlabel = 'pc15')\n",
        "\n",
        "ax3 = sns.histplot(x ='pc16', data= merged_train_df, hue= 'label', kde= True, ax= ax[2], palette='winter')\n",
        "ax3.set(xlabel = 'pc16')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IZhb25zBVmAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_df[merged_train_df['label'] == 1]"
      ],
      "metadata": {
        "id": "dBGJ7enqk6TC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "58381385-9428-4f9c-f1ce-36b13239d457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        user_id  pc0  pc1    pc2    pc3       pc4  pc5    pc6    pc7    pc8  \\\n",
              "252        1080  1.0  2.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "305        1307  1.0  1.0  0.295  0.285  0.966102  0.5  0.346  0.057  0.344   \n",
              "481        2001  0.0  1.0  0.490  0.455  0.928571  0.4  1.046  0.126  1.036   \n",
              "482        2002  1.0  1.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "515        2129  1.0  5.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "...         ...  ...  ...    ...    ...       ...  ...    ...    ...    ...   \n",
              "857668  3699581  1.0  2.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "857678  3699636  1.0  5.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "857691  3699702  1.0  6.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "857775  3700044  1.0  6.0  0.590  0.575  0.974576  0.5  1.668  0.087  1.665   \n",
              "857789  3700118  1.0  8.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "\n",
              "        ...  loan_type_2  loan_type_3  loan_type_4  loan_type_5  loan_type_6  \\\n",
              "252     ...        False        False        False         True        False   \n",
              "305     ...        False        False        False         True        False   \n",
              "481     ...        False        False         True         True        False   \n",
              "482     ...        False        False        False         True        False   \n",
              "515     ...        False        False        False         True        False   \n",
              "...     ...          ...          ...          ...          ...          ...   \n",
              "857668  ...        False        False        False         True        False   \n",
              "857678  ...        False        False        False         True        False   \n",
              "857691  ...        False        False         True        False        False   \n",
              "857775  ...        False        False         True        False        False   \n",
              "857789  ...        False        False        False         True        False   \n",
              "\n",
              "        loan_type_7  loan_type_8  loan_type_9  loan_type_10  loan_type_11  \n",
              "252           False        False        False         False         False  \n",
              "305           False        False        False         False         False  \n",
              "481           False        False        False         False         False  \n",
              "482           False        False        False         False         False  \n",
              "515           False        False        False         False         False  \n",
              "...             ...          ...          ...           ...           ...  \n",
              "857668        False        False        False         False         False  \n",
              "857678        False        False        False         False         False  \n",
              "857691        False        False        False         False         False  \n",
              "857775        False        False        False          True         False  \n",
              "857789        False        False        False         False         False  \n",
              "\n",
              "[10857 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb60c0e3-28e2-411a-b4ed-0de7ec0e2882\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pc0</th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>...</th>\n",
              "      <th>loan_type_2</th>\n",
              "      <th>loan_type_3</th>\n",
              "      <th>loan_type_4</th>\n",
              "      <th>loan_type_5</th>\n",
              "      <th>loan_type_6</th>\n",
              "      <th>loan_type_7</th>\n",
              "      <th>loan_type_8</th>\n",
              "      <th>loan_type_9</th>\n",
              "      <th>loan_type_10</th>\n",
              "      <th>loan_type_11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>1080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1307</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.295</td>\n",
              "      <td>0.285</td>\n",
              "      <td>0.966102</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.344</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>2001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.046</td>\n",
              "      <td>0.126</td>\n",
              "      <td>1.036</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>2002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>2129</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857668</th>\n",
              "      <td>3699581</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857678</th>\n",
              "      <td>3699636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857691</th>\n",
              "      <td>3699702</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857775</th>\n",
              "      <td>3700044</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.974576</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.668</td>\n",
              "      <td>0.087</td>\n",
              "      <td>1.665</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857789</th>\n",
              "      <td>3700118</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10857 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb60c0e3-28e2-411a-b4ed-0de7ec0e2882')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb60c0e3-28e2-411a-b4ed-0de7ec0e2882 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb60c0e3-28e2-411a-b4ed-0de7ec0e2882');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-583a43f5-a998-4414-9270-aa6bbbdd6032\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-583a43f5-a998-4414-9270-aa6bbbdd6032')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-583a43f5-a998-4414-9270-aa6bbbdd6032 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_df"
      ],
      "metadata": {
        "id": "JYjXZ6CSA2zJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e1c0d6c2-d3c4-4992-dba0-769a8c16abff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         user_id  pc0  pc1    pc2    pc3       pc4  pc5    pc6   pc7    pc8  \\\n",
              "857899         0  1.0  5.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "857900         1  0.0  8.0  0.630  0.565  0.896825  0.6  2.298  0.21  2.284   \n",
              "857901         2 -1.0 -1.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "0              3  1.0  1.0  0.275  0.255  0.927273  0.4  0.260  0.04  0.254   \n",
              "1              5  0.0  0.0  0.430  0.365  0.848837  0.4  1.253  0.21  1.235   \n",
              "...          ...  ...  ...    ...    ...       ...  ...    ...   ...    ...   \n",
              "3332844  3700545  1.0  7.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "3332845  3700546  1.0  1.0  0.125  0.125  1.000000 -1.0  0.120 -1.00  0.120   \n",
              "3332846  3700547  1.0  0.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "857898   3700548  0.0  4.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "3332847  3700549  1.0  1.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.00 -1.000   \n",
              "\n",
              "         ...  loan_type_2  loan_type_3  loan_type_4  loan_type_5  loan_type_6  \\\n",
              "857899   ...        False        False        False         True        False   \n",
              "857900   ...         True        False        False        False        False   \n",
              "857901   ...        False        False        False         True        False   \n",
              "0        ...        False        False        False         True        False   \n",
              "1        ...        False        False        False         True        False   \n",
              "...      ...          ...          ...          ...          ...          ...   \n",
              "3332844  ...        False        False        False         True        False   \n",
              "3332845  ...        False        False         True        False        False   \n",
              "3332846  ...        False        False        False         True        False   \n",
              "857898   ...        False        False        False        False        False   \n",
              "3332847  ...        False        False        False         True        False   \n",
              "\n",
              "         loan_type_7  loan_type_8  loan_type_9  loan_type_10  loan_type_11  \n",
              "857899         False        False        False         False         False  \n",
              "857900         False        False        False         False         False  \n",
              "857901         False        False        False         False         False  \n",
              "0              False        False        False         False         False  \n",
              "1              False        False        False          True         False  \n",
              "...              ...          ...          ...           ...           ...  \n",
              "3332844        False        False        False         False         False  \n",
              "3332845        False        False        False         False         False  \n",
              "3332846        False        False        False         False         False  \n",
              "857898         False        False        False         False         False  \n",
              "3332847        False        False        False         False         False  \n",
              "\n",
              "[3332848 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f807a04-e7ae-46a9-aafc-8627c5a7b659\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pc0</th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>...</th>\n",
              "      <th>loan_type_2</th>\n",
              "      <th>loan_type_3</th>\n",
              "      <th>loan_type_4</th>\n",
              "      <th>loan_type_5</th>\n",
              "      <th>loan_type_6</th>\n",
              "      <th>loan_type_7</th>\n",
              "      <th>loan_type_8</th>\n",
              "      <th>loan_type_9</th>\n",
              "      <th>loan_type_10</th>\n",
              "      <th>loan_type_11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>857899</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857900</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.896825</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2.298</td>\n",
              "      <td>0.21</td>\n",
              "      <td>2.284</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857901</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.927273</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.254</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.253</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.235</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332844</th>\n",
              "      <td>3700545</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332845</th>\n",
              "      <td>3700546</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.120</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.120</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332846</th>\n",
              "      <td>3700547</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857898</th>\n",
              "      <td>3700548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332847</th>\n",
              "      <td>3700549</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3332848 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f807a04-e7ae-46a9-aafc-8627c5a7b659')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f807a04-e7ae-46a9-aafc-8627c5a7b659 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f807a04-e7ae-46a9-aafc-8627c5a7b659');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6804525b-31b5-4029-9dfb-e77c4ae7e3a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6804525b-31b5-4029-9dfb-e77c4ae7e3a3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6804525b-31b5-4029-9dfb-e77c4ae7e3a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9b9a1bfc-e550-4616-88a1-dc037e99e5fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9b9a1bfc-e550-4616-88a1-dc037e99e5fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_train_df"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_df[merged_train_df['label'] == 0]"
      ],
      "metadata": {
        "id": "IFmOUKeylPKv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f7eb985d-6162-4c14-f7f3-6fff7c768ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        user_id  pc0  pc1    pc2    pc3       pc4  pc5    pc6    pc7    pc8  \\\n",
              "0             3  1.0  1.0  0.275  0.255  0.927273  0.4  0.260  0.040  0.254   \n",
              "1             5  0.0  0.0  0.430  0.365  0.848837  0.4  1.253  0.210  1.235   \n",
              "2             9  1.0  3.0  1.315  0.825  0.627376  0.9  2.385  0.128  2.270   \n",
              "3            10  0.0  5.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "4            17  1.0  1.0  0.235  0.160  0.680851  0.1  0.120  0.002  0.104   \n",
              "...         ...  ...  ...    ...    ...       ...  ...    ...    ...    ...   \n",
              "857894  3700529  1.0  4.0  0.190  0.160  0.842105  0.1  0.281  0.005  0.274   \n",
              "857895  3700532  1.0  3.0  1.710  1.535  0.897661  2.1  3.750  0.687  3.712   \n",
              "857896  3700537  1.0  0.0  2.165  2.060  0.951501  2.4  2.213  0.065  2.186   \n",
              "857897  3700543  1.0  5.0  2.075  1.565  0.754217  1.9  3.292  0.342  3.188   \n",
              "857898  3700548  0.0  4.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "\n",
              "        ...  loan_type_2  loan_type_3  loan_type_4  loan_type_5  loan_type_6  \\\n",
              "0       ...        False        False        False         True        False   \n",
              "1       ...        False        False        False         True        False   \n",
              "2       ...        False        False         True         True        False   \n",
              "3       ...        False        False         True        False        False   \n",
              "4       ...        False        False         True        False        False   \n",
              "...     ...          ...          ...          ...          ...          ...   \n",
              "857894  ...        False        False         True        False        False   \n",
              "857895  ...        False        False         True         True         True   \n",
              "857896  ...        False         True        False        False        False   \n",
              "857897  ...        False        False        False        False         True   \n",
              "857898  ...        False        False        False        False        False   \n",
              "\n",
              "        loan_type_7  loan_type_8  loan_type_9  loan_type_10  loan_type_11  \n",
              "0             False        False        False         False         False  \n",
              "1             False        False        False          True         False  \n",
              "2             False        False        False         False         False  \n",
              "3             False        False        False         False         False  \n",
              "4             False        False        False         False         False  \n",
              "...             ...          ...          ...           ...           ...  \n",
              "857894        False        False        False         False         False  \n",
              "857895        False        False        False         False         False  \n",
              "857896        False        False        False         False         False  \n",
              "857897        False        False        False         False         False  \n",
              "857898        False        False        False         False         False  \n",
              "\n",
              "[847042 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57416261-6f1c-470c-970e-39c91ef85aaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pc0</th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>...</th>\n",
              "      <th>loan_type_2</th>\n",
              "      <th>loan_type_3</th>\n",
              "      <th>loan_type_4</th>\n",
              "      <th>loan_type_5</th>\n",
              "      <th>loan_type_6</th>\n",
              "      <th>loan_type_7</th>\n",
              "      <th>loan_type_8</th>\n",
              "      <th>loan_type_9</th>\n",
              "      <th>loan_type_10</th>\n",
              "      <th>loan_type_11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.927273</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.254</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.253</td>\n",
              "      <td>0.210</td>\n",
              "      <td>1.235</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.315</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.627376</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.385</td>\n",
              "      <td>0.128</td>\n",
              "      <td>2.270</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.104</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857894</th>\n",
              "      <td>3700529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.274</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857895</th>\n",
              "      <td>3700532</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.710</td>\n",
              "      <td>1.535</td>\n",
              "      <td>0.897661</td>\n",
              "      <td>2.1</td>\n",
              "      <td>3.750</td>\n",
              "      <td>0.687</td>\n",
              "      <td>3.712</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857896</th>\n",
              "      <td>3700537</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.165</td>\n",
              "      <td>2.060</td>\n",
              "      <td>0.951501</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.065</td>\n",
              "      <td>2.186</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857897</th>\n",
              "      <td>3700543</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.075</td>\n",
              "      <td>1.565</td>\n",
              "      <td>0.754217</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.292</td>\n",
              "      <td>0.342</td>\n",
              "      <td>3.188</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857898</th>\n",
              "      <td>3700548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>847042 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57416261-6f1c-470c-970e-39c91ef85aaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57416261-6f1c-470c-970e-39c91ef85aaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57416261-6f1c-470c-970e-39c91ef85aaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17b19c4e-7c15-4eab-b462-4c995acf484a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17b19c4e-7c15-4eab-b462-4c995acf484a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17b19c4e-7c15-4eab-b462-4c995acf484a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data yang memiliki nilai tidak null di kolom 'ts'\n",
        "# valid_data = merged_train_df.dropna(subset=['ts'])\n",
        "valid_data = merged_train_df\n",
        "\n",
        "# Hitung jumlah maksimum sampel yang bisa diambil dari label 1 dan 0 di data yang valid\n",
        "label_1_count = valid_data[valid_data['label'] == 1].shape[0]\n",
        "label_0_count = valid_data[valid_data['label'] == 0].shape[0]\n",
        "\n",
        "# Tentukan ukuran sampel yang seimbang (jumlah minimum antara label 1 dan 0)\n",
        "sample_size = min(label_1_count, label_0_count)\n",
        "\n",
        "# Ambil sampel dari masing-masing label di data yang valid\n",
        "sampled_label_1 = valid_data[valid_data['label'] == 1].sample(n=sample_size, random_state=42)\n",
        "sampled_label_0 = valid_data[valid_data['label'] == 0].sample(n=sample_size, random_state=42)\n",
        "\n",
        "# Gabungkan kedua sampel menjadi satu dataframe seimbang\n",
        "balanced_df = pd.concat([sampled_label_1, sampled_label_0], ignore_index=True)\n",
        "\n",
        "# Periksa distribusi label dalam dataframe seimbang\n",
        "print(balanced_df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "Lao1kzgEmSwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34533a33-9d5f-49a2-c410-bb2acdadae41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1.0    10857\n",
            "0.0    10857\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Drop kolom 'ts' dari balanced_df\n",
        "# merged_train_df.drop(columns=['ts'], inplace=True)"
      ],
      "metadata": {
        "id": "us57-SpEXQ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Drop kolom 'ts' dari balanced_df\n",
        "# merged_test_df.drop(columns=['ts'], inplace=True)"
      ],
      "metadata": {
        "id": "KPXrupEoaTwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Drop kolom 'ts' dari balanced_df\n",
        "# balanced_df.drop(columns=['ts'], inplace=True)"
      ],
      "metadata": {
        "id": "uu6Iciwz3RU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df.info()"
      ],
      "metadata": {
        "id": "FWBRu_k3cdKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea657cd-8996-4046-a5e9-764c5ecd52b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21714 entries, 0 to 21713\n",
            "Data columns (total 31 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   user_id       21714 non-null  int64  \n",
            " 1   pc0           21714 non-null  float64\n",
            " 2   pc1           21714 non-null  float64\n",
            " 3   pc2           21714 non-null  float64\n",
            " 4   pc3           21714 non-null  float64\n",
            " 5   pc4           21714 non-null  float64\n",
            " 6   pc5           21714 non-null  float64\n",
            " 7   pc6           21714 non-null  float64\n",
            " 8   pc7           21714 non-null  float64\n",
            " 9   pc8           21714 non-null  float64\n",
            " 10  pc9           21714 non-null  float64\n",
            " 11  pc10          21714 non-null  float64\n",
            " 12  pc11          21714 non-null  float64\n",
            " 13  pc12          21714 non-null  float64\n",
            " 14  pc13          21714 non-null  float64\n",
            " 15  pc14          21714 non-null  float64\n",
            " 16  pc15          21714 non-null  float64\n",
            " 17  pc16          21714 non-null  float64\n",
            " 18  label         21714 non-null  float64\n",
            " 19  ts            13802 non-null  float64\n",
            " 20  loan_type_1   21714 non-null  bool   \n",
            " 21  loan_type_2   21714 non-null  bool   \n",
            " 22  loan_type_3   21714 non-null  bool   \n",
            " 23  loan_type_4   21714 non-null  bool   \n",
            " 24  loan_type_5   21714 non-null  bool   \n",
            " 25  loan_type_6   21714 non-null  bool   \n",
            " 26  loan_type_7   21714 non-null  bool   \n",
            " 27  loan_type_8   21714 non-null  bool   \n",
            " 28  loan_type_9   21714 non-null  bool   \n",
            " 29  loan_type_10  21714 non-null  bool   \n",
            " 30  loan_type_11  21714 non-null  bool   \n",
            "dtypes: bool(11), float64(19), int64(1)\n",
            "memory usage: 3.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df"
      ],
      "metadata": {
        "id": "BNr8iDTSM2wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "846916e3-0301-4d8c-f208-f03c89d5142b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_id  pc0  pc1    pc2    pc3       pc4  pc5    pc6    pc7    pc8  \\\n",
              "0        12325  1.0  1.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "1      2471153  1.0  5.0  0.590  0.490  0.830508  0.4  0.361  0.051  0.341   \n",
              "2      1584515  1.0  4.0  1.050  1.015  0.966667  1.1  2.192  0.034  2.184   \n",
              "3      2051716  1.0  1.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "4      1132416  1.0  5.0  0.315  0.310  0.984127  0.1  0.083  0.002  0.082   \n",
              "...        ...  ...  ...    ...    ...       ...  ...    ...    ...    ...   \n",
              "21709   297046  1.0  3.0  7.730  7.530  0.974127  7.0  2.807  0.116  2.765   \n",
              "21710  3439582  1.0  7.0 -1.000 -1.000 -1.000000 -1.0 -1.000 -1.000 -1.000   \n",
              "21711  3040965  1.0  4.0  0.550  0.445  0.809091  0.1  0.995  0.001  0.969   \n",
              "21712  1199980  1.0  6.0  0.160  0.160  1.000000  0.2  0.247  0.041  0.247   \n",
              "21713  2355458  0.0  8.0  0.180  0.180  1.000000  0.2  0.171  0.007  0.171   \n",
              "\n",
              "       ...  loan_type_2  loan_type_3  loan_type_4  loan_type_5  loan_type_6  \\\n",
              "0      ...        False        False        False         True        False   \n",
              "1      ...        False        False        False         True        False   \n",
              "2      ...        False        False        False        False        False   \n",
              "3      ...        False        False        False         True        False   \n",
              "4      ...        False        False        False         True        False   \n",
              "...    ...          ...          ...          ...          ...          ...   \n",
              "21709  ...        False        False        False         True        False   \n",
              "21710  ...        False        False        False         True        False   \n",
              "21711  ...        False        False        False         True         True   \n",
              "21712  ...        False        False        False         True        False   \n",
              "21713  ...        False        False        False         True        False   \n",
              "\n",
              "       loan_type_7  loan_type_8  loan_type_9  loan_type_10  loan_type_11  \n",
              "0            False        False        False         False         False  \n",
              "1            False        False        False         False         False  \n",
              "2            False        False        False         False          True  \n",
              "3            False        False        False         False         False  \n",
              "4            False         True        False         False         False  \n",
              "...            ...          ...          ...           ...           ...  \n",
              "21709        False        False        False         False         False  \n",
              "21710        False        False        False         False         False  \n",
              "21711        False        False        False         False         False  \n",
              "21712        False        False        False         False         False  \n",
              "21713        False        False        False         False         False  \n",
              "\n",
              "[21714 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f55bd786-fae9-45cc-9735-08c174ab9c9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pc0</th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>...</th>\n",
              "      <th>loan_type_2</th>\n",
              "      <th>loan_type_3</th>\n",
              "      <th>loan_type_4</th>\n",
              "      <th>loan_type_5</th>\n",
              "      <th>loan_type_6</th>\n",
              "      <th>loan_type_7</th>\n",
              "      <th>loan_type_8</th>\n",
              "      <th>loan_type_9</th>\n",
              "      <th>loan_type_10</th>\n",
              "      <th>loan_type_11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12325</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2471153</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.830508</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.361</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.341</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1584515</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.050</td>\n",
              "      <td>1.015</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.192</td>\n",
              "      <td>0.034</td>\n",
              "      <td>2.184</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2051716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1132416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.984127</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.082</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21709</th>\n",
              "      <td>297046</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.730</td>\n",
              "      <td>7.530</td>\n",
              "      <td>0.974127</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.807</td>\n",
              "      <td>0.116</td>\n",
              "      <td>2.765</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21710</th>\n",
              "      <td>3439582</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21711</th>\n",
              "      <td>3040965</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.445</td>\n",
              "      <td>0.809091</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.969</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21712</th>\n",
              "      <td>1199980</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.247</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.247</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21713</th>\n",
              "      <td>2355458</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.180</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.171</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.171</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21714 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f55bd786-fae9-45cc-9735-08c174ab9c9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f55bd786-fae9-45cc-9735-08c174ab9c9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f55bd786-fae9-45cc-9735-08c174ab9c9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b215e08-a467-45ee-9991-bbe43d741d2d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b215e08-a467-45ee-9991-bbe43d741d2d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b215e08-a467-45ee-9991-bbe43d741d2d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eeeb1d52-041f-4299-838c-f0f94715f330\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eeeb1d52-041f-4299-838c-f0f94715f330 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm-AvZiQoQlr",
        "outputId": "03078100-eeff-450d-bc2d-a1cde09cf679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 367702 entries, 0 to 367701\n",
            "Data columns (total 30 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   user_id       367702 non-null  int64  \n",
            " 1   pc0           367702 non-null  float64\n",
            " 2   pc1           367702 non-null  float64\n",
            " 3   pc2           367702 non-null  float64\n",
            " 4   pc3           367702 non-null  float64\n",
            " 5   pc4           367702 non-null  float64\n",
            " 6   pc5           367702 non-null  float64\n",
            " 7   pc6           367702 non-null  float64\n",
            " 8   pc7           367702 non-null  float64\n",
            " 9   pc8           367702 non-null  float64\n",
            " 10  pc9           367702 non-null  float64\n",
            " 11  pc10          367702 non-null  float64\n",
            " 12  pc11          367702 non-null  float64\n",
            " 13  pc12          367702 non-null  float64\n",
            " 14  pc13          367702 non-null  float64\n",
            " 15  pc14          367702 non-null  float64\n",
            " 16  pc15          367702 non-null  float64\n",
            " 17  pc16          367702 non-null  float64\n",
            " 18  ts            289408 non-null  float64\n",
            " 19  loan_type_1   367702 non-null  bool   \n",
            " 20  loan_type_2   367702 non-null  bool   \n",
            " 21  loan_type_3   367702 non-null  bool   \n",
            " 22  loan_type_4   367702 non-null  bool   \n",
            " 23  loan_type_5   367702 non-null  bool   \n",
            " 24  loan_type_6   367702 non-null  bool   \n",
            " 25  loan_type_7   367702 non-null  bool   \n",
            " 26  loan_type_8   367702 non-null  bool   \n",
            " 27  loan_type_9   367702 non-null  bool   \n",
            " 28  loan_type_10  367702 non-null  bool   \n",
            " 29  loan_type_11  367702 non-null  bool   \n",
            "dtypes: bool(11), float64(18), int64(1)\n",
            "memory usage: 57.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Convert"
      ],
      "metadata": {
        "id": "0PL8Kk9Bn7E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import networkx as nx\n",
        "# from itertools import combinations\n",
        "\n",
        "# # Membaca data\n",
        "# # merge_train_df = pd.read_csv('path/to/merge_train_df.csv')\n",
        "\n",
        "# # Inisialisasi graf\n",
        "# G = nx.Graph()\n",
        "\n",
        "# # Menambahkan node dan fitur node\n",
        "# for _, row in balanced_df.iterrows():\n",
        "#     user_id = row['user_id']\n",
        "#     features = row[['pc0', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11', 'pc12', 'pc13', 'pc14', 'pc15', 'pc16']].tolist()\n",
        "#     label = row['label']\n",
        "#     G.add_node(user_id, features=features, label=label)\n",
        "\n",
        "# # Membuat dictionary untuk pengguna berdasarkan loan_type\n",
        "# loan_types = [f'loan_type_{i}' for i in range(1, 12)]\n",
        "# loan_dict = {loan_type: [] for loan_type in loan_types}\n",
        "\n",
        "# # Mengelompokkan pengguna berdasarkan loan_type\n",
        "# for loan_type in loan_types:\n",
        "#     users_with_loan = balanced_df[balanced_df[loan_type] == 1]['user_id'].tolist()\n",
        "#     loan_dict[loan_type].extend(users_with_loan)\n",
        "\n",
        "# # Membuat edge antar pengguna berdasarkan loan_dict\n",
        "# for users in loan_dict.values():\n",
        "#     for u1, u2 in combinations(users, 2):\n",
        "#         G.add_edge(u1, u2)\n",
        "\n",
        "# # G sekarang adalah graf dengan node, fitur, dan sisi\n"
      ],
      "metadata": {
        "id": "4Uls5DCKn91G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b088ebb0-c49f-486d-8864-3db87ed3274d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f2676f160ecd>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloan_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# G sekarang adalah graf dengan node, fitur, dan sisi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u_of_edge, v_of_edge, **attr)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebunch_to_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/utils/misc.py\u001b[0m in \u001b[0;36m_clear_cache\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m     \"\"\"Clear the cache of a graph (currently stores converted graphs).\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import math\n",
        "\n",
        "# Membaca data\n",
        "# balanced_df =\n",
        "\n",
        "# Inisialisasi graf\n",
        "G = nx.Graph()\n",
        "\n",
        "# Menambahkan node dan fitur node\n",
        "for _, row in balanced_df.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    features = row[['pc0', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11', 'pc12', 'pc13', 'pc14', 'pc15', 'pc16']].tolist()\n",
        "    label = row['label']\n",
        "    G.add_node(user_id, features=features, label=label)\n",
        "\n",
        "# Menghitung jumlah batch yang diperlukan\n",
        "batch_size = 1000  # Ubah sesuai dengan kebutuhan\n",
        "num_batches = math.ceil(len(balanced_df) / batch_size)\n",
        "\n",
        "line0 = 0\n",
        "\n",
        "# Definisi loan_types\n",
        "loan_types = [f'loan_type_{i}' for i in range(1, 12)]\n",
        "\n",
        "# Memproses dataset secara berbasis batch\n",
        "for batch_idx in range(num_batches):\n",
        "    batch_start = batch_idx * batch_size\n",
        "    batch_end = min((batch_idx + 1) * batch_size, len(balanced_df))\n",
        "    batch_data = balanced_df.iloc[batch_start:batch_end]\n",
        "    line1 = 0\n",
        "    line0 += 1\n",
        "    print(\"batch: \", line0)\n",
        "    # Membuat edge untuk batch saat ini\n",
        "    for loan_type in loan_types:\n",
        "        line1+=1\n",
        "        print(\"type: \", line1)\n",
        "        users_with_loan = batch_data[batch_data[loan_type] == 1]['user_id'].tolist()\n",
        "        # line2 = 0\n",
        "        for u1, u2 in combinations(users_with_loan, 2):\n",
        "            G.add_edge(u1, u2)\n",
        "            # line2+=1\n",
        "            # print(\"comb: \", line2)\n",
        "\n",
        "# G sekarang adalah graf dengan node, fitur, dan sisi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNpExcb-8A0w",
        "outputId": "7cad9d5a-e4a9-4104-c9f5-da1ed2fa363d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch:  1\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  2\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  3\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  4\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  5\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  6\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  7\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  8\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  9\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  10\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  11\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  12\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  13\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  14\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  15\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  16\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  17\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import networkx as nx\n",
        "# from itertools import combinations\n",
        "\n",
        "# # Membaca data test\n",
        "# # merged_test_df = pd.read_csv('path/to/merged_test_df.csv')\n",
        "\n",
        "# # Inisialisasi graf\n",
        "# G_test = nx.Graph()\n",
        "\n",
        "# # Menambahkan node dan fitur node\n",
        "# for _, row in merged_test_df.iterrows():\n",
        "#     user_id = row['user_id']\n",
        "#     features = row[['pc0', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11', 'pc12', 'pc13', 'pc14', 'pc15', 'pc16']].tolist()\n",
        "#     G_test.add_node(user_id, features=features)\n",
        "\n",
        "# # Membuat dictionary untuk pengguna berdasarkan loan_type\n",
        "# loan_types = [f'loan_type_{i}' for i in range(1, 12)]\n",
        "# loan_dict_test = {loan_type: [] for loan_type in loan_types}\n",
        "\n",
        "\n",
        "# # Mengelompokkan pengguna berdasarkan loan_type\n",
        "# for loan_type in loan_types:\n",
        "#     users_with_loan = merged_test_df[merged_test_df[loan_type] == 1]['user_id'].tolist()\n",
        "#     loan_dict_test[loan_type].extend(users_with_loan)\n",
        "\n",
        "# # Membuat edge antar pengguna berdasarkan loan_dict_test\n",
        "# for users in loan_dict_test.values():\n",
        "#     for u1, u2 in combinations(users, 2):\n",
        "#         G_test.add_edge(u1, u2)\n",
        "\n",
        "# # G_test sekarang adalah graf dengan node dan fitur\n"
      ],
      "metadata": {
        "id": "rzM5wvlhpIW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import math\n",
        "\n",
        "# Membaca data test\n",
        "# Gantilah dengan path yang sesuai dengan lokasi merged_test_df.csv\n",
        "# merged_test_df = pd.read_csv('path/to/merged_test_df.csv')\n",
        "\n",
        "# Inisialisasi graf\n",
        "G_test = nx.Graph()\n",
        "\n",
        "# Menambahkan node dan fitur node\n",
        "for _, row in merged_test_df.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    features = row[['pc0', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11', 'pc12', 'pc13', 'pc14', 'pc15', 'pc16']].tolist()\n",
        "    G_test.add_node(user_id, features=features)\n",
        "\n",
        "# Menghitung jumlah batch yang diperlukan\n",
        "batch_size = 1000  # Ubah sesuai dengan kebutuhan\n",
        "num_batches = math.ceil(len(merged_test_df) / batch_size)\n",
        "\n",
        "# Definisi loan_types\n",
        "loan_types = [f'loan_type_{i}' for i in range(1, 12)]\n",
        "\n",
        "line0 = 0\n",
        "\n",
        "# Memproses dataset secara berbasis batch\n",
        "for batch_idx in range(num_batches):\n",
        "    batch_start = batch_idx * batch_size\n",
        "    batch_end = min((batch_idx + 1) * batch_size, len(merged_test_df))\n",
        "    batch_data = merged_test_df.iloc[batch_start:batch_end]\n",
        "    line1 = 0\n",
        "    line0 += 1\n",
        "    print(\"batch: \", line0)\n",
        "    # Membuat edge untuk batch saat ini\n",
        "    for loan_type in loan_types:\n",
        "        users_with_loan = batch_data[batch_data[loan_type] == 1]['user_id'].tolist()\n",
        "        line1+=1\n",
        "        print(\"type: \", line1)\n",
        "        for u1, u2 in combinations(users_with_loan, 2):\n",
        "            G_test.add_edge(u1, u2)\n",
        "\n",
        "# G_test sekarang adalah graf dengan node dan fitur\n"
      ],
      "metadata": {
        "id": "Fn9omLipBxiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93f0aae-818d-4c53-fb9e-2aecf2a2b102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch:  1\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  2\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  3\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  4\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  5\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  6\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  7\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  8\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  9\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  10\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  11\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  12\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  13\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  14\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  15\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  16\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  17\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  18\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  19\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  20\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  21\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  22\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  23\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  24\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  25\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  26\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  27\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  28\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  29\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  30\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  31\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  32\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  33\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  34\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  35\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  36\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  37\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  38\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  39\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  40\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  41\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  42\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  43\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  44\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  45\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  46\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  47\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  48\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  49\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  50\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  51\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  52\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  53\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  54\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  55\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  56\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  57\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  58\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  59\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  60\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  61\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  62\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  63\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  64\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  65\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  66\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  67\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  68\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  69\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  70\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  71\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  72\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  73\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n",
            "batch:  74\n",
            "type:  1\n",
            "type:  2\n",
            "type:  3\n",
            "type:  4\n",
            "type:  5\n",
            "type:  6\n",
            "type:  7\n",
            "type:  8\n",
            "type:  9\n",
            "type:  10\n",
            "type:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mke0S31mAfXs",
        "outputId": "1ca282ea-8371-4de5-ed3b-0d71ca6f1ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import torch\n",
        "\n",
        "# URL file di Google Drive\n",
        "url = 'https://drive.google.com/uc?export=download&id=1BVbDyTTm0ysm-7P8CBNMqSAsHxKQN-Aq'\n",
        "output = 'data.pt'\n",
        "\n",
        "# Unduh file\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Memuat kembali data dari file .pt\n",
        "data = torch.load(output)\n",
        "\n",
        "# Jika Anda juga memiliki file data_test.pt\n",
        "url_test = 'https://drive.google.com/uc?export=download&id=1KWRPoVpsUuHJ1lvWwvKs1p05N3Xuatu7'\n",
        "output_test = 'data_test.pt'\n",
        "\n",
        "# Unduh file data_test\n",
        "gdown.download(url_test, output_test, quiet=False)\n",
        "\n",
        "# Memuat kembali data_test dari file .pt\n",
        "data_test = torch.load(output_test)\n"
      ],
      "metadata": {
        "id": "sMD3ycfo_4MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# data = from_networkx(G)\n",
        "data = torch.load('data.pt')\n",
        "\n",
        "# Memindahkan fitur node dan label ke tensor\n",
        "data.x = torch.tensor([G.nodes[n]['features'] for n in G.nodes()], dtype=torch.float)\n",
        "data.y = torch.tensor([G.nodes[n]['label'] for n in G.nodes()], dtype=torch.float)\n",
        "\n",
        "torch.save(data, 'data5000.pt')\n",
        "# Data siap untuk digunakan dalam model GNN\n"
      ],
      "metadata": {
        "id": "nqef9ZV4pgJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# data_test = from_networkx(G_test)\n",
        "data_test = torch.load('data_test.pt')\n",
        "\n",
        "# Memindahkan fitur node ke tensor\n",
        "data_test.x = torch.tensor([G_test.nodes[n]['features'] for n in G_test.nodes()], dtype=torch.float)\n",
        "\n",
        "\n",
        "torch.save(data_test, 'data_test5000.pt')\n",
        "\n",
        "# Data test siap untuk digunakan dalam model GNN\n"
      ],
      "metadata": {
        "id": "6UoOf5rUpkyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6qRyFjHDr4D",
        "outputId": "f2e6a9e8-c57c-4c41-80a6-e18d9459c835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
            "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 greenlet-3.0.3 optuna-3.6.1 sqlalchemy-2.0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# from torch_geometric.nn import GCNConv\n",
        "# from torch_geometric.data import Data\n",
        "# from torch_geometric.loader import DataLoader\n",
        "# from torch_geometric.utils import from_networkx\n",
        "# import networkx as nx\n",
        "# import pandas as pd\n",
        "# from sklearn.metrics import average_precision_score, classification_report\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import optuna\n",
        "\n",
        "# # Definisi model GNN\n",
        "# class GCN(torch.nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "#         super(GCN, self).__init__()\n",
        "#         self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "#         self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         return F.log_softmax(x, dim=1)\n",
        "\n",
        "# # Fungsi untuk tujuan optimasi hyperparameter\n",
        "# def objective(trial):\n",
        "#     input_dim = 17  # Jumlah fitur\n",
        "#     hidden_dim = trial.suggest_int('hidden_dim', 16, 128)\n",
        "#     output_dim = 2  # Binary classification\n",
        "\n",
        "#     model = GCN(input_dim, hidden_dim, output_dim).to(device)\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=trial.suggest_loguniform('lr', 1e-4, 1e-2))\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#     # Melatih model\n",
        "#     model.train()\n",
        "#     for epoch in range(50):  # Mengatur jumlah epoch\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(data_train)\n",
        "#         loss = criterion(out[data_train.train_mask], data_train.y[data_train.train_mask].long())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     # Evaluasi model\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         out = model(data_val)\n",
        "#         y_pred_proba = F.softmax(out[data_val.test_mask], dim=1)[:, 1].cpu().numpy()\n",
        "#     aps = average_precision_score(data_val.y[data_val.test_mask].cpu().numpy(), y_pred_proba)\n",
        "#     return aps\n",
        "\n",
        "# # Load data and preprocess as previously described\n",
        "# # Assuming data_train, data_val, and data_test have been created\n",
        "\n",
        "# # Setup device\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # Convert data to PyTorch Geometric format\n",
        "# data_train = data\n",
        "# data_val = data\n",
        "# data_test = data_test\n",
        "\n",
        "# # Adding train and test mask for training and evaluation\n",
        "# data_train.train_mask = torch.tensor([True] * len(data_train.y), dtype=torch.bool)\n",
        "# data_val.test_mask = torch.tensor([True] * len(data_val.y), dtype=torch.bool)\n",
        "\n",
        "# # Create Optuna study and optimize hyperparameters\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(objective, n_trials=100)\n",
        "\n",
        "# # Hasil hyperparameter terbaik\n",
        "# best_params = study.best_params\n",
        "# print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "# # Melatih model dengan hyperparameter terbaik\n",
        "# best_model = GCN(17, best_params['hidden_dim'], 2).to(device)\n",
        "# optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['lr'])\n",
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# # Melatih model\n",
        "# best_model.train()\n",
        "# for epoch in range(50):\n",
        "#     optimizer.zero_grad()\n",
        "#     out = best_model(data_train)\n",
        "#     loss = criterion(out[data_train.train_mask], data_train.y[data_train.train_mask].long())\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "# # Evaluasi model\n",
        "# best_model.eval()\n",
        "# with torch.no_grad():\n",
        "#     out = best_model(data_val)\n",
        "#     y_pred_proba_val = F.softmax(out[data_val.test_mask], dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "# average_precision = average_precision_score(data_val.y[data_val.test_mask].cpu().numpy(), y_pred_proba_val)\n",
        "# print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# # Optional: Evaluasi model menggunakan classification report\n",
        "# y_pred = out[data_val.test_mask].max(1)[1].cpu().numpy()\n",
        "# print(classification_report(data_val.y[data_val.test_mask].cpu().numpy(), y_pred))\n",
        "\n",
        "# # Prediksi probabilitas untuk data test\n",
        "# with torch.no_grad():\n",
        "#     out_test = best_model(data_test)\n",
        "#     y_pred_proba_test = F.softmax(out_test, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "# # Menyimpan hasil prediksi ke CSV\n",
        "# submission = pd.DataFrame({\n",
        "#     'user_id': merged_test_df['user_id'],\n",
        "#     'label': y_pred_proba_test\n",
        "# })\n",
        "# submission.to_csv('submission_gnn.csv', index=False)\n",
        "\n",
        "# subs = pd.read_csv('submission_gnn.csv')\n",
        "# print(subs[subs['label'] >= 0.5])\n"
      ],
      "metadata": {
        "id": "CqejjNpyrTMC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "0c128010-8372-48fb-a54f-8daaf92ad012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-07 02:39:00,805] A new study created in memory with name: no-name-864a1b4f-5630-4ddb-b066-8c2b827653fa\n",
            "<ipython-input-42-0bc52bf83b44>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  optimizer = torch.optim.Adam(model.parameters(), lr=trial.suggest_loguniform('lr', 1e-4, 1e-2))\n",
            "[W 2024-07-07 02:45:16,723] Trial 0 failed with parameters: {'hidden_dim': 116, 'lr': 0.0037727808757116754} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-42-0bc52bf83b44>\", line 43, in objective\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 525, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 267, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "[W 2024-07-07 02:45:16,726] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-0bc52bf83b44>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Create Optuna study and optimize hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Hasil hyperparameter terbaik\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0bc52bf83b44>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from sklearn.metrics import average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definisi model GNN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Load data and preprocess as previously described\n",
        "# Assuming data_train, data_val, and data_test have been created\n",
        "\n",
        "# Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Convert data to PyTorch Geometric format\n",
        "data_train = data\n",
        "data_val = data\n",
        "data_test = data_test\n",
        "\n",
        "# Adding train and test mask for training and evaluation\n",
        "data_train.train_mask = torch.tensor([True] * len(data_train.y), dtype=torch.bool)\n",
        "data_val.test_mask = torch.tensor([True] * len(data_val.y), dtype=torch.bool)\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 17  # Jumlah fitur\n",
        "hidden_dim = 64\n",
        "output_dim = 2  # Binary classification\n",
        "lr = 0.01\n",
        "\n",
        "# Initialize model, optimizer and loss function\n",
        "model = GCN(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Melatih model\n",
        "model.train()\n",
        "for epoch in range(50):  # Mengatur jumlah epoch\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data_train)\n",
        "    loss = criterion(out[data_train.train_mask], data_train.y[data_train.train_mask].long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluasi model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data_val)\n",
        "    y_pred_proba_val = F.softmax(out[data_val.test_mask], dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "average_precision = average_precision_score(data_val.y[data_val.test_mask].cpu().numpy(), y_pred_proba_val)\n",
        "print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# Optional: Evaluasi model menggunakan classification report\n",
        "y_pred = out[data_val.test_mask].max(1)[1].cpu().numpy()\n",
        "print(classification_report(data_val.y[data_val.test_mask].cpu().numpy(), y_pred))\n",
        "\n",
        "# Prediksi probabilitas untuk data test\n",
        "with torch.no_grad():\n",
        "    out_test = model(data_test)\n",
        "    y_pred_proba_test = F.softmax(out_test, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "# Menyimpan hasil prediksi ke CSV\n",
        "submission = pd.DataFrame({\n",
        "    'user_id': merged_test_df['user_id'],\n",
        "    'label': y_pred_proba_test\n",
        "})\n",
        "submission.to_csv('submission_gnn.csv', index=False)\n",
        "\n",
        "subs = pd.read_csv('submission_gnn.csv')\n",
        "print(subs[subs['label'] >= 0.5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNjpPoYIFeKH",
        "outputId": "141096bb-e797-48ed-e40b-cd68d5bacfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision Score: 0.9913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.97      0.97     42418\n",
            "         1.0       0.97      0.96      0.97     42418\n",
            "\n",
            "    accuracy                           0.97     84836\n",
            "   macro avg       0.97      0.97      0.97     84836\n",
            "weighted avg       0.97      0.97      0.97     84836\n",
            "\n",
            "        user_id     label\n",
            "1582      15985  0.608218\n",
            "3907      38709  0.666300\n",
            "6184      61292  0.646900\n",
            "11174    109848  1.000000\n",
            "15310    150219  1.000000\n",
            "...         ...       ...\n",
            "361142  3633358  0.960320\n",
            "361754  3640000  0.960320\n",
            "364431  3667022  1.000000\n",
            "365930  3682822  0.952021\n",
            "366732  3690673  0.711544\n",
            "\n",
            "[207 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "fwouObI4ajFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = balanced_df.drop(columns=['label'])\n",
        "y = balanced_df['label']"
      ],
      "metadata": {
        "id": "k0AX2fJqbJuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4-AP0BgsrUZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = merged_test_df\n",
        "# X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "0wOXQ-JQxLuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Modelling"
      ],
      "metadata": {
        "id": "ZuNikg2EsAF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model_rf (contoh dengan RandomForest)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vrZK73MKr_og",
        "outputId": "5771ca62-155f-4b66-be9e-294ad56a753f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model_rf\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model_rf.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Prediksi probabilitas untuk data validasi\n",
        "y_val_pred_proba = model_rf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Evaluasi model_rf menggunakan Average Precision Score\n",
        "average_precision = average_precision_score(y_val, y_val_pred_proba)\n",
        "print(f'Average Precision Score: {average_precision:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDc3PTF7sHX2",
        "outputId": "422ff04f-dd1b-46e2-b861-52c80945ff44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.65      0.66      2175\n",
            "         1.0       0.66      0.66      0.66      2168\n",
            "\n",
            "    accuracy                           0.66      4343\n",
            "   macro avg       0.66      0.66      0.66      4343\n",
            "weighted avg       0.66      0.66      0.66      4343\n",
            "\n",
            "Average Precision Score: 0.6701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "submisi_df = pd.DataFrame({\n",
        "    'user_id': data_test['user_id'],\n",
        "    'label': y_pred\n",
        "})\n",
        "\n",
        "submisi_df.to_csv('submisi.csv', index=False)"
      ],
      "metadata": {
        "id": "vMIKOWPOv15L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN Modelling\n"
      ],
      "metadata": {
        "id": "IeiY2MvKmdpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat graph dari data pinjaman\n",
        "G = nx.from_pandas_edgelist(data_loan, source='user_id', target='reference_contact')\n",
        "\n",
        "# Memastikan bahwa setiap node dalam G memiliki fitur di combined_train_df\n",
        "# Kita perlu menambahkan node ke graf yang mungkin tidak memiliki edges\n",
        "all_users = pd.concat([data_train['user_id'], data_non_borrower['user_id'], data_loan['user_id'], data_test['user_id']]).unique()\n",
        "for user in all_users:\n",
        "    if user not in G:\n",
        "        G.add_node(user)\n",
        "\n",
        "# Menambahkan fitur node dari combined_train_df\n",
        "node_features_df = combined_train_df.set_index('user_id').sort_index()\n",
        "node_features = node_features_df.drop(columns=['label']).reindex(G.nodes).fillna(0).values\n",
        "labels = node_features_df['label'].reindex(G.nodes).fillna(0).values"
      ],
      "metadata": {
        "id": "b1yTveSdmfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, node in enumerate(G.nodes):\n",
        "    G.nodes[node]['x'] = node_features[i]\n",
        "\n",
        "# Mengkonversi graph NetworkX menjadi PyTorch Geometric\n",
        "data = from_networkx(G)\n",
        "data.x = data.x.float()  # Konversi data.x menjadi float32\n",
        "data.edge_index = data.edge_index.long()  # Konversi data.edge_index menjadi long\n",
        "data.y = torch.tensor(labels, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "HmRaBG5ymhmH",
        "outputId": "b1a448c9-3c3e-4201-d516-9f7b4a270221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-973044c1cc2a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mengkonversi graph NetworkX menjadi PyTorch Geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Konversi data.x menjadi float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Konversi data.edge_index menjadi long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/convert.py\u001b[0m in \u001b[0;36mfrom_networkx\u001b[0;34m(G, group_node_attrs, group_edge_attrs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36mto_directed\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m         G.add_edges_from(\n\u001b[1;32m   1705\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_nodes_from\u001b[0;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_for_adding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mnewnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m         G.add_edges_from(\n\u001b[1;32m   1705\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = torch.rand(len(data.y)) < 0.8\n",
        "test_mask = ~train_mask\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask"
      ],
      "metadata": {
        "id": "DRHU367Im62G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan model GNN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 16)\n",
        "        self.conv2 = GCNConv(16, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "ojoHosbxnC5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = data.x.shape[1]\n",
        "num_classes = 2\n",
        "\n",
        "# Inisialisasi model\n",
        "model = GCN(num_features, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Yxo3Oxa8nFdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "# Evaluate model\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    pred = out.argmax(dim=1)\n",
        "    test_pred = pred[data.test_mask]\n",
        "    test_true = data.y[data.test_mask]\n",
        "    aps = average_precision_score(test_true.cpu(), test_pred.cpu())\n",
        "    report = classification_report(test_true.cpu(), test_pred.cpu(), output_dict=True)\n",
        "    return aps, report"
      ],
      "metadata": {
        "id": "jLyz-eRsnHQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        aps, report = evaluate()\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Average Precision Score: {aps:.4f}')"
      ],
      "metadata": {
        "id": "lS2tKvP6nH2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi akhir\n",
        "aps, report = evaluate()\n",
        "print(f'Final Average Precision Score: {aps:.4f}')\n",
        "print('Classification Report:')\n",
        "print(report)"
      ],
      "metadata": {
        "id": "BKKLRNiwnNXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN"
      ],
      "metadata": {
        "id": "2p51TyFrddTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import json\n",
        "\n",
        "data_dir = \"/content/\"\n",
        "\n",
        "# Ekstrak fitur dan simpan sebagai JSON\n",
        "node_features = balanced_df[['user_id', 'pc0', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'pc11', 'pc12', 'pc13', 'pc14', 'pc15', 'pc16', 'ts',\n",
        "                                 'loan_type_1', 'loan_type_2', 'loan_type_3', 'loan_type_4', 'loan_type_5', 'loan_type_6', 'loan_type_7', 'loan_type_8', 'loan_type_9',\n",
        "                                 'loan_type_10', 'loan_type_11']]\n",
        "\n",
        "# Convert dataframe to dictionary\n",
        "node_features_dict = node_features.set_index('user_id').T.to_dict('list')\n",
        "\n",
        "# Save the dictionary as JSON file\n",
        "with open(os.path.join(data_dir, \"node_features.json\"), \"w\") as json_file:\n",
        "    json.dump(node_features_dict, json_file)"
      ],
      "metadata": {
        "id": "NOjV0uIDdfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan label sebagai CSV\n",
        "merged_train_df[['user_id', 'label']].to_csv(os.path.join(data_dir, \"node_labels.csv\"), index=False)\n"
      ],
      "metadata": {
        "id": "HG71lHBueDyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Load node features\n",
        "def load_node_csv(path, index_col, **kwargs):\n",
        "    df = pd.read_csv(path, **kwargs)\n",
        "    mapping = {i: node_id for i, node_id in enumerate(df[index_col].unique())}\n",
        "\n",
        "    with open(os.path.join(data_dir, \"node_features.json\"), \"r\") as json_file:\n",
        "        features_data = json.load(json_file)\n",
        "\n",
        "    xs = []\n",
        "    for index, node_id in mapping.items():\n",
        "        features = features_data.get(str(node_id), [])\n",
        "        if features:\n",
        "            features_tensor = torch.tensor(features, dtype=torch.float)\n",
        "            xs.append(features_tensor)\n",
        "        else:\n",
        "            xs.append(torch.zeros(1, dtype=torch.float))\n",
        "\n",
        "    padded_features = pad_sequence(xs, batch_first=True, padding_value=0)\n",
        "    mask = padded_features != 0\n",
        "\n",
        "    mean = torch.mean(padded_features[mask].float())\n",
        "    std = torch.std(padded_features[mask].float())\n",
        "\n",
        "    x = (padded_features - mean) / (std + 1e-8)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Load labels\n",
        "def load_labels_csv(path, label_col, **kwargs):\n",
        "    df = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    label_categories = df[label_col].astype(\"category\").cat.categories\n",
        "\n",
        "    class_label_to_code = pd.DataFrame({\n",
        "        \"class_label\": label_categories,\n",
        "        \"class_label_code\": pd.Categorical(label_categories, categories=label_categories).codes\n",
        "    })\n",
        "    df[\"class_label_code\"] = pd.Categorical(df[label_col], categories=label_categories).codes\n",
        "\n",
        "    y = torch.tensor(df[\"class_label_code\"].values, dtype=torch.long)\n",
        "\n",
        "    return y\n",
        "\n",
        "# Paths\n",
        "data_dir = \"/content/\"\n",
        "node_features_path = os.path.join(data_dir, \"node_labels.csv\")\n",
        "label_path = os.path.join(data_dir, \"node_labels.csv\")\n",
        "\n",
        "# Load node features and labels\n",
        "x = load_node_csv(path=node_features_path, index_col=\"user_id\")\n",
        "y = load_labels_csv(path=label_path, label_col=\"label\")\n",
        "\n",
        "print(x)\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "SgYlCqnHe8Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load edges\n",
        "def load_edge_csv(path, src_index_col, dst_index_col, **kwargs):\n",
        "    df = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    src = df[src_index_col].values\n",
        "    dst = df[dst_index_col].values\n",
        "    edge_index = torch.tensor([src, dst])\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "print(\"Edges:\")\n",
        "print(edge_index)"
      ],
      "metadata": {
        "id": "mjW5PNRBfplz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GBM"
      ],
      "metadata": {
        "id": "XCynuhP2NkrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjgX_4LgkBYv",
        "outputId": "b8249f36-cf48-4b9a-f4d4-d8ffa418e843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# Fungsi untuk tujuan optimasi hyperparameter\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'average_precision',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**param)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='average_precision')\n",
        "\n",
        "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "    aps = average_precision_score(y_val, y_pred_proba)\n",
        "    return aps\n",
        "\n",
        "# # Prediksi probabilitas untuk data validasi\n",
        "# y_pred_proba = model_lgb.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# # Evaluasi model_lgb menggunakan Average Precision Score\n",
        "# average_precision = average_precision_score(y_val, y_pred_proba)\n",
        "# print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# # Optional: Evaluasi model_lgb menggunakan classification report\n",
        "# y_pred = model_lgb.predict(X_val)\n",
        "# print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "DrCcHM0SNmaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat study Optuna dan optimasi hyperparameter\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "# Hasil hyperparameter terbaik\n",
        "best_params = study.best_params\n",
        "print(f\"Best parameters found: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xTR1JQixptV",
        "outputId": "c449bbac-ebfb-4ef7-d5e0-cd62bbda81ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:55:50,839] A new study created in memory with name: no-name-510a7d4d-c09b-4c23-8eea-dfa1e6869099\n",
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6575172938465543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6575172938465543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726364877921121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726364877921121\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6575172938465543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6575172938465543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726364877921121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726364877921121\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006777 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6575172938465543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6575172938465543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726364877921121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726364877921121\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:55:51,606] Trial 0 finished with value: 0.7822706329330791 and parameters: {'learning_rate': 0.03567562155383362, 'feature_fraction': 0.6575172938465543, 'bagging_fraction': 0.9726364877921121, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 0 with value: 0.7822706329330791.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6575172938465543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6575172938465543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726364877921121, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726364877921121\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6288593146938257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6288593146938257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6303536038963711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6303536038963711\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6288593146938257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6288593146938257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6303536038963711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6303536038963711\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006020 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6288593146938257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6288593146938257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6303536038963711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6303536038963711\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:52,394] Trial 1 finished with value: 0.7841289550057557 and parameters: {'learning_rate': 0.046450551022745895, 'feature_fraction': 0.6288593146938257, 'bagging_fraction': 0.6303536038963711, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 1 with value: 0.7841289550057557.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6288593146938257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6288593146938257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6303536038963711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6303536038963711\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950428452984351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950428452984351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9275504687497534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9275504687497534\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950428452984351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950428452984351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9275504687497534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9275504687497534\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950428452984351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950428452984351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9275504687497534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9275504687497534\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:53,311] Trial 2 finished with value: 0.773694407766156 and parameters: {'learning_rate': 0.01466468646104885, 'feature_fraction': 0.9950428452984351, 'bagging_fraction': 0.9275504687497534, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 1 with value: 0.7841289550057557.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9950428452984351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950428452984351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9275504687497534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9275504687497534\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8947724270109003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947724270109003\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8796108576610537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8796108576610537\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8947724270109003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947724270109003\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8796108576610537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8796108576610537\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8947724270109003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947724270109003\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8796108576610537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8796108576610537\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:54,136] Trial 3 finished with value: 0.7848919556591344 and parameters: {'learning_rate': 0.05294035695008923, 'feature_fraction': 0.8947724270109003, 'bagging_fraction': 0.8796108576610537, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8947724270109003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8947724270109003\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8796108576610537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8796108576610537\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8442305932085916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8442305932085916\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9423861836413975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423861836413975\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8442305932085916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8442305932085916\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9423861836413975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423861836413975\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003573 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8442305932085916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8442305932085916\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9423861836413975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423861836413975\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:54,983] Trial 4 finished with value: 0.7656183278039317 and parameters: {'learning_rate': 0.00010667656181121106, 'feature_fraction': 0.8442305932085916, 'bagging_fraction': 0.9423861836413975, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8442305932085916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8442305932085916\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9423861836413975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423861836413975\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6526848113657407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526848113657407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6306716867375853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6306716867375853\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6526848113657407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526848113657407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6306716867375853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6306716867375853\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6526848113657407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526848113657407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6306716867375853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6306716867375853\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:55,742] Trial 5 finished with value: 0.7730346979791003 and parameters: {'learning_rate': 0.0004650662363225693, 'feature_fraction': 0.6526848113657407, 'bagging_fraction': 0.6306716867375853, 'bagging_freq': 7, 'min_child_samples': 91}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6526848113657407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526848113657407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6306716867375853, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6306716867375853\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6823732234664681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6823732234664681\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9418790338029207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9418790338029207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6823732234664681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6823732234664681\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9418790338029207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9418790338029207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6823732234664681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6823732234664681\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9418790338029207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9418790338029207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:56,930] Trial 6 finished with value: 0.769711246953762 and parameters: {'learning_rate': 0.0077806262832110715, 'feature_fraction': 0.6823732234664681, 'bagging_fraction': 0.9418790338029207, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6823732234664681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6823732234664681\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9418790338029207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9418790338029207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.886025171047331, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886025171047331\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6722261540738538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6722261540738538\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.886025171047331, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886025171047331\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6722261540738538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6722261540738538\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.886025171047331, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886025171047331\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6722261540738538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6722261540738538\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:58,075] Trial 7 finished with value: 0.77106918990985 and parameters: {'learning_rate': 0.0007635520924148433, 'feature_fraction': 0.886025171047331, 'bagging_fraction': 0.6722261540738538, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.886025171047331, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886025171047331\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6722261540738538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6722261540738538\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8657030147315312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8657030147315312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6730383429866194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730383429866194\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8657030147315312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8657030147315312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6730383429866194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730383429866194\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005081 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8657030147315312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8657030147315312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6730383429866194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730383429866194\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:55:59,124] Trial 8 finished with value: 0.7700059454373502 and parameters: {'learning_rate': 0.0012060279459756265, 'feature_fraction': 0.8657030147315312, 'bagging_fraction': 0.6730383429866194, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8657030147315312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8657030147315312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6730383429866194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6730383429866194\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9224082101305578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224082101305578\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.683010551362109, subsample=1.0 will be ignored. Current value: bagging_fraction=0.683010551362109\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9224082101305578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224082101305578\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.683010551362109, subsample=1.0 will be ignored. Current value: bagging_fraction=0.683010551362109\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9224082101305578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224082101305578\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.683010551362109, subsample=1.0 will be ignored. Current value: bagging_fraction=0.683010551362109\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:00,331] Trial 9 finished with value: 0.7758453171922262 and parameters: {'learning_rate': 0.01559890274225313, 'feature_fraction': 0.9224082101305578, 'bagging_fraction': 0.683010551362109, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9224082101305578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224082101305578\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.683010551362109, subsample=1.0 will be ignored. Current value: bagging_fraction=0.683010551362109\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7591913303693937, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591913303693937\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8290340548749148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290340548749148\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7591913303693937, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591913303693937\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8290340548749148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290340548749148\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7591913303693937, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591913303693937\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8290340548749148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290340548749148\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:01,621] Trial 10 finished with value: 0.7837754012715887 and parameters: {'learning_rate': 0.07888625247767903, 'feature_fraction': 0.7591913303693937, 'bagging_fraction': 0.8290340548749148, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7591913303693937, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591913303693937\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8290340548749148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8290340548749148\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7601590552320173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7601590552320173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8076180126200887, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076180126200887\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7601590552320173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7601590552320173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8076180126200887, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076180126200887\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7601590552320173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7601590552320173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8076180126200887, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076180126200887\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:02,935] Trial 11 finished with value: 0.7785761342996407 and parameters: {'learning_rate': 0.0969307613874608, 'feature_fraction': 0.7601590552320173, 'bagging_fraction': 0.8076180126200887, 'bagging_freq': 6, 'min_child_samples': 72}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7601590552320173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7601590552320173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8076180126200887, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076180126200887\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6117489585569581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6117489585569581\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8648711945494466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8648711945494466\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6117489585569581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6117489585569581\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8648711945494466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8648711945494466\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6117489585569581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6117489585569581\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8648711945494466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8648711945494466\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:04,219] Trial 12 finished with value: 0.7695425986413046 and parameters: {'learning_rate': 0.005494182397582521, 'feature_fraction': 0.6117489585569581, 'bagging_fraction': 0.8648711945494466, 'bagging_freq': 7, 'min_child_samples': 54}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6117489585569581, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6117489585569581\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8648711945494466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8648711945494466\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9736674562627092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9736674562627092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7494467916634204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7494467916634204\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9736674562627092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9736674562627092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7494467916634204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7494467916634204\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006820 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9736674562627092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9736674562627092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7494467916634204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7494467916634204\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:05,170] Trial 13 finished with value: 0.7817755725266542 and parameters: {'learning_rate': 0.03024336139056413, 'feature_fraction': 0.9736674562627092, 'bagging_fraction': 0.7494467916634204, 'bagging_freq': 5, 'min_child_samples': 79}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9736674562627092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9736674562627092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7494467916634204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7494467916634204\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021113139117204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021113139117204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7484191954410271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7484191954410271\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021113139117204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021113139117204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7484191954410271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7484191954410271\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006646 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021113139117204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021113139117204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7484191954410271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7484191954410271\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:06,098] Trial 14 finished with value: 0.7704529125913828 and parameters: {'learning_rate': 0.0026054802900807163, 'feature_fraction': 0.8021113139117204, 'bagging_fraction': 0.7484191954410271, 'bagging_freq': 6, 'min_child_samples': 48}. Best is trial 3 with value: 0.7848919556591344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021113139117204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021113139117204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7484191954410271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7484191954410271\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7316015556860268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7316015556860268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8871297934870989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8871297934870989\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7316015556860268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7316015556860268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8871297934870989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8871297934870989\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006102 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7316015556860268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7316015556860268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8871297934870989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8871297934870989\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:06,970] Trial 15 finished with value: 0.7852221793123216 and parameters: {'learning_rate': 0.04648833132067453, 'feature_fraction': 0.7316015556860268, 'bagging_fraction': 0.8871297934870989, 'bagging_freq': 5, 'min_child_samples': 82}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7316015556860268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7316015556860268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8871297934870989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8871297934870989\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7276486860677093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276486860677093\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861460126013871, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861460126013871\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7276486860677093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276486860677093\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861460126013871, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861460126013871\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7276486860677093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276486860677093\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861460126013871, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861460126013871\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:07,883] Trial 16 finished with value: 0.7798522212740852 and parameters: {'learning_rate': 0.01784757832355384, 'feature_fraction': 0.7276486860677093, 'bagging_fraction': 0.861460126013871, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7276486860677093, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276486860677093\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861460126013871, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861460126013871\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9316589778289809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9316589778289809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8925406974600686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8925406974600686\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9316589778289809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9316589778289809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8925406974600686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8925406974600686\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003632 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9316589778289809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9316589778289809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8925406974600686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8925406974600686\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:08,744] Trial 17 finished with value: 0.7655102428777079 and parameters: {'learning_rate': 0.0027941218924727117, 'feature_fraction': 0.9316589778289809, 'bagging_fraction': 0.8925406974600686, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9316589778289809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9316589778289809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8925406974600686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8925406974600686\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8188387474220176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188387474220176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7647741577138525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7647741577138525\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8188387474220176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188387474220176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7647741577138525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7647741577138525\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003709 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8188387474220176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188387474220176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7647741577138525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7647741577138525\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:09,618] Trial 18 finished with value: 0.7714277621727844 and parameters: {'learning_rate': 0.0065854312128589484, 'feature_fraction': 0.8188387474220176, 'bagging_fraction': 0.7647741577138525, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8188387474220176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188387474220176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7647741577138525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7647741577138525\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7077570988443141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077570988443141\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9992937135646451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992937135646451\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7077570988443141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077570988443141\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9992937135646451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992937135646451\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006839 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7077570988443141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077570988443141\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9992937135646451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992937135646451\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:10,526] Trial 19 finished with value: 0.7833413777349205 and parameters: {'learning_rate': 0.05337538634070312, 'feature_fraction': 0.7077570988443141, 'bagging_fraction': 0.9992937135646451, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7077570988443141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077570988443141\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9992937135646451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992937135646451\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7743016081369404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743016081369404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981171867074395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981171867074395\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7743016081369404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743016081369404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981171867074395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981171867074395\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7743016081369404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743016081369404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981171867074395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981171867074395\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:11,448] Trial 20 finished with value: 0.7799576136649976 and parameters: {'learning_rate': 0.023748755842852496, 'feature_fraction': 0.7743016081369404, 'bagging_fraction': 0.8981171867074395, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7743016081369404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743016081369404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981171867074395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981171867074395\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6049765126281896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049765126281896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6142572189154542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6142572189154542\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6049765126281896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049765126281896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6142572189154542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6142572189154542\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6049765126281896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049765126281896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6142572189154542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6142572189154542\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:12,226] Trial 21 finished with value: 0.7825527018574252 and parameters: {'learning_rate': 0.05537105739651134, 'feature_fraction': 0.6049765126281896, 'bagging_fraction': 0.6142572189154542, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial 15 with value: 0.7852221793123216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6049765126281896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049765126281896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6142572189154542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6142572189154542\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6419639057854207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419639057854207\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8399524765617303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399524765617303\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6419639057854207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419639057854207\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8399524765617303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399524765617303\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004171 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6419639057854207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419639057854207\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8399524765617303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399524765617303\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:13,033] Trial 22 finished with value: 0.7861004704662568 and parameters: {'learning_rate': 0.039697684421743096, 'feature_fraction': 0.6419639057854207, 'bagging_fraction': 0.8399524765617303, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6419639057854207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419639057854207\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8399524765617303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399524765617303\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712270535117837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712270535117837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8294724202539135, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8294724202539135\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712270535117837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712270535117837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8294724202539135, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8294724202539135\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007003 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712270535117837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712270535117837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8294724202539135, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8294724202539135\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:13,926] Trial 23 finished with value: 0.7736071773208975 and parameters: {'learning_rate': 0.011593991659584227, 'feature_fraction': 0.712270535117837, 'bagging_fraction': 0.8294724202539135, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.712270535117837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712270535117837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8294724202539135, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8294724202539135\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6806547079892233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6806547079892233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8720824247202075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8720824247202075\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6806547079892233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6806547079892233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8720824247202075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8720824247202075\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006168 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6806547079892233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6806547079892233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8720824247202075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8720824247202075\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:14,944] Trial 24 finished with value: 0.784843120678671 and parameters: {'learning_rate': 0.09276374847286771, 'feature_fraction': 0.6806547079892233, 'bagging_fraction': 0.8720824247202075, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6806547079892233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6806547079892233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8720824247202075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8720824247202075\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9080308106745816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080308106745816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924139737405448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924139737405448\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9080308106745816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080308106745816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924139737405448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924139737405448\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9080308106745816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080308106745816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924139737405448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924139737405448\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:16,107] Trial 25 finished with value: 0.7835168620590873 and parameters: {'learning_rate': 0.034076810547992664, 'feature_fraction': 0.9080308106745816, 'bagging_fraction': 0.7924139737405448, 'bagging_freq': 7, 'min_child_samples': 86}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9080308106745816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080308106745816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924139737405448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924139737405448\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8328182740788599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328182740788599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.90966639102628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.90966639102628\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8328182740788599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328182740788599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.90966639102628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.90966639102628\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010239 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8328182740788599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328182740788599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.90966639102628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.90966639102628\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:17,456] Trial 26 finished with value: 0.7797728793889356 and parameters: {'learning_rate': 0.025148791116843944, 'feature_fraction': 0.8328182740788599, 'bagging_fraction': 0.90966639102628, 'bagging_freq': 5, 'min_child_samples': 74}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8328182740788599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8328182740788599\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.90966639102628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.90966639102628\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7812163906363725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812163906363725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8431148562282158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431148562282158\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7812163906363725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812163906363725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8431148562282158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431148562282158\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004881 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7812163906363725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812163906363725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8431148562282158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431148562282158\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:18,778] Trial 27 finished with value: 0.7740181702984451 and parameters: {'learning_rate': 0.008909904635583306, 'feature_fraction': 0.7812163906363725, 'bagging_fraction': 0.8431148562282158, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7812163906363725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812163906363725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8431148562282158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8431148562282158\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7400642696212084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400642696212084\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7985606428768308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7985606428768308\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7400642696212084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400642696212084\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7985606428768308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7985606428768308\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014562 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7400642696212084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400642696212084\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7985606428768308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7985606428768308\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:20,094] Trial 28 finished with value: 0.7696931736614389 and parameters: {'learning_rate': 0.004127710818002898, 'feature_fraction': 0.7400642696212084, 'bagging_fraction': 0.7985606428768308, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7400642696212084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400642696212084\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7985606428768308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7985606428768308\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6554775732087454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6554775732087454\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8865644328947118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865644328947118\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6554775732087454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6554775732087454\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8865644328947118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865644328947118\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013829 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6554775732087454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6554775732087454\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8865644328947118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865644328947118\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:21,454] Trial 29 finished with value: 0.7853409725805673 and parameters: {'learning_rate': 0.0485796393121503, 'feature_fraction': 0.6554775732087454, 'bagging_fraction': 0.8865644328947118, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6554775732087454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6554775732087454\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8865644328947118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865644328947118\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501138525369139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501138525369139\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9642960627398107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642960627398107\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501138525369139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501138525369139\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9642960627398107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642960627398107\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010751 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501138525369139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501138525369139\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9642960627398107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642960627398107\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:22,439] Trial 30 finished with value: 0.7834113326368866 and parameters: {'learning_rate': 0.03570447299309602, 'feature_fraction': 0.6501138525369139, 'bagging_fraction': 0.9642960627398107, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6501138525369139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501138525369139\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9642960627398107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642960627398107\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6723017087249981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6723017087249981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8835315667654752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8835315667654752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6723017087249981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6723017087249981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8835315667654752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8835315667654752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6723017087249981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6723017087249981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8835315667654752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8835315667654752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:23,292] Trial 31 finished with value: 0.7841415102709132 and parameters: {'learning_rate': 0.05935785507368148, 'feature_fraction': 0.6723017087249981, 'bagging_fraction': 0.8835315667654752, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6723017087249981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6723017087249981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8835315667654752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8835315667654752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6244499232534939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6244499232534939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.911924880279556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.911924880279556\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6244499232534939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6244499232534939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.911924880279556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.911924880279556\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6244499232534939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6244499232534939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.911924880279556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.911924880279556\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:24,188] Trial 32 finished with value: 0.7848145114166031 and parameters: {'learning_rate': 0.041810430838764054, 'feature_fraction': 0.6244499232534939, 'bagging_fraction': 0.911924880279556, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6244499232534939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6244499232534939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.911924880279556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.911924880279556\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6969414187972746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969414187972746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8505157324393136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8505157324393136\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6969414187972746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969414187972746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8505157324393136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8505157324393136\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6969414187972746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969414187972746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8505157324393136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8505157324393136\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:25,102] Trial 33 finished with value: 0.7810533062401184 and parameters: {'learning_rate': 0.021524313631754752, 'feature_fraction': 0.6969414187972746, 'bagging_fraction': 0.8505157324393136, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6969414187972746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969414187972746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8505157324393136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8505157324393136\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6400261499461661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400261499461661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9271774472675668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9271774472675668\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6400261499461661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400261499461661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9271774472675668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9271774472675668\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008059 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6400261499461661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400261499461661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9271774472675668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9271774472675668\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:25,956] Trial 34 finished with value: 0.7844944009253734 and parameters: {'learning_rate': 0.06543037717459659, 'feature_fraction': 0.6400261499461661, 'bagging_fraction': 0.9271774472675668, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6400261499461661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400261499461661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9271774472675668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9271774472675668\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6672598874958334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6672598874958334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.966957606423043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.966957606423043\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6672598874958334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6672598874958334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.966957606423043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.966957606423043\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6672598874958334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6672598874958334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.966957606423043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.966957606423043\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:26,849] Trial 35 finished with value: 0.7665762866709768 and parameters: {'learning_rate': 0.00014770488435563586, 'feature_fraction': 0.6672598874958334, 'bagging_fraction': 0.966957606423043, 'bagging_freq': 4, 'min_child_samples': 96}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6672598874958334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6672598874958334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.966957606423043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.966957606423043\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6289352711009955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6289352711009955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9288809994716606, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9288809994716606\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6289352711009955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6289352711009955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9288809994716606, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9288809994716606\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6289352711009955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6289352711009955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9288809994716606, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9288809994716606\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:27,757] Trial 36 finished with value: 0.7732694996033894 and parameters: {'learning_rate': 0.010880604998084442, 'feature_fraction': 0.6289352711009955, 'bagging_fraction': 0.9288809994716606, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 22 with value: 0.7861004704662568.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6289352711009955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6289352711009955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9288809994716606, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9288809994716606\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7248852830750256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7248852830750256\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206924278356114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206924278356114\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7248852830750256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7248852830750256\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206924278356114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206924278356114\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7248852830750256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7248852830750256\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206924278356114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206924278356114\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:28,618] Trial 37 finished with value: 0.788632039189861 and parameters: {'learning_rate': 0.047321162935646074, 'feature_fraction': 0.7248852830750256, 'bagging_fraction': 0.8206924278356114, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7248852830750256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7248852830750256\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206924278356114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206924278356114\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319964805860192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319964805860192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.816765591234877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.816765591234877\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319964805860192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319964805860192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.816765591234877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.816765591234877\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004152 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319964805860192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319964805860192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.816765591234877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.816765591234877\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:29,446] Trial 38 finished with value: 0.7858916959042112 and parameters: {'learning_rate': 0.043170300092197654, 'feature_fraction': 0.7319964805860192, 'bagging_fraction': 0.816765591234877, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7319964805860192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319964805860192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.816765591234877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.816765591234877\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939209088024504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939209088024504\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7696595253966884, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696595253966884\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939209088024504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939209088024504\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7696595253966884, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696595253966884\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006432 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939209088024504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939209088024504\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7696595253966884, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696595253966884\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:30,320] Trial 39 finished with value: 0.776240202555071 and parameters: {'learning_rate': 0.01346116672628049, 'feature_fraction': 0.6939209088024504, 'bagging_fraction': 0.7696595253966884, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6939209088024504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939209088024504\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7696595253966884, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696595253966884\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6566037456724098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6566037456724098\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138899010820491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138899010820491\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6566037456724098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6566037456724098\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138899010820491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138899010820491\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6566037456724098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6566037456724098\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138899010820491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138899010820491\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:31,180] Trial 40 finished with value: 0.784174012232125 and parameters: {'learning_rate': 0.029820776096615768, 'feature_fraction': 0.6566037456724098, 'bagging_fraction': 0.7138899010820491, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6566037456724098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6566037456724098\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7138899010820491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7138899010820491\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7307546600134389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7307546600134389\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206536263160757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206536263160757\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7307546600134389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7307546600134389\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206536263160757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206536263160757\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7307546600134389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7307546600134389\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206536263160757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206536263160757\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:32,052] Trial 41 finished with value: 0.788631165911464 and parameters: {'learning_rate': 0.04427103328064878, 'feature_fraction': 0.7307546600134389, 'bagging_fraction': 0.8206536263160757, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7307546600134389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7307546600134389\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8206536263160757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206536263160757\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465417557936151, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465417557936151\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184511412761016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184511412761016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465417557936151, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465417557936151\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184511412761016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184511412761016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010816 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465417557936151, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465417557936151\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184511412761016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184511412761016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:33,159] Trial 42 finished with value: 0.7864409183641962 and parameters: {'learning_rate': 0.07356358596689819, 'feature_fraction': 0.7465417557936151, 'bagging_fraction': 0.8184511412761016, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 37 with value: 0.788632039189861.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7465417557936151, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465417557936151\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184511412761016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184511412761016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7499287003387377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7499287003387377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8280324517609294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8280324517609294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7499287003387377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7499287003387377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8280324517609294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8280324517609294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010267 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7499287003387377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7499287003387377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8280324517609294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8280324517609294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:34,307] Trial 43 finished with value: 0.7888139905937138 and parameters: {'learning_rate': 0.07157382492625827, 'feature_fraction': 0.7499287003387377, 'bagging_fraction': 0.8280324517609294, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7499287003387377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7499287003387377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8280324517609294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8280324517609294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7549827911890771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549827911890771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7842554224002833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7842554224002833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7549827911890771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549827911890771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7842554224002833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7842554224002833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011485 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7549827911890771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549827911890771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7842554224002833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7842554224002833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:35,462] Trial 44 finished with value: 0.7845332694542112 and parameters: {'learning_rate': 0.07324293956439476, 'feature_fraction': 0.7549827911890771, 'bagging_fraction': 0.7842554224002833, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7549827911890771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549827911890771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7842554224002833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7842554224002833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.79162069328517, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79162069328517\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8276641210326147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8276641210326147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.79162069328517, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79162069328517\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8276641210326147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8276641210326147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015253 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.79162069328517, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79162069328517\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8276641210326147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8276641210326147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:36,636] Trial 45 finished with value: 0.7852793269522872 and parameters: {'learning_rate': 0.09733171729642194, 'feature_fraction': 0.79162069328517, 'bagging_fraction': 0.8276641210326147, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.79162069328517, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79162069328517\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8276641210326147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8276641210326147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7561438728221498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561438728221498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8464003059145926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464003059145926\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7561438728221498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561438728221498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8464003059145926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464003059145926\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7561438728221498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561438728221498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8464003059145926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464003059145926\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:37,959] Trial 46 finished with value: 0.7866824016783576 and parameters: {'learning_rate': 0.06941806580654411, 'feature_fraction': 0.7561438728221498, 'bagging_fraction': 0.8464003059145926, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7561438728221498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7561438728221498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8464003059145926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464003059145926\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7594009749314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7594009749314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.814868391139111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.814868391139111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7594009749314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7594009749314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.814868391139111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.814868391139111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011567 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7594009749314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7594009749314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.814868391139111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.814868391139111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:39,223] Trial 47 finished with value: 0.7850416257121521 and parameters: {'learning_rate': 0.07069983374054284, 'feature_fraction': 0.7594009749314, 'bagging_fraction': 0.814868391139111, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7594009749314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7594009749314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.814868391139111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.814868391139111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8081279902565833, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8081279902565833\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7393996481425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7393996481425\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8081279902565833, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8081279902565833\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7393996481425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7393996481425\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008088 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8081279902565833, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8081279902565833\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7393996481425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7393996481425\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:40,533] Trial 48 finished with value: 0.7697660562650419 and parameters: {'learning_rate': 0.0011330273389774388, 'feature_fraction': 0.8081279902565833, 'bagging_fraction': 0.7393996481425, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8081279902565833, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8081279902565833\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7393996481425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7393996481425\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7193907514204847, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7193907514204847\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7761097449138423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7761097449138423\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7193907514204847, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7193907514204847\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7761097449138423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7761097449138423\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014165 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7193907514204847, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7193907514204847\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7761097449138423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7761097449138423\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:41,432] Trial 49 finished with value: 0.7833372813825684 and parameters: {'learning_rate': 0.07572988570343665, 'feature_fraction': 0.7193907514204847, 'bagging_fraction': 0.7761097449138423, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7193907514204847, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7193907514204847\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7761097449138423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7761097449138423\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451514515797024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451514515797024\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597077305477477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597077305477477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451514515797024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451514515797024\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597077305477477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597077305477477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003624 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451514515797024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451514515797024\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597077305477477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597077305477477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:42,282] Trial 50 finished with value: 0.7800032751815729 and parameters: {'learning_rate': 0.018081471919261058, 'feature_fraction': 0.7451514515797024, 'bagging_fraction': 0.8597077305477477, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7451514515797024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451514515797024\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597077305477477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597077305477477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7732887062475453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7732887062475453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8417082055186678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8417082055186678\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7732887062475453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7732887062475453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8417082055186678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8417082055186678\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7732887062475453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7732887062475453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8417082055186678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8417082055186678\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:43,195] Trial 51 finished with value: 0.7814702597519813 and parameters: {'learning_rate': 0.03446654038213507, 'feature_fraction': 0.7732887062475453, 'bagging_fraction': 0.8417082055186678, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7732887062475453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7732887062475453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8417082055186678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8417082055186678\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7062880181276814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062880181276814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107858024782817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107858024782817\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7062880181276814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062880181276814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107858024782817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107858024782817\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003659 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7062880181276814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062880181276814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107858024782817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107858024782817\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:44,002] Trial 52 finished with value: 0.7849881430191444 and parameters: {'learning_rate': 0.0592018363490833, 'feature_fraction': 0.7062880181276814, 'bagging_fraction': 0.8107858024782817, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7062880181276814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062880181276814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107858024782817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107858024782817\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.866663151957318, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.866663151957318\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8295704668699846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8295704668699846\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.866663151957318, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.866663151957318\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8295704668699846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8295704668699846\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004424 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.866663151957318, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.866663151957318\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8295704668699846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8295704668699846\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:44,827] Trial 53 finished with value: 0.7861791783766855 and parameters: {'learning_rate': 0.09716667987294672, 'feature_fraction': 0.866663151957318, 'bagging_fraction': 0.8295704668699846, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.866663151957318, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.866663151957318\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8295704668699846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8295704668699846\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8528367659453452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528367659453452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.791337218675634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.791337218675634\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8528367659453452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528367659453452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.791337218675634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.791337218675634\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8528367659453452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528367659453452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.791337218675634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.791337218675634\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:45,631] Trial 54 finished with value: 0.7842473966995347 and parameters: {'learning_rate': 0.09158010024938906, 'feature_fraction': 0.8528367659453452, 'bagging_fraction': 0.791337218675634, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8528367659453452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528367659453452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.791337218675634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.791337218675634\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9500457637731794, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500457637731794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8309474575859516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8309474575859516\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9500457637731794, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500457637731794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8309474575859516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8309474575859516\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9500457637731794, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500457637731794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8309474575859516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8309474575859516\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:46,399] Trial 55 finished with value: 0.7818381015035857 and parameters: {'learning_rate': 0.027396210630972976, 'feature_fraction': 0.9500457637731794, 'bagging_fraction': 0.8309474575859516, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9500457637731794, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500457637731794\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8309474575859516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8309474575859516\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8219945916639099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219945916639099\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.856440237426724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.856440237426724\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8219945916639099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219945916639099\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.856440237426724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.856440237426724\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8219945916639099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219945916639099\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.856440237426724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.856440237426724\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:47,303] Trial 56 finished with value: 0.7685382146358772 and parameters: {'learning_rate': 0.0003330328160343739, 'feature_fraction': 0.8219945916639099, 'bagging_fraction': 0.856440237426724, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8219945916639099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8219945916639099\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.856440237426724, subsample=1.0 will be ignored. Current value: bagging_fraction=0.856440237426724\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8735791731999069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8735791731999069\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8050654553487073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050654553487073\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8735791731999069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8735791731999069\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8050654553487073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050654553487073\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004314 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8735791731999069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8735791731999069\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8050654553487073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050654553487073\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:48,111] Trial 57 finished with value: 0.7869736377474512 and parameters: {'learning_rate': 0.07561737684333456, 'feature_fraction': 0.8735791731999069, 'bagging_fraction': 0.8050654553487073, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8735791731999069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8735791731999069\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8050654553487073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8050654553487073\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7818176474408384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818176474408384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7559350543246284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7559350543246284\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7818176474408384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818176474408384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7559350543246284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7559350543246284\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010041 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7818176474408384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818176474408384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7559350543246284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7559350543246284\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:49,030] Trial 58 finished with value: 0.7700148160301343 and parameters: {'learning_rate': 0.0020904128935741507, 'feature_fraction': 0.7818176474408384, 'bagging_fraction': 0.7559350543246284, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7818176474408384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818176474408384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7559350543246284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7559350543246284\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7442837181555452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442837181555452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7997945093910027, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7997945093910027\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7442837181555452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442837181555452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7997945093910027, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7997945093910027\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003597 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7442837181555452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442837181555452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7997945093910027, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7997945093910027\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:49,827] Trial 59 finished with value: 0.788369758405268 and parameters: {'learning_rate': 0.05178694833771033, 'feature_fraction': 0.7442837181555452, 'bagging_fraction': 0.7997945093910027, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7442837181555452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442837181555452\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7997945093910027, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7997945093910027\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7264104072107693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7264104072107693\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7338558849147251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7338558849147251\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7264104072107693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7264104072107693\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7338558849147251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7338558849147251\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7264104072107693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7264104072107693\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7338558849147251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7338558849147251\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:56:50,702] Trial 60 finished with value: 0.7787086474758393 and parameters: {'learning_rate': 0.01983400723425159, 'feature_fraction': 0.7264104072107693, 'bagging_fraction': 0.7338558849147251, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7264104072107693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7264104072107693\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7338558849147251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7338558849147251\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7506101238859464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506101238859464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7996883079336125, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996883079336125\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7506101238859464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506101238859464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7996883079336125, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996883079336125\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012004 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7506101238859464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506101238859464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7996883079336125, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996883079336125\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:51,911] Trial 61 finished with value: 0.7875041660676394 and parameters: {'learning_rate': 0.050128183630439756, 'feature_fraction': 0.7506101238859464, 'bagging_fraction': 0.7996883079336125, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7506101238859464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506101238859464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7996883079336125, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996883079336125\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7929241697654574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929241697654574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8039809294530563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8039809294530563\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7929241697654574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929241697654574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8039809294530563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8039809294530563\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011437 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7929241697654574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929241697654574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8039809294530563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8039809294530563\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:53,103] Trial 62 finished with value: 0.7851881334292803 and parameters: {'learning_rate': 0.04789808699514595, 'feature_fraction': 0.7929241697654574, 'bagging_fraction': 0.8039809294530563, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7929241697654574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929241697654574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8039809294530563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8039809294530563\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7667413309768746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7667413309768746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8712551525952504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8712551525952504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7667413309768746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7667413309768746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8712551525952504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8712551525952504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014758 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7667413309768746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7667413309768746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8712551525952504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8712551525952504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:54,371] Trial 63 finished with value: 0.7863214650238826 and parameters: {'learning_rate': 0.05288370743536456, 'feature_fraction': 0.7667413309768746, 'bagging_fraction': 0.8712551525952504, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7667413309768746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7667413309768746\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8712551525952504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8712551525952504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7494842302462776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7494842302462776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.781610803340034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.781610803340034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7494842302462776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7494842302462776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.781610803340034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.781610803340034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011392 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7494842302462776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7494842302462776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.781610803340034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.781610803340034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:55,717] Trial 64 finished with value: 0.7850093178860318 and parameters: {'learning_rate': 0.039826448889842526, 'feature_fraction': 0.7494842302462776, 'bagging_fraction': 0.781610803340034, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7494842302462776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7494842302462776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.781610803340034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.781610803340034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7173116267463122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7173116267463122\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8006746255942913, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8006746255942913\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7173116267463122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7173116267463122\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8006746255942913, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8006746255942913\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015875 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7173116267463122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7173116267463122\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8006746255942913, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8006746255942913\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:57,101] Trial 65 finished with value: 0.7834740270680728 and parameters: {'learning_rate': 0.03050838032355542, 'feature_fraction': 0.7173116267463122, 'bagging_fraction': 0.8006746255942913, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7173116267463122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7173116267463122\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8006746255942913, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8006746255942913\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319506136577876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319506136577876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7626586696446689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626586696446689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7319506136577876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319506136577876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7626586696446689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626586696446689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319506136577876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319506136577876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7626586696446689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626586696446689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:58,349] Trial 66 finished with value: 0.7871148216500596 and parameters: {'learning_rate': 0.06273736146620085, 'feature_fraction': 0.7319506136577876, 'bagging_fraction': 0.7626586696446689, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7319506136577876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319506136577876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7626586696446689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626586696446689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6942483704229155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6942483704229155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7169671580871846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7169671580871846\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6942483704229155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6942483704229155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7169671580871846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7169671580871846\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6942483704229155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6942483704229155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7169671580871846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7169671580871846\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:56:59,410] Trial 67 finished with value: 0.7869116962725506 and parameters: {'learning_rate': 0.05574539689042404, 'feature_fraction': 0.6942483704229155, 'bagging_fraction': 0.7169671580871846, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6942483704229155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6942483704229155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7169671580871846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7169671580871846\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.73307260681204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73307260681204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7655028144642612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7655028144642612\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.73307260681204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73307260681204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7655028144642612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7655028144642612\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003615 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.73307260681204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73307260681204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7655028144642612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7655028144642612\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:00,242] Trial 68 finished with value: 0.7806156400380309 and parameters: {'learning_rate': 0.026436019693759652, 'feature_fraction': 0.73307260681204, 'bagging_fraction': 0.7655028144642612, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.73307260681204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73307260681204\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7655028144642612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7655028144642612\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8840014704460862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8840014704460862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7836834928551568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7836834928551568\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8840014704460862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8840014704460862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7836834928551568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7836834928551568\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004224 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8840014704460862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8840014704460862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7836834928551568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7836834928551568\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:01,125] Trial 69 finished with value: 0.7842605003441641 and parameters: {'learning_rate': 0.040330639713212005, 'feature_fraction': 0.8840014704460862, 'bagging_fraction': 0.7836834928551568, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8840014704460862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8840014704460862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7836834928551568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7836834928551568\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7027023135453123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7027023135453123\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7554013178199537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554013178199537\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7027023135453123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7027023135453123\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7554013178199537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554013178199537\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006694 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7027023135453123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7027023135453123\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7554013178199537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554013178199537\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:02,029] Trial 70 finished with value: 0.7751399846021219 and parameters: {'learning_rate': 0.015603223309415876, 'feature_fraction': 0.7027023135453123, 'bagging_fraction': 0.7554013178199537, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7027023135453123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7027023135453123\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7554013178199537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7554013178199537\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6850778470229996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6850778470229996\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7050785642085583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7050785642085583\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6850778470229996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6850778470229996\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7050785642085583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7050785642085583\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6850778470229996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6850778470229996\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7050785642085583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7050785642085583\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:02,862] Trial 71 finished with value: 0.7854166546978797 and parameters: {'learning_rate': 0.057760419687790804, 'feature_fraction': 0.6850778470229996, 'bagging_fraction': 0.7050785642085583, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 43 with value: 0.7888139905937138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6850778470229996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6850778470229996\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7050785642085583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7050785642085583\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6890013605013567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6890013605013567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6589937741676131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6589937741676131\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6890013605013567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6890013605013567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6589937741676131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6589937741676131\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006732 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6890013605013567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6890013605013567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6589937741676131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6589937741676131\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:03,672] Trial 72 finished with value: 0.7905655863734544 and parameters: {'learning_rate': 0.08080757622142744, 'feature_fraction': 0.6890013605013567, 'bagging_fraction': 0.6589937741676131, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6890013605013567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6890013605013567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6589937741676131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6589937741676131\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.995966272330377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.995966272330377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.628242627013881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.628242627013881\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.995966272330377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.995966272330377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.628242627013881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.628242627013881\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.995966272330377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.995966272330377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.628242627013881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.628242627013881\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:04,472] Trial 73 finished with value: 0.7844517195224776 and parameters: {'learning_rate': 0.07836890302985845, 'feature_fraction': 0.995966272330377, 'bagging_fraction': 0.628242627013881, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.995966272330377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.995966272330377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.628242627013881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.628242627013881\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7227979285846031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7227979285846031\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6533023663064785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6533023663064785\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7227979285846031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7227979285846031\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6533023663064785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6533023663064785\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7227979285846031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7227979285846031\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6533023663064785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6533023663064785\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:05,286] Trial 74 finished with value: 0.7892325172162995 and parameters: {'learning_rate': 0.046874842760751885, 'feature_fraction': 0.7227979285846031, 'bagging_fraction': 0.6533023663064785, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7227979285846031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7227979285846031\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6533023663064785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6533023663064785\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7158444675836976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7158444675836976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6546599424724262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6546599424724262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7158444675836976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7158444675836976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6546599424724262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6546599424724262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006118 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7158444675836976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7158444675836976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6546599424724262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6546599424724262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:06,166] Trial 75 finished with value: 0.7898954421984536 and parameters: {'learning_rate': 0.047044705032866695, 'feature_fraction': 0.7158444675836976, 'bagging_fraction': 0.6546599424724262, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7158444675836976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7158444675836976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6546599424724262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6546599424724262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.716306205002824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716306205002824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638205886814413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638205886814413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.716306205002824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716306205002824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638205886814413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638205886814413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.716306205002824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716306205002824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638205886814413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638205886814413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:07,009] Trial 76 finished with value: 0.7840809962796994 and parameters: {'learning_rate': 0.04585549959065605, 'feature_fraction': 0.716306205002824, 'bagging_fraction': 0.638205886814413, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.716306205002824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716306205002824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638205886814413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638205886814413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6695365615960058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6695365615960058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6635095919354378, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6635095919354378\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6695365615960058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6695365615960058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6635095919354378, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6635095919354378\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6695365615960058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6695365615960058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6635095919354378, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6635095919354378\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:07,883] Trial 77 finished with value: 0.7827486495425615 and parameters: {'learning_rate': 0.03397615013378601, 'feature_fraction': 0.6695365615960058, 'bagging_fraction': 0.6635095919354378, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6695365615960058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6695365615960058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6635095919354378, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6635095919354378\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6825818565400034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825818565400034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6528867337766276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6528867337766276\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6825818565400034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825818565400034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6528867337766276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6528867337766276\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6825818565400034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825818565400034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6528867337766276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6528867337766276\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:08,720] Trial 78 finished with value: 0.7820242096219165 and parameters: {'learning_rate': 0.02068257596412472, 'feature_fraction': 0.6825818565400034, 'bagging_fraction': 0.6528867337766276, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6825818565400034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825818565400034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6528867337766276, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6528867337766276\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7407231159620339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7407231159620339\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6955636932411184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6955636932411184\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7407231159620339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7407231159620339\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6955636932411184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6955636932411184\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7407231159620339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7407231159620339\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6955636932411184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6955636932411184\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:09,791] Trial 79 finished with value: 0.7836758526931451 and parameters: {'learning_rate': 0.023606786775497088, 'feature_fraction': 0.7407231159620339, 'bagging_fraction': 0.6955636932411184, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7407231159620339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7407231159620339\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6955636932411184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6955636932411184\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7221995084581119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221995084581119\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6005289102298906, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6005289102298906\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7221995084581119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221995084581119\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6005289102298906, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6005289102298906\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7221995084581119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221995084581119\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6005289102298906, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6005289102298906\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:10,894] Trial 80 finished with value: 0.7856799086953049 and parameters: {'learning_rate': 0.04896832180670038, 'feature_fraction': 0.7221995084581119, 'bagging_fraction': 0.6005289102298906, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7221995084581119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221995084581119\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6005289102298906, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6005289102298906\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7070212308595369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070212308595369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6854459639177298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6854459639177298\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7070212308595369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070212308595369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6854459639177298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6854459639177298\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011311 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7070212308595369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070212308595369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6854459639177298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6854459639177298\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:12,038] Trial 81 finished with value: 0.788383485988193 and parameters: {'learning_rate': 0.06211698321188859, 'feature_fraction': 0.7070212308595369, 'bagging_fraction': 0.6854459639177298, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7070212308595369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070212308595369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6854459639177298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6854459639177298\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7088661261890589, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7088661261890589\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.681093874603712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.681093874603712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7088661261890589, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7088661261890589\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.681093874603712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.681093874603712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013475 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7088661261890589, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7088661261890589\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.681093874603712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.681093874603712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:13,120] Trial 82 finished with value: 0.7877458400192968 and parameters: {'learning_rate': 0.08678808131584095, 'feature_fraction': 0.7088661261890589, 'bagging_fraction': 0.681093874603712, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7088661261890589, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7088661261890589\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.681093874603712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.681093874603712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.707565246753401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.707565246753401\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6824522909097726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6824522909097726\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.707565246753401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.707565246753401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.6824522909097726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6824522909097726\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.707565246753401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.707565246753401\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6824522909097726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6824522909097726\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:14,333] Trial 83 finished with value: 0.790360489513099 and parameters: {'learning_rate': 0.08813117982840395, 'feature_fraction': 0.707565246753401, 'bagging_fraction': 0.6824522909097726, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.707565246753401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.707565246753401\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6824522909097726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6824522909097726\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6951424066493703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6951424066493703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6517351923269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6517351923269\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6951424066493703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6951424066493703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6517351923269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6517351923269\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012588 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6951424066493703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6951424066493703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6517351923269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6517351923269\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:15,574] Trial 84 finished with value: 0.7849801651920276 and parameters: {'learning_rate': 0.06392541124114647, 'feature_fraction': 0.6951424066493703, 'bagging_fraction': 0.6517351923269, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6951424066493703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6951424066493703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6517351923269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6517351923269\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813147991542522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813147991542522\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6693004793872392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6693004793872392\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6813147991542522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813147991542522\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6693004793872392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6693004793872392\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016264 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813147991542522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813147991542522\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6693004793872392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6693004793872392\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:16,829] Trial 85 finished with value: 0.784240395062688 and parameters: {'learning_rate': 0.03720053219737886, 'feature_fraction': 0.6813147991542522, 'bagging_fraction': 0.6693004793872392, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6813147991542522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813147991542522\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6693004793872392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6693004793872392\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7379017224139958, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7379017224139958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6888339651593621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6888339651593621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7379017224139958, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7379017224139958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6888339651593621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6888339651593621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011188 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7379017224139958, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7379017224139958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6888339651593621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6888339651593621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:17,868] Trial 86 finished with value: 0.7823416304302954 and parameters: {'learning_rate': 0.08332518095470795, 'feature_fraction': 0.7379017224139958, 'bagging_fraction': 0.6888339651593621, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7379017224139958, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7379017224139958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6888339651593621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6888339651593621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.700973798122445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700973798122445\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638512415089593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638512415089593\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.700973798122445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700973798122445\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638512415089593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638512415089593\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.700973798122445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700973798122445\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638512415089593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638512415089593\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:18,734] Trial 87 finished with value: 0.78535649868734 and parameters: {'learning_rate': 0.06549083783165759, 'feature_fraction': 0.700973798122445, 'bagging_fraction': 0.638512415089593, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.700973798122445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700973798122445\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638512415089593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638512415089593\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7668364401048956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668364401048956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6211492162074684, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6211492162074684\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7668364401048956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668364401048956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6211492162074684, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6211492162074684\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003610 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7668364401048956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668364401048956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6211492162074684, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6211492162074684\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:19,472] Trial 88 finished with value: 0.7820296154370197 and parameters: {'learning_rate': 0.09691680996161671, 'feature_fraction': 0.7668364401048956, 'bagging_fraction': 0.6211492162074684, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7668364401048956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668364401048956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6211492162074684, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6211492162074684\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6638009306146112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6638009306146112\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6551618177236717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6551618177236717\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6638009306146112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6638009306146112\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6551618177236717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6551618177236717\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6638009306146112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6638009306146112\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6551618177236717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6551618177236717\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:20,301] Trial 89 finished with value: 0.7844172147567435 and parameters: {'learning_rate': 0.03207757727519242, 'feature_fraction': 0.6638009306146112, 'bagging_fraction': 0.6551618177236717, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6638009306146112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6638009306146112\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6551618177236717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6551618177236717\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6888811256329881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888811256329881\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782061023838047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782061023838047\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6888811256329881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888811256329881\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782061023838047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782061023838047\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007540 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6888811256329881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888811256329881\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782061023838047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782061023838047\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:21,129] Trial 90 finished with value: 0.7862738982289323 and parameters: {'learning_rate': 0.04183576904107302, 'feature_fraction': 0.6888811256329881, 'bagging_fraction': 0.6782061023838047, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6888811256329881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888811256329881\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782061023838047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782061023838047\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7073241155549908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7073241155549908\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6638089776069641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6638089776069641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7073241155549908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7073241155549908\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6638089776069641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6638089776069641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7073241155549908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7073241155549908\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6638089776069641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6638089776069641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:21,915] Trial 91 finished with value: 0.788668030027162 and parameters: {'learning_rate': 0.08112759826736592, 'feature_fraction': 0.7073241155549908, 'bagging_fraction': 0.6638089776069641, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7073241155549908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7073241155549908\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6638089776069641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6638089776069641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115026989122744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115026989122744\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6427915896540438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6427915896540438\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115026989122744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115026989122744\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6427915896540438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6427915896540438\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006089 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115026989122744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115026989122744\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6427915896540438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6427915896540438\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:22,700] Trial 92 finished with value: 0.7884725036157225 and parameters: {'learning_rate': 0.08545285518237826, 'feature_fraction': 0.7115026989122744, 'bagging_fraction': 0.6427915896540438, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7115026989122744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115026989122744\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6427915896540438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6427915896540438\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115555483938008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115555483938008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6452864873746635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452864873746635\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115555483938008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115555483938008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6452864873746635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452864873746635\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7115555483938008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115555483938008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6452864873746635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452864873746635\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:23,501] Trial 93 finished with value: 0.7830094841680415 and parameters: {'learning_rate': 0.08159772642892998, 'feature_fraction': 0.7115555483938008, 'bagging_fraction': 0.6452864873746635, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7115555483938008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7115555483938008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6452864873746635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6452864873746635\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7200605687547722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200605687547722\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6625470645059874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6625470645059874\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7200605687547722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200605687547722\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6625470645059874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6625470645059874\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7200605687547722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200605687547722\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6625470645059874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6625470645059874\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:24,291] Trial 94 finished with value: 0.7860422648739557 and parameters: {'learning_rate': 0.06437920507651282, 'feature_fraction': 0.7200605687547722, 'bagging_fraction': 0.6625470645059874, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7200605687547722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200605687547722\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6625470645059874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6625470645059874\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.677437778930191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.677437778930191\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.610489280831833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.610489280831833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.677437778930191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.677437778930191\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.610489280831833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.610489280831833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.677437778930191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.677437778930191\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.610489280831833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.610489280831833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:25,075] Trial 95 finished with value: 0.7863387628226505 and parameters: {'learning_rate': 0.08418212322316006, 'feature_fraction': 0.677437778930191, 'bagging_fraction': 0.610489280831833, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.677437778930191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.677437778930191\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.610489280831833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.610489280831833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7048686590649627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7048686590649627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6898975851672476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6898975851672476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7048686590649627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7048686590649627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6898975851672476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6898975851672476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7048686590649627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7048686590649627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6898975851672476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6898975851672476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:25,891] Trial 96 finished with value: 0.7866421892101721 and parameters: {'learning_rate': 0.057827035577567965, 'feature_fraction': 0.7048686590649627, 'bagging_fraction': 0.6898975851672476, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7048686590649627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7048686590649627\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6898975851672476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6898975851672476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7304648075822344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7304648075822344\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.631879004239445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.631879004239445\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7304648075822344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7304648075822344\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.631879004239445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.631879004239445\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7304648075822344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7304648075822344\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.631879004239445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.631879004239445\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:26,677] Trial 97 finished with value: 0.7839824748650314 and parameters: {'learning_rate': 0.07329217361889223, 'feature_fraction': 0.7304648075822344, 'bagging_fraction': 0.631879004239445, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7304648075822344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7304648075822344\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.631879004239445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.631879004239445\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.713717402818637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713717402818637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6709455537967193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6709455537967193\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.713717402818637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713717402818637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6709455537967193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6709455537967193\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.713717402818637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713717402818637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6709455537967193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6709455537967193\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:27,438] Trial 98 finished with value: 0.780956217189339 and parameters: {'learning_rate': 0.09768698821040922, 'feature_fraction': 0.713717402818637, 'bagging_fraction': 0.6709455537967193, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.713717402818637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713717402818637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6709455537967193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6709455537967193\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6901541018098173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6901541018098173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454171070407583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454171070407583\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6901541018098173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6901541018098173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454171070407583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454171070407583\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6901541018098173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6901541018098173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454171070407583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454171070407583\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:28,494] Trial 99 finished with value: 0.7888593040241448 and parameters: {'learning_rate': 0.04364839627534737, 'feature_fraction': 0.6901541018098173, 'bagging_fraction': 0.6454171070407583, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6901541018098173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6901541018098173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454171070407583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454171070407583\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6959304155610742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6959304155610742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6456704285876215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6456704285876215\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6959304155610742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6959304155610742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6456704285876215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6456704285876215\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6959304155610742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6959304155610742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6456704285876215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6456704285876215\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:29,646] Trial 100 finished with value: 0.7856014426580843 and parameters: {'learning_rate': 0.04422157871306909, 'feature_fraction': 0.6959304155610742, 'bagging_fraction': 0.6456704285876215, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6959304155610742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6959304155610742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6456704285876215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6456704285876215\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.723002326140905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723002326140905\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6598795068371985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6598795068371985\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.723002326140905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723002326140905\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6598795068371985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6598795068371985\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010669 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.723002326140905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723002326140905\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6598795068371985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6598795068371985\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:30,871] Trial 101 finished with value: 0.7698623230450576 and parameters: {'learning_rate': 0.0048527795469906106, 'feature_fraction': 0.723002326140905, 'bagging_fraction': 0.6598795068371985, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.723002326140905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723002326140905\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6598795068371985, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6598795068371985\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6742046208347526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742046208347526\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6434907525651107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6434907525651107\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6742046208347526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742046208347526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6434907525651107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6434907525651107\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6742046208347526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742046208347526\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6434907525651107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6434907525651107\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:32,038] Trial 102 finished with value: 0.7871089773368501 and parameters: {'learning_rate': 0.06545913525259242, 'feature_fraction': 0.6742046208347526, 'bagging_fraction': 0.6434907525651107, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6742046208347526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742046208347526\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6434907525651107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6434907525651107\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.689284620644073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689284620644073\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6239421196168061, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6239421196168061\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.689284620644073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689284620644073\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6239421196168061, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6239421196168061\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013016 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.689284620644073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689284620644073\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6239421196168061, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6239421196168061\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:33,285] Trial 103 finished with value: 0.7854351285275751 and parameters: {'learning_rate': 0.036962323372488184, 'feature_fraction': 0.689284620644073, 'bagging_fraction': 0.6239421196168061, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.689284620644073, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689284620644073\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6239421196168061, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6239421196168061\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.645941375102087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.645941375102087\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7066853338724591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7066853338724591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.645941375102087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.645941375102087\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7066853338724591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7066853338724591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011992 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.645941375102087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.645941375102087\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7066853338724591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7066853338724591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:34,534] Trial 104 finished with value: 0.7897143681140699 and parameters: {'learning_rate': 0.054645506524975136, 'feature_fraction': 0.645941375102087, 'bagging_fraction': 0.7066853338724591, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.645941375102087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.645941375102087\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7066853338724591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7066853338724591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501104339620851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501104339620851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6698875242000862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6698875242000862\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6501104339620851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501104339620851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6698875242000862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6698875242000862\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012334 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501104339620851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501104339620851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6698875242000862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6698875242000862\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:35,776] Trial 105 finished with value: 0.7873654915752569 and parameters: {'learning_rate': 0.0526855662156846, 'feature_fraction': 0.6501104339620851, 'bagging_fraction': 0.6698875242000862, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6501104339620851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501104339620851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6698875242000862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6698875242000862\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6264914367082424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6264914367082424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6161116513602426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6161116513602426\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6264914367082424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6264914367082424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6161116513602426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6161116513602426\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011302 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6264914367082424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6264914367082424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6161116513602426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6161116513602426\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:36,702] Trial 106 finished with value: 0.7838610143327289 and parameters: {'learning_rate': 0.029353020029672994, 'feature_fraction': 0.6264914367082424, 'bagging_fraction': 0.6161116513602426, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6264914367082424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6264914367082424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6161116513602426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6161116513602426\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6662763523350768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6662763523350768\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8215287652793474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8215287652793474\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6662763523350768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6662763523350768\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8215287652793474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8215287652793474\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6662763523350768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6662763523350768\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8215287652793474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8215287652793474\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:37,526] Trial 107 finished with value: 0.7843018812499416 and parameters: {'learning_rate': 0.08472062300795691, 'feature_fraction': 0.6662763523350768, 'bagging_fraction': 0.8215287652793474, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6662763523350768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6662763523350768\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8215287652793474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8215287652793474\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6120431498008827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6120431498008827\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7004977393523678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7004977393523678\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6120431498008827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6120431498008827\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7004977393523678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7004977393523678\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006668 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6120431498008827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6120431498008827\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7004977393523678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7004977393523678\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:38,347] Trial 108 finished with value: 0.7843249254828271 and parameters: {'learning_rate': 0.0445277810363122, 'feature_fraction': 0.6120431498008827, 'bagging_fraction': 0.7004977393523678, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6120431498008827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6120431498008827\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7004977393523678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7004977393523678\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6384459954057814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6384459954057814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8361469394847514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361469394847514\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6384459954057814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6384459954057814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8361469394847514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361469394847514\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6384459954057814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6384459954057814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8361469394847514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361469394847514\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:39,160] Trial 109 finished with value: 0.7885128252767227 and parameters: {'learning_rate': 0.07364095517740005, 'feature_fraction': 0.6384459954057814, 'bagging_fraction': 0.8361469394847514, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6384459954057814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6384459954057814\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8361469394847514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361469394847514\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6437049787093795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6437049787093795\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7112970974824275, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7112970974824275\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6437049787093795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6437049787093795\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7112970974824275, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7112970974824275\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6437049787093795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6437049787093795\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7112970974824275, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7112970974824275\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:39,966] Trial 110 finished with value: 0.7865597488755369 and parameters: {'learning_rate': 0.07133808478662654, 'feature_fraction': 0.6437049787093795, 'bagging_fraction': 0.7112970974824275, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6437049787093795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6437049787093795\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7112970974824275, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7112970974824275\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6155479790292837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155479790292837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6345779433982688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345779433982688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6155479790292837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155479790292837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6345779433982688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345779433982688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6155479790292837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155479790292837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6345779433982688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345779433982688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:40,754] Trial 111 finished with value: 0.785361396932087 and parameters: {'learning_rate': 0.051366930356188265, 'feature_fraction': 0.6155479790292837, 'bagging_fraction': 0.6345779433982688, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6155479790292837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155479790292837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6345779433982688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6345779433982688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6300918649527226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6300918649527226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8328632740476611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8328632740476611\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6300918649527226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6300918649527226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8328632740476611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8328632740476611\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6300918649527226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6300918649527226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8328632740476611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8328632740476611\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:41,571] Trial 112 finished with value: 0.7854791032700448 and parameters: {'learning_rate': 0.07268369221538695, 'feature_fraction': 0.6300918649527226, 'bagging_fraction': 0.8328632740476611, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6300918649527226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6300918649527226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8328632740476611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8328632740476611\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6001975505275249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001975505275249\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.839111412598509, subsample=1.0 will be ignored. Current value: bagging_fraction=0.839111412598509\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6001975505275249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001975505275249\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.839111412598509, subsample=1.0 will be ignored. Current value: bagging_fraction=0.839111412598509\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6001975505275249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001975505275249\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.839111412598509, subsample=1.0 will be ignored. Current value: bagging_fraction=0.839111412598509\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:42,452] Trial 113 finished with value: 0.7700848521691038 and parameters: {'learning_rate': 0.0006331413565839854, 'feature_fraction': 0.6001975505275249, 'bagging_fraction': 0.839111412598509, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6001975505275249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001975505275249\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.839111412598509, subsample=1.0 will be ignored. Current value: bagging_fraction=0.839111412598509\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6595311225696918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6595311225696918\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782147756260076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782147756260076\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6595311225696918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6595311225696918\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782147756260076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782147756260076\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6595311225696918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6595311225696918\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782147756260076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782147756260076\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:43,209] Trial 114 finished with value: 0.7843940184623941 and parameters: {'learning_rate': 0.09986969474640367, 'feature_fraction': 0.6595311225696918, 'bagging_fraction': 0.6782147756260076, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6595311225696918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6595311225696918\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6782147756260076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782147756260076\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6340649950761981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6340649950761981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.658437914126797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.658437914126797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6340649950761981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6340649950761981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.658437914126797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.658437914126797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6340649950761981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6340649950761981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.658437914126797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.658437914126797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:43,998] Trial 115 finished with value: 0.7862292485337589 and parameters: {'learning_rate': 0.08001290474350352, 'feature_fraction': 0.6340649950761981, 'bagging_fraction': 0.658437914126797, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6340649950761981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6340649950761981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.658437914126797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.658437914126797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346994656068353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346994656068353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485352330442928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485352330442928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346994656068353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346994656068353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485352330442928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485352330442928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003642 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346994656068353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346994656068353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485352330442928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485352330442928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:44,782] Trial 116 finished with value: 0.7861720091232619 and parameters: {'learning_rate': 0.055398636761082934, 'feature_fraction': 0.7346994656068353, 'bagging_fraction': 0.6485352330442928, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7346994656068353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346994656068353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485352330442928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485352330442928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7147628437338761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7147628437338761\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85248732919191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85248732919191\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7147628437338761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7147628437338761\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85248732919191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85248732919191\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006643 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7147628437338761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7147628437338761\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85248732919191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85248732919191\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:45,680] Trial 117 finished with value: 0.7850359363077131 and parameters: {'learning_rate': 0.03782893241319804, 'feature_fraction': 0.7147628437338761, 'bagging_fraction': 0.85248732919191, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7147628437338761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7147628437338761\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85248732919191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85248732919191\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7021253977257159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7021253977257159\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107641339788814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107641339788814\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7021253977257159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7021253977257159\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107641339788814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107641339788814\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003668 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7021253977257159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7021253977257159\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107641339788814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107641339788814\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:46,664] Trial 118 finished with value: 0.7878968295154546 and parameters: {'learning_rate': 0.04695206049276233, 'feature_fraction': 0.7021253977257159, 'bagging_fraction': 0.8107641339788814, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7021253977257159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7021253977257159\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8107641339788814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8107641339788814\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7238807780876618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7238807780876618\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8739203376981594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739203376981594\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7238807780876618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7238807780876618\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8739203376981594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739203376981594\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010009 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7238807780876618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7238807780876618\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8739203376981594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739203376981594\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:47,917] Trial 119 finished with value: 0.7696064292184029 and parameters: {'learning_rate': 0.00015193898276614378, 'feature_fraction': 0.7238807780876618, 'bagging_fraction': 0.8739203376981594, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7238807780876618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7238807780876618\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8739203376981594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739203376981594\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6889960397531243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6889960397531243\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8239605761687502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8239605761687502\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6889960397531243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6889960397531243\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8239605761687502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8239605761687502\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6889960397531243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6889960397531243\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8239605761687502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8239605761687502\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:49,129] Trial 120 finished with value: 0.785932366002974 and parameters: {'learning_rate': 0.059257927000378206, 'feature_fraction': 0.6889960397531243, 'bagging_fraction': 0.8239605761687502, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6889960397531243, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6889960397531243\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8239605761687502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8239605761687502\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7057986662418442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7057986662418442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6878110310029228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6878110310029228\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7057986662418442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7057986662418442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6878110310029228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6878110310029228\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014924 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7057986662418442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7057986662418442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6878110310029228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6878110310029228\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:50,257] Trial 121 finished with value: 0.7873592255395417 and parameters: {'learning_rate': 0.0661312439113341, 'feature_fraction': 0.7057986662418442, 'bagging_fraction': 0.6878110310029228, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7057986662418442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7057986662418442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6878110310029228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6878110310029228\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7281902631818152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7281902631818152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6647848312104021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6647848312104021\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7281902631818152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7281902631818152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6647848312104021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6647848312104021\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017443 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7281902631818152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7281902631818152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6647848312104021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6647848312104021\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:51,483] Trial 122 finished with value: 0.7844712867972874 and parameters: {'learning_rate': 0.08263330159846811, 'feature_fraction': 0.7281902631818152, 'bagging_fraction': 0.6647848312104021, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7281902631818152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7281902631818152\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6647848312104021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6647848312104021\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7435970301364764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7435970301364764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6759524086359259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6759524086359259\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7435970301364764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7435970301364764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6759524086359259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6759524086359259\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012126 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7435970301364764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7435970301364764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6759524086359259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6759524086359259\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:52,731] Trial 123 finished with value: 0.789130100332102 and parameters: {'learning_rate': 0.05874542609145147, 'feature_fraction': 0.7435970301364764, 'bagging_fraction': 0.6759524086359259, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7435970301364764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7435970301364764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6759524086359259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6759524086359259\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7500936548247411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7500936548247411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7233861180428153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233861180428153\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7500936548247411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7500936548247411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7233861180428153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233861180428153\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011733 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7500936548247411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7500936548247411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7233861180428153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233861180428153\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:54,084] Trial 124 finished with value: 0.7880518041839945 and parameters: {'learning_rate': 0.04083270561801342, 'feature_fraction': 0.7500936548247411, 'bagging_fraction': 0.7233861180428153, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7500936548247411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7500936548247411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7233861180428153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7233861180428153\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7642562616714906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7642562616714906\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6959198112011074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6959198112011074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7642562616714906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7642562616714906\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6959198112011074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6959198112011074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7642562616714906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7642562616714906\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6959198112011074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6959198112011074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:57:55,034] Trial 125 finished with value: 0.788801445191746 and parameters: {'learning_rate': 0.07175400433857011, 'feature_fraction': 0.7642562616714906, 'bagging_fraction': 0.6959198112011074, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7642562616714906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7642562616714906\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6959198112011074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6959198112011074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7636695651125842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636695651125842\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6787509374551336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6787509374551336\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7636695651125842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636695651125842\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6787509374551336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6787509374551336\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7636695651125842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636695651125842\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6787509374551336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6787509374551336\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:55,910] Trial 126 finished with value: 0.7837477460189326 and parameters: {'learning_rate': 0.03254871671939265, 'feature_fraction': 0.7636695651125842, 'bagging_fraction': 0.6787509374551336, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7636695651125842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636695651125842\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6787509374551336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6787509374551336\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417352720558844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417352720558844\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6987601340486846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6987601340486846\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417352720558844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417352720558844\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6987601340486846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6987601340486846\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417352720558844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417352720558844\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6987601340486846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6987601340486846\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:56,750] Trial 127 finished with value: 0.7892319238605269 and parameters: {'learning_rate': 0.05381368487784647, 'feature_fraction': 0.7417352720558844, 'bagging_fraction': 0.6987601340486846, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7417352720558844, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417352720558844\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6987601340486846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6987601340486846\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417458300420638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417458300420638\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302643274833163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302643274833163\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417458300420638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417458300420638\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302643274833163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302643274833163\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7417458300420638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417458300420638\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302643274833163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302643274833163\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:57,620] Trial 128 finished with value: 0.778977841275797 and parameters: {'learning_rate': 0.024173460837274206, 'feature_fraction': 0.7417458300420638, 'bagging_fraction': 0.7302643274833163, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7417458300420638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417458300420638\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302643274833163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302643274833163\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7849191300053244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849191300053244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7034508914211345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7034508914211345\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7849191300053244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849191300053244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7034508914211345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7034508914211345\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003687 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7849191300053244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849191300053244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7034508914211345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7034508914211345\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:58,430] Trial 129 finished with value: 0.7878232492509765 and parameters: {'learning_rate': 0.048922308525168955, 'feature_fraction': 0.7849191300053244, 'bagging_fraction': 0.7034508914211345, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7849191300053244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849191300053244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7034508914211345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7034508914211345\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7737078568986683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7737078568986683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6948513751367411, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6948513751367411\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7737078568986683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7737078568986683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6948513751367411, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6948513751367411\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004075 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7737078568986683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7737078568986683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6948513751367411, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6948513751367411\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:59,190] Trial 130 finished with value: 0.7879619897864263 and parameters: {'learning_rate': 0.05706718958610513, 'feature_fraction': 0.7737078568986683, 'bagging_fraction': 0.6948513751367411, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7737078568986683, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7737078568986683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6948513751367411, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6948513751367411\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7551949803646896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7551949803646896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6716889935926172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6716889935926172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7551949803646896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7551949803646896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6716889935926172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6716889935926172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004148 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7551949803646896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7551949803646896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6716889935926172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6716889935926172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:57:59,973] Trial 131 finished with value: 0.7875070907354407 and parameters: {'learning_rate': 0.07272862879703247, 'feature_fraction': 0.7551949803646896, 'bagging_fraction': 0.6716889935926172, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7551949803646896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7551949803646896\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6716889935926172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6716889935926172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7360351782884604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7360351782884604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6981987620594369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6981987620594369\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7360351782884604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7360351782884604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6981987620594369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6981987620594369\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007473 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7360351782884604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7360351782884604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6981987620594369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6981987620594369\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:00,822] Trial 132 finished with value: 0.7880777709645831 and parameters: {'learning_rate': 0.04342939373375112, 'feature_fraction': 0.7360351782884604, 'bagging_fraction': 0.6981987620594369, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7360351782884604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7360351782884604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6981987620594369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6981987620594369\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.756322684591264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.756322684591264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6756266254485087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6756266254485087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.756322684591264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.756322684591264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6756266254485087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6756266254485087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003699 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.756322684591264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.756322684591264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6756266254485087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6756266254485087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:01,612] Trial 133 finished with value: 0.7879853909660386 and parameters: {'learning_rate': 0.059012978740467355, 'feature_fraction': 0.756322684591264, 'bagging_fraction': 0.6756266254485087, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.756322684591264, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.756322684591264\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6756266254485087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6756266254485087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7412736014789657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7412736014789657\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7090526350737708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7090526350737708\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7412736014789657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7412736014789657\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7090526350737708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7090526350737708\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7412736014789657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7412736014789657\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7090526350737708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7090526350737708\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:02,452] Trial 134 finished with value: 0.7696927540133555 and parameters: {'learning_rate': 0.0018576576210901164, 'feature_fraction': 0.7412736014789657, 'bagging_fraction': 0.7090526350737708, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7412736014789657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7412736014789657\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7090526350737708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7090526350737708\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272549134770572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272549134770572\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351740678912953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351740678912953\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272549134770572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272549134770572\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351740678912953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351740678912953\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272549134770572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272549134770572\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351740678912953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351740678912953\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:03,297] Trial 135 finished with value: 0.7885497372303023 and parameters: {'learning_rate': 0.06689956350596708, 'feature_fraction': 0.7272549134770572, 'bagging_fraction': 0.8351740678912953, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7272549134770572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272549134770572\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351740678912953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351740678912953\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7274837095833163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274837095833163\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.846267080516178, subsample=1.0 will be ignored. Current value: bagging_fraction=0.846267080516178\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7274837095833163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274837095833163\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.846267080516178, subsample=1.0 will be ignored. Current value: bagging_fraction=0.846267080516178\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7274837095833163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274837095833163\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.846267080516178, subsample=1.0 will be ignored. Current value: bagging_fraction=0.846267080516178\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:04,202] Trial 136 finished with value: 0.7704120082642124 and parameters: {'learning_rate': 0.007777129914727562, 'feature_fraction': 0.7274837095833163, 'bagging_fraction': 0.846267080516178, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7274837095833163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274837095833163\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.846267080516178, subsample=1.0 will be ignored. Current value: bagging_fraction=0.846267080516178\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7454413366067176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7454413366067176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6548615601162404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6548615601162404\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7454413366067176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7454413366067176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6548615601162404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6548615601162404\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010012 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7454413366067176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7454413366067176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6548615601162404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6548615601162404\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:05,266] Trial 137 finished with value: 0.7826228738608543 and parameters: {'learning_rate': 0.051160341323520805, 'feature_fraction': 0.7454413366067176, 'bagging_fraction': 0.6548615601162404, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7454413366067176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7454413366067176\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6548615601162404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6548615601162404\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7640480765193446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640480765193446\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6658584193576923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6658584193576923\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7640480765193446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640480765193446\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6658584193576923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6658584193576923\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013897 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7640480765193446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640480765193446\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6658584193576923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6658584193576923\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:06,473] Trial 138 finished with value: 0.7837332083365176 and parameters: {'learning_rate': 0.035043418233143935, 'feature_fraction': 0.7640480765193446, 'bagging_fraction': 0.6658584193576923, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7640480765193446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640480765193446\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6658584193576923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6658584193576923\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7191831488672327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191831488672327\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8165466756954696, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8165466756954696\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7191831488672327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191831488672327\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8165466756954696, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8165466756954696\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009678 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7191831488672327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191831488672327\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8165466756954696, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8165466756954696\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:07,652] Trial 139 finished with value: 0.7860784774673213 and parameters: {'learning_rate': 0.06599457162834771, 'feature_fraction': 0.7191831488672327, 'bagging_fraction': 0.8165466756954696, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7191831488672327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191831488672327\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8165466756954696, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8165466756954696\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979966991275468, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979966991275468\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857096950996594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857096950996594\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6979966991275468, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979966991275468\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857096950996594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857096950996594\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008313 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979966991275468, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979966991275468\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857096950996594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857096950996594\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:08,932] Trial 140 finished with value: 0.7847094131955561 and parameters: {'learning_rate': 0.028391131651351466, 'feature_fraction': 0.6979966991275468, 'bagging_fraction': 0.6857096950996594, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6979966991275468, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979966991275468\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857096950996594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857096950996594\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358467438611919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358467438611919\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303045579528703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303045579528703\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358467438611919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358467438611919\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303045579528703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303045579528703\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010624 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358467438611919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358467438611919\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303045579528703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303045579528703\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:10,168] Trial 141 finished with value: 0.7867963102950989 and parameters: {'learning_rate': 0.07542194071476069, 'feature_fraction': 0.7358467438611919, 'bagging_fraction': 0.8303045579528703, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7358467438611919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358467438611919\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303045579528703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303045579528703\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7252583332129837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7252583332129837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8357751887104704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8357751887104704\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7252583332129837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7252583332129837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8357751887104704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8357751887104704\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011958 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7252583332129837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7252583332129837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8357751887104704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8357751887104704\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:11,421] Trial 142 finished with value: 0.7869018219329381 and parameters: {'learning_rate': 0.090623870772956, 'feature_fraction': 0.7252583332129837, 'bagging_fraction': 0.8357751887104704, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7252583332129837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7252583332129837\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8357751887104704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8357751887104704\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7479581842866038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479581842866038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8611910035914413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8611910035914413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7479581842866038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479581842866038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8611910035914413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8611910035914413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011525 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7479581842866038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479581842866038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8611910035914413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8611910035914413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:13,579] Trial 143 finished with value: 0.7896734510108917 and parameters: {'learning_rate': 0.06668257712082398, 'feature_fraction': 0.7479581842866038, 'bagging_fraction': 0.8611910035914413, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7479581842866038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7479581842866038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8611910035914413, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8611910035914413\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7497527252776142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7497527252776142\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.86630225560584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86630225560584\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7497527252776142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7497527252776142\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.86630225560584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86630225560584\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7497527252776142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7497527252776142\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.86630225560584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86630225560584\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:14,655] Trial 144 finished with value: 0.7889717708319364 and parameters: {'learning_rate': 0.05334312112225956, 'feature_fraction': 0.7497527252776142, 'bagging_fraction': 0.86630225560584, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7497527252776142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7497527252776142\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.86630225560584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86630225560584\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7483658840149798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7483658840149798\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7180237500185896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7180237500185896\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7483658840149798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7483658840149798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.7180237500185896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7180237500185896\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011313 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7483658840149798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7483658840149798\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7180237500185896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7180237500185896\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:15,745] Trial 145 finished with value: 0.7878491996861836 and parameters: {'learning_rate': 0.04663413875488532, 'feature_fraction': 0.7483658840149798, 'bagging_fraction': 0.7180237500185896, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7483658840149798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7483658840149798\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7180237500185896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7180237500185896\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7721151237316215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7721151237316215\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8947891660181481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8947891660181481\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7721151237316215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7721151237316215\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8947891660181481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8947891660181481\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7721151237316215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7721151237316215\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8947891660181481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8947891660181481\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:16,752] Trial 146 finished with value: 0.7871313123276522 and parameters: {'learning_rate': 0.055304299388836325, 'feature_fraction': 0.7721151237316215, 'bagging_fraction': 0.8947891660181481, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7721151237316215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7721151237316215\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8947891660181481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8947891660181481\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385386780994407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385386780994407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8811738255215026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8811738255215026\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385386780994407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385386780994407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8811738255215026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8811738255215026\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003582 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385386780994407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385386780994407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8811738255215026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8811738255215026\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:17,628] Trial 147 finished with value: 0.7847179870970613 and parameters: {'learning_rate': 0.03756313782514327, 'feature_fraction': 0.7385386780994407, 'bagging_fraction': 0.8811738255215026, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7385386780994407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385386780994407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8811738255215026, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8811738255215026\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7516577590583351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7516577590583351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9067643865463227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067643865463227\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7516577590583351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7516577590583351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9067643865463227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067643865463227\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7516577590583351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7516577590583351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9067643865463227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067643865463227\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:18,566] Trial 148 finished with value: 0.7860493968185589 and parameters: {'learning_rate': 0.04109175260779905, 'feature_fraction': 0.7516577590583351, 'bagging_fraction': 0.9067643865463227, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7516577590583351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7516577590583351\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9067643865463227, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067643865463227\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7967395508685089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7967395508685089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8589683782709904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8589683782709904\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7967395508685089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7967395508685089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8589683782709904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8589683782709904\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7967395508685089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7967395508685089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8589683782709904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8589683782709904\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:19,395] Trial 149 finished with value: 0.787088269817898 and parameters: {'learning_rate': 0.058460375944274695, 'feature_fraction': 0.7967395508685089, 'bagging_fraction': 0.8589683782709904, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7967395508685089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7967395508685089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8589683782709904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8589683782709904\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7610770068238936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7610770068238936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924518548855448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924518548855448\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7610770068238936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7610770068238936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924518548855448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924518548855448\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7610770068238936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7610770068238936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924518548855448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924518548855448\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:20,203] Trial 150 finished with value: 0.7864171416876071 and parameters: {'learning_rate': 0.09970440311884601, 'feature_fraction': 0.7610770068238936, 'bagging_fraction': 0.7924518548855448, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7610770068238936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7610770068238936\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7924518548855448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7924518548855448\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156966480662192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156966480662192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8688110698078241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8688110698078241\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156966480662192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156966480662192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8688110698078241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8688110698078241\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008639 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156966480662192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156966480662192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8688110698078241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8688110698078241\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:21,067] Trial 151 finished with value: 0.7905394097296805 and parameters: {'learning_rate': 0.06787142514948104, 'feature_fraction': 0.7156966480662192, 'bagging_fraction': 0.8688110698078241, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7156966480662192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156966480662192\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8688110698078241, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8688110698078241\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7145414762889304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7145414762889304\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8646632980225698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8646632980225698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7145414762889304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7145414762889304\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8646632980225698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8646632980225698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7145414762889304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7145414762889304\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8646632980225698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8646632980225698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:21,969] Trial 152 finished with value: 0.7879988649608254 and parameters: {'learning_rate': 0.05056420790531147, 'feature_fraction': 0.7145414762889304, 'bagging_fraction': 0.8646632980225698, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7145414762889304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7145414762889304\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8646632980225698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8646632980225698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7093459033638402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7093459033638402\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8679091032212024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8679091032212024\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7093459033638402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7093459033638402\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8679091032212024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8679091032212024\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7093459033638402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7093459033638402\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8679091032212024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8679091032212024\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:22,855] Trial 153 finished with value: 0.7877990169319038 and parameters: {'learning_rate': 0.06367474581350958, 'feature_fraction': 0.7093459033638402, 'bagging_fraction': 0.8679091032212024, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7093459033638402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7093459033638402\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8679091032212024, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8679091032212024\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7183772531281486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183772531281486\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734690919506728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734690919506728\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7183772531281486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183772531281486\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734690919506728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734690919506728\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7183772531281486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183772531281486\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734690919506728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734690919506728\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:23,722] Trial 154 finished with value: 0.7865999761000938 and parameters: {'learning_rate': 0.0841232066410783, 'feature_fraction': 0.7183772531281486, 'bagging_fraction': 0.8734690919506728, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7183772531281486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183772531281486\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734690919506728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734690919506728\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7338520070563328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7338520070563328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.659856727647368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.659856727647368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7338520070563328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7338520070563328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.659856727647368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.659856727647368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7338520070563328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7338520070563328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.659856727647368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.659856727647368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:24,886] Trial 155 finished with value: 0.7864740225205069 and parameters: {'learning_rate': 0.04501925890482142, 'feature_fraction': 0.7338520070563328, 'bagging_fraction': 0.659856727647368, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7338520070563328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7338520070563328\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.659856727647368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.659856727647368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7809809662912944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7809809662912944\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8509473580037095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8509473580037095\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7809809662912944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7809809662912944\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8509473580037095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8509473580037095\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010559 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7809809662912944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7809809662912944\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8509473580037095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8509473580037095\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:26,094] Trial 156 finished with value: 0.7881440398038116 and parameters: {'learning_rate': 0.0680022022146534, 'feature_fraction': 0.7809809662912944, 'bagging_fraction': 0.8509473580037095, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7809809662912944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7809809662912944\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8509473580037095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8509473580037095\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465890480601775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465890480601775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8886549989413736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886549989413736\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465890480601775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465890480601775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8886549989413736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886549989413736\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012241 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7465890480601775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465890480601775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8886549989413736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886549989413736\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:27,299] Trial 157 finished with value: 0.7871381546046329 and parameters: {'learning_rate': 0.05322333879920578, 'feature_fraction': 0.7465890480601775, 'bagging_fraction': 0.8886549989413736, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7465890480601775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7465890480601775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8886549989413736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886549989413736\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6960011217615426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6960011217615426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6516431641166515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6516431641166515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6960011217615426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6960011217615426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6516431641166515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6516431641166515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6960011217615426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6960011217615426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6516431641166515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6516431641166515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:28,456] Trial 158 finished with value: 0.7887858947730377 and parameters: {'learning_rate': 0.07522944365434918, 'feature_fraction': 0.6960011217615426, 'bagging_fraction': 0.6516431641166515, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6960011217615426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6960011217615426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6516431641166515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6516431641166515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6779643106711005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6779643106711005\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6519221001387338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519221001387338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6779643106711005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6779643106711005\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6519221001387338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519221001387338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010542 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6779643106711005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6779643106711005\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6519221001387338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519221001387338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:29,603] Trial 159 finished with value: 0.7897400777720938 and parameters: {'learning_rate': 0.07916233325501214, 'feature_fraction': 0.6779643106711005, 'bagging_fraction': 0.6519221001387338, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 72 with value: 0.7905655863734544.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6779643106711005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6779643106711005\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6519221001387338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519221001387338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6874640457051617, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6874640457051617\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6375279654653782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6375279654653782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6874640457051617, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6874640457051617\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6375279654653782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6375279654653782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005322 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6874640457051617, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6874640457051617\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6375279654653782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6375279654653782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:30,775] Trial 160 finished with value: 0.7914369906862723 and parameters: {'learning_rate': 0.08719244695498335, 'feature_fraction': 0.6874640457051617, 'bagging_fraction': 0.6375279654653782, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6874640457051617, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6874640457051617\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6375279654653782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6375279654653782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6943227626167345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6943227626167345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329740136074006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329740136074006\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6943227626167345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6943227626167345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329740136074006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329740136074006\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015292 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6943227626167345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6943227626167345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329740136074006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329740136074006\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:31,946] Trial 161 finished with value: 0.7858045537175606 and parameters: {'learning_rate': 0.08746479832004986, 'feature_fraction': 0.6943227626167345, 'bagging_fraction': 0.6329740136074006, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6943227626167345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6943227626167345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329740136074006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329740136074006\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6849902675227875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6849902675227875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454938220042145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454938220042145\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6849902675227875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6849902675227875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454938220042145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454938220042145\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012201 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6849902675227875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6849902675227875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454938220042145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454938220042145\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:32,906] Trial 162 finished with value: 0.7880782989092311 and parameters: {'learning_rate': 0.07671610805975668, 'feature_fraction': 0.6849902675227875, 'bagging_fraction': 0.6454938220042145, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6849902675227875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6849902675227875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6454938220042145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6454938220042145\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6790435716615089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790435716615089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6526778390451071, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6526778390451071\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6790435716615089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790435716615089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6526778390451071, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6526778390451071\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6790435716615089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790435716615089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6526778390451071, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6526778390451071\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:33,665] Trial 163 finished with value: 0.7864565260864371 and parameters: {'learning_rate': 0.09985046256195773, 'feature_fraction': 0.6790435716615089, 'bagging_fraction': 0.6526778390451071, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6790435716615089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790435716615089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6526778390451071, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6526778390451071\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.672019574040846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.672019574040846\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6396186195301313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6396186195301313\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.672019574040846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.672019574040846\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6396186195301313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6396186195301313\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.672019574040846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.672019574040846\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6396186195301313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6396186195301313\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:34,456] Trial 164 finished with value: 0.7846428057799636 and parameters: {'learning_rate': 0.07756063934002715, 'feature_fraction': 0.672019574040846, 'bagging_fraction': 0.6396186195301313, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.672019574040846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.672019574040846\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6396186195301313, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6396186195301313\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979511529953463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979511529953463\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6696575761330016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6696575761330016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979511529953463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979511529953463\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6696575761330016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6696575761330016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979511529953463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979511529953463\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6696575761330016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6696575761330016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:35,254] Trial 165 finished with value: 0.7874624877919754 and parameters: {'learning_rate': 0.08724056817476572, 'feature_fraction': 0.6979511529953463, 'bagging_fraction': 0.6696575761330016, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6979511529953463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979511529953463\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6696575761330016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6696575761330016\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.68949454298567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68949454298567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650745164333355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650745164333355\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.68949454298567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68949454298567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650745164333355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650745164333355\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.68949454298567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68949454298567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650745164333355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650745164333355\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:36,108] Trial 166 finished with value: 0.7844901793644197 and parameters: {'learning_rate': 0.06083550411786456, 'feature_fraction': 0.68949454298567, 'bagging_fraction': 0.650745164333355, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.68949454298567, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68949454298567\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650745164333355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650745164333355\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6745367873457553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6745367873457553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6234529734208132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6234529734208132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6745367873457553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6745367873457553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6234529734208132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6234529734208132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6745367873457553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6745367873457553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6234529734208132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6234529734208132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:36,920] Trial 167 finished with value: 0.7886105132833203 and parameters: {'learning_rate': 0.07117090959449121, 'feature_fraction': 0.6745367873457553, 'bagging_fraction': 0.6234529734208132, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6745367873457553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6745367873457553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6234529734208132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6234529734208132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7032212200073966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7032212200073966\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6815325722566826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6815325722566826\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7032212200073966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7032212200073966\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6815325722566826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6815325722566826\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7032212200073966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7032212200073966\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6815325722566826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6815325722566826\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:37,733] Trial 168 finished with value: 0.7875201358481586 and parameters: {'learning_rate': 0.06525385486195516, 'feature_fraction': 0.7032212200073966, 'bagging_fraction': 0.6815325722566826, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7032212200073966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7032212200073966\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6815325722566826, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6815325722566826\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6895076746720763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6895076746720763\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585104036581924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585104036581924\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6895076746720763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6895076746720763\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585104036581924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585104036581924\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6895076746720763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6895076746720763\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585104036581924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585104036581924\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:38,533] Trial 169 finished with value: 0.7859534864418265 and parameters: {'learning_rate': 0.07992328428150407, 'feature_fraction': 0.6895076746720763, 'bagging_fraction': 0.6585104036581924, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6895076746720763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6895076746720763\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585104036581924, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585104036581924\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9845050295304725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9845050295304725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6362956415459344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6362956415459344\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9845050295304725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9845050295304725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6362956415459344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6362956415459344\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9845050295304725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9845050295304725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6362956415459344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6362956415459344\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:39,361] Trial 170 finished with value: 0.7871811163941527 and parameters: {'learning_rate': 0.058591528466657085, 'feature_fraction': 0.9845050295304725, 'bagging_fraction': 0.6362956415459344, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9845050295304725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9845050295304725\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6362956415459344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6362956415459344\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7029994813484678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7029994813484678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6929052014586132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6929052014586132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7029994813484678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7029994813484678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6929052014586132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6929052014586132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7029994813484678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7029994813484678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6929052014586132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6929052014586132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:40,169] Trial 171 finished with value: 0.7853121187547398 and parameters: {'learning_rate': 0.07199377851666568, 'feature_fraction': 0.7029994813484678, 'bagging_fraction': 0.6929052014586132, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7029994813484678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7029994813484678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6929052014586132, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6929052014586132\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7114391172645037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7114391172645037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6713317670793504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6713317670793504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7114391172645037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7114391172645037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6713317670793504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6713317670793504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004758 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7114391172645037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7114391172645037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6713317670793504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6713317670793504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:40,964] Trial 172 finished with value: 0.7857223619627411 and parameters: {'learning_rate': 0.05293462588859752, 'feature_fraction': 0.7114391172645037, 'bagging_fraction': 0.6713317670793504, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7114391172645037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7114391172645037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6713317670793504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6713317670793504\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501147060921851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501147060921851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6628511319349304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6628511319349304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501147060921851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501147060921851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6628511319349304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6628511319349304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6501147060921851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501147060921851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6628511319349304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6628511319349304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:41,764] Trial 173 finished with value: 0.7803844062040819 and parameters: {'learning_rate': 0.08395449590130544, 'feature_fraction': 0.6501147060921851, 'bagging_fraction': 0.6628511319349304, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6501147060921851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501147060921851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6628511319349304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6628511319349304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813876251351113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813876251351113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6100127459045661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6100127459045661\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813876251351113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813876251351113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6100127459045661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6100127459045661\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813876251351113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813876251351113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6100127459045661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6100127459045661\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:42,560] Trial 174 finished with value: 0.7879975198644682 and parameters: {'learning_rate': 0.06329605522021421, 'feature_fraction': 0.6813876251351113, 'bagging_fraction': 0.6100127459045661, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6813876251351113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813876251351113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6100127459045661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6100127459045661\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.658287991082543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.658287991082543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6538276518583942, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6538276518583942\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.658287991082543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.658287991082543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6538276518583942, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6538276518583942\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012874 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.658287991082543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.658287991082543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6538276518583942, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6538276518583942\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:43,639] Trial 175 finished with value: 0.784849833337765 and parameters: {'learning_rate': 0.08925402168401257, 'feature_fraction': 0.658287991082543, 'bagging_fraction': 0.6538276518583942, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.658287991082543, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.658287991082543\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6538276518583942, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6538276518583942\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7218876323995447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7218876323995447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9965368721779246, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9965368721779246\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7218876323995447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7218876323995447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9965368721779246, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9965368721779246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011694 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7218876323995447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7218876323995447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9965368721779246, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9965368721779246\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:44,928] Trial 176 finished with value: 0.7881889014534241 and parameters: {'learning_rate': 0.049976152670696695, 'feature_fraction': 0.7218876323995447, 'bagging_fraction': 0.9965368721779246, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7218876323995447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7218876323995447\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9965368721779246, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9965368721779246\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7573208890097013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573208890097013\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6266418428786362, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6266418428786362\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7573208890097013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573208890097013\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6266418428786362, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6266418428786362\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7573208890097013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573208890097013\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6266418428786362, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6266418428786362\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:46,028] Trial 177 finished with value: 0.7812957083918552 and parameters: {'learning_rate': 0.07420687964699735, 'feature_fraction': 0.7573208890097013, 'bagging_fraction': 0.6266418428786362, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7573208890097013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573208890097013\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6266418428786362, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6266418428786362\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7113763675691116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113763675691116\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6448892578485793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6448892578485793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7113763675691116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113763675691116\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6448892578485793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6448892578485793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010194 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7113763675691116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113763675691116\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6448892578485793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6448892578485793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:47,248] Trial 178 finished with value: 0.7731738915644797 and parameters: {'learning_rate': 0.003383821751175745, 'feature_fraction': 0.7113763675691116, 'bagging_fraction': 0.6448892578485793, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7113763675691116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113763675691116\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6448892578485793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6448892578485793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6962771719982128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6962771719982128\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6765373605792864, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6765373605792864\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6962771719982128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6962771719982128\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6765373605792864, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6765373605792864\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6962771719982128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6962771719982128\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6765373605792864, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6765373605792864\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:48,521] Trial 179 finished with value: 0.7864338965716209 and parameters: {'learning_rate': 0.05877184022370328, 'feature_fraction': 0.6962771719982128, 'bagging_fraction': 0.6765373605792864, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6962771719982128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6962771719982128\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6765373605792864, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6765373605792864\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8088654744942932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8088654744942932\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6675241512688286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6675241512688286\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8088654744942932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8088654744942932\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6675241512688286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6675241512688286\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010918 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8088654744942932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8088654744942932\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6675241512688286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6675241512688286\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:49,836] Trial 180 finished with value: 0.788812414236123 and parameters: {'learning_rate': 0.06624936364171202, 'feature_fraction': 0.8088654744942932, 'bagging_fraction': 0.6675241512688286, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8088654744942932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8088654744942932\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6675241512688286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6675241512688286\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8033585722661952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8033585722661952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6668490710687427, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668490710687427\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8033585722661952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8033585722661952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6668490710687427, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668490710687427\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010264 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8033585722661952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8033585722661952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6668490710687427, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668490710687427\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:51,078] Trial 181 finished with value: 0.7846265304642436 and parameters: {'learning_rate': 0.06720325089931464, 'feature_fraction': 0.8033585722661952, 'bagging_fraction': 0.6668490710687427, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8033585722661952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8033585722661952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6668490710687427, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668490710687427\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8234903062037358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8234903062037358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857407279387587, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857407279387587\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8234903062037358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8234903062037358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857407279387587, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857407279387587\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8234903062037358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8234903062037358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857407279387587, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857407279387587\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:51,924] Trial 182 finished with value: 0.786088033988941 and parameters: {'learning_rate': 0.05319373228708913, 'feature_fraction': 0.8234903062037358, 'bagging_fraction': 0.6857407279387587, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8234903062037358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8234903062037358\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6857407279387587, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6857407279387587\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272852424251676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272852424251676\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6576057603814857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6576057603814857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272852424251676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272852424251676\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6576057603814857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6576057603814857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7272852424251676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272852424251676\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6576057603814857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6576057603814857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:52,786] Trial 183 finished with value: 0.7878456196365745 and parameters: {'learning_rate': 0.0446388877618282, 'feature_fraction': 0.7272852424251676, 'bagging_fraction': 0.6576057603814857, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7272852424251676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272852424251676\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6576057603814857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6576057603814857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7411624736767046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7411624736767046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7030120283629859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7030120283629859\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7411624736767046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7411624736767046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7030120283629859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7030120283629859\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7411624736767046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7411624736767046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7030120283629859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7030120283629859\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:53,495] Trial 184 finished with value: 0.7820064473225912 and parameters: {'learning_rate': 0.09963982150866474, 'feature_fraction': 0.7411624736767046, 'bagging_fraction': 0.7030120283629859, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7411624736767046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7411624736767046\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7030120283629859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7030120283629859\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6650343653145225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650343653145225\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6496568947246688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6496568947246688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6650343653145225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650343653145225\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6496568947246688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6496568947246688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006145 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6650343653145225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650343653145225\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6496568947246688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6496568947246688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:54,287] Trial 185 finished with value: 0.7860271145728988 and parameters: {'learning_rate': 0.07612848492007761, 'feature_fraction': 0.6650343653145225, 'bagging_fraction': 0.6496568947246688, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6650343653145225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6650343653145225\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6496568947246688, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6496568947246688\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175475031757143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175475031757143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.642133198320111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.642133198320111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175475031757143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175475031757143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.642133198320111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.642133198320111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003469 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175475031757143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175475031757143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.642133198320111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.642133198320111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:58:55,099] Trial 186 finished with value: 0.7877860971734058 and parameters: {'learning_rate': 0.06095160441991459, 'feature_fraction': 0.7175475031757143, 'bagging_fraction': 0.642133198320111, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7175475031757143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175475031757143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.642133198320111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.642133198320111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7045672163451008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7045672163451008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8797348940807695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8797348940807695\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7045672163451008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7045672163451008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8797348940807695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8797348940807695\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7045672163451008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7045672163451008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8797348940807695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8797348940807695\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:55,946] Trial 187 finished with value: 0.7864724370121066 and parameters: {'learning_rate': 0.08561330683058788, 'feature_fraction': 0.7045672163451008, 'bagging_fraction': 0.8797348940807695, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7045672163451008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7045672163451008\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8797348940807695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8797348940807695\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8304133475215982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8304133475215982\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6780701632193986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780701632193986\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8304133475215982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8304133475215982\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6780701632193986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780701632193986\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8304133475215982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8304133475215982\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6780701632193986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780701632193986\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:56,741] Trial 188 finished with value: 0.7862863448244879 and parameters: {'learning_rate': 0.06523434691238854, 'feature_fraction': 0.8304133475215982, 'bagging_fraction': 0.6780701632193986, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8304133475215982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8304133475215982\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6780701632193986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6780701632193986\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6828598788988028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6828598788988028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8615848870856311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8615848870856311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6828598788988028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6828598788988028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8615848870856311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8615848870856311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6828598788988028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6828598788988028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8615848870856311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8615848870856311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:57,643] Trial 189 finished with value: 0.785815709824004 and parameters: {'learning_rate': 0.039304162901208126, 'feature_fraction': 0.6828598788988028, 'bagging_fraction': 0.8615848870856311, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6828598788988028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6828598788988028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8615848870856311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8615848870856311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319763234621492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319763234621492\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664127525834816, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664127525834816\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319763234621492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319763234621492\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664127525834816, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664127525834816\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003646 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319763234621492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319763234621492\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664127525834816, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664127525834816\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:58,463] Trial 190 finished with value: 0.7869586410100211 and parameters: {'learning_rate': 0.04783050733604985, 'feature_fraction': 0.7319763234621492, 'bagging_fraction': 0.664127525834816, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7319763234621492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319763234621492\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664127525834816, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664127525834816\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486774087531182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486774087531182\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8129656150040976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8129656150040976\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486774087531182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486774087531182\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8129656150040976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8129656150040976\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486774087531182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486774087531182\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8129656150040976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8129656150040976\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:58:59,362] Trial 191 finished with value: 0.7864937644243499 and parameters: {'learning_rate': 0.05539689431230785, 'feature_fraction': 0.7486774087531182, 'bagging_fraction': 0.8129656150040976, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7486774087531182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486774087531182\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8129656150040976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8129656150040976\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8160024872425342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8160024872425342\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8244137347214994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8244137347214994\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8160024872425342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8160024872425342\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8244137347214994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8244137347214994\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8160024872425342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8160024872425342\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8244137347214994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8244137347214994\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:00,231] Trial 192 finished with value: 0.7894488255975032 and parameters: {'learning_rate': 0.043401476136423436, 'feature_fraction': 0.8160024872425342, 'bagging_fraction': 0.8244137347214994, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8160024872425342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8160024872425342\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8244137347214994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8244137347214994\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8185746220151879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8185746220151879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6951431638772219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6951431638772219\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8185746220151879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8185746220151879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6951431638772219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6951431638772219\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8185746220151879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8185746220151879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6951431638772219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6951431638772219\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:01,023] Trial 193 finished with value: 0.784179690342526 and parameters: {'learning_rate': 0.07135628368318338, 'feature_fraction': 0.8185746220151879, 'bagging_fraction': 0.6951431638772219, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8185746220151879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8185746220151879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6951431638772219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6951431638772219\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8116618393109715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8116618393109715\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8432667607380437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8432667607380437\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8116618393109715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8116618393109715\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8432667607380437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8432667607380437\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010452 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8116618393109715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8116618393109715\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8432667607380437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8432667607380437\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:02,271] Trial 194 finished with value: 0.7878402620204303 and parameters: {'learning_rate': 0.044629253122413046, 'feature_fraction': 0.8116618393109715, 'bagging_fraction': 0.8432667607380437, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8116618393109715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8116618393109715\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8432667607380437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8432667607380437\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8107622168548642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8107622168548642\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6560642902099423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6560642902099423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8107622168548642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8107622168548642\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6560642902099423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6560642902099423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011659 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8107622168548642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8107622168548642\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6560642902099423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6560642902099423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:03,442] Trial 195 finished with value: 0.7872421495040045 and parameters: {'learning_rate': 0.07898579151491897, 'feature_fraction': 0.8107622168548642, 'bagging_fraction': 0.6560642902099423, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8107622168548642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8107622168548642\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6560642902099423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6560642902099423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7857046722807014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7857046722807014\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333026163478255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333026163478255\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7857046722807014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7857046722807014\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333026163478255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333026163478255\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012275 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7857046722807014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7857046722807014\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333026163478255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333026163478255\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:04,601] Trial 196 finished with value: 0.7858645603406011 and parameters: {'learning_rate': 0.05722743259283019, 'feature_fraction': 0.7857046722807014, 'bagging_fraction': 0.6333026163478255, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7857046722807014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7857046722807014\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333026163478255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333026163478255\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8313885243470216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8313885243470216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6680745872384843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6680745872384843\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8313885243470216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8313885243470216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6680745872384843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6680745872384843\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8313885243470216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8313885243470216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6680745872384843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6680745872384843\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:06,030] Trial 197 finished with value: 0.7846060042645858 and parameters: {'learning_rate': 0.03614861464651161, 'feature_fraction': 0.8313885243470216, 'bagging_fraction': 0.6680745872384843, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8313885243470216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8313885243470216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6680745872384843, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6680745872384843\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7677211399729431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677211399729431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6850930857651403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6850930857651403\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7677211399729431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677211399729431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6850930857651403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6850930857651403\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014329 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7677211399729431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677211399729431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6850930857651403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6850930857651403\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:07,312] Trial 198 finished with value: 0.7852767482947254 and parameters: {'learning_rate': 0.06767919738305252, 'feature_fraction': 0.7677211399729431, 'bagging_fraction': 0.6850930857651403, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7677211399729431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7677211399729431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6850930857651403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6850930857651403\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6930118428933437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6930118428933437\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8243808508734971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8243808508734971\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6930118428933437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6930118428933437\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8243808508734971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8243808508734971\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011257 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6930118428933437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6930118428933437\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8243808508734971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8243808508734971\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:08,587] Trial 199 finished with value: 0.7869289113595694 and parameters: {'learning_rate': 0.08941730519376524, 'feature_fraction': 0.6930118428933437, 'bagging_fraction': 0.8243808508734971, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6930118428933437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6930118428933437\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8243808508734971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8243808508734971\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8379518160794885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8379518160794885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8534083706163629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8534083706163629\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8379518160794885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8379518160794885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8534083706163629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8534083706163629\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8379518160794885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8379518160794885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8534083706163629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8534083706163629\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:09,869] Trial 200 finished with value: 0.7874603254485413 and parameters: {'learning_rate': 0.04970747082363906, 'feature_fraction': 0.8379518160794885, 'bagging_fraction': 0.8534083706163629, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8379518160794885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8379518160794885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8534083706163629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8534083706163629\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7361512660064975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361512660064975\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650016784257567, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650016784257567\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7361512660064975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361512660064975\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650016784257567, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650016784257567\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006550 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7361512660064975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361512660064975\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650016784257567, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650016784257567\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:10,712] Trial 201 finished with value: 0.7889907072773941 and parameters: {'learning_rate': 0.04169330374661586, 'feature_fraction': 0.7361512660064975, 'bagging_fraction': 0.650016784257567, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7361512660064975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361512660064975\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.650016784257567, subsample=1.0 will be ignored. Current value: bagging_fraction=0.650016784257567\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8031535072269058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8031535072269058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6486501343146739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6486501343146739\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8031535072269058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8031535072269058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6486501343146739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6486501343146739\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008665 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8031535072269058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8031535072269058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6486501343146739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6486501343146739\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:11,612] Trial 202 finished with value: 0.7875938041474639 and parameters: {'learning_rate': 0.042960686947083125, 'feature_fraction': 0.8031535072269058, 'bagging_fraction': 0.6486501343146739, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8031535072269058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8031535072269058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6486501343146739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6486501343146739\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7419974870222921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7419974870222921\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6603382342963617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6603382342963617\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7419974870222921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7419974870222921\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6603382342963617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6603382342963617\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7419974870222921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7419974870222921\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6603382342963617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6603382342963617\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:12,450] Trial 203 finished with value: 0.787234925681694 and parameters: {'learning_rate': 0.05903052532228725, 'feature_fraction': 0.7419974870222921, 'bagging_fraction': 0.6603382342963617, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7419974870222921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7419974870222921\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6603382342963617, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6603382342963617\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234075002065509, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234075002065509\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393363599922054, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393363599922054\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234075002065509, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234075002065509\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393363599922054, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393363599922054\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234075002065509, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234075002065509\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393363599922054, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393363599922054\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:13,259] Trial 204 finished with value: 0.7846065352731082 and parameters: {'learning_rate': 0.033256633215011974, 'feature_fraction': 0.7234075002065509, 'bagging_fraction': 0.6393363599922054, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7234075002065509, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234075002065509\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393363599922054, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393363599922054\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7544306079371508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7544306079371508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6463945054444632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463945054444632\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7544306079371508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7544306079371508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6463945054444632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463945054444632\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7544306079371508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7544306079371508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6463945054444632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463945054444632\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:14,158] Trial 205 finished with value: 0.7701627342209473 and parameters: {'learning_rate': 0.00031585221409052215, 'feature_fraction': 0.7544306079371508, 'bagging_fraction': 0.6463945054444632, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7544306079371508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7544306079371508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6463945054444632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463945054444632\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7328057818591394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328057818591394\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6776835735022056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6776835735022056\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7328057818591394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328057818591394\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6776835735022056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6776835735022056\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7328057818591394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328057818591394\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6776835735022056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6776835735022056\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:14,954] Trial 206 finished with value: 0.787688021858777 and parameters: {'learning_rate': 0.05082456478701534, 'feature_fraction': 0.7328057818591394, 'bagging_fraction': 0.6776835735022056, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7328057818591394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328057818591394\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6776835735022056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6776835735022056\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7101804424139155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7101804424139155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6717384269713991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6717384269713991\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7101804424139155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7101804424139155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6717384269713991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6717384269713991\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7101804424139155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7101804424139155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6717384269713991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6717384269713991\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:15,749] Trial 207 finished with value: 0.7848011045307182 and parameters: {'learning_rate': 0.06982166901474389, 'feature_fraction': 0.7101804424139155, 'bagging_fraction': 0.6717384269713991, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7101804424139155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7101804424139155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6717384269713991, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6717384269713991\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170526911992909, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170526911992909\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6525888754206823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6525888754206823\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170526911992909, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170526911992909\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6525888754206823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6525888754206823\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007794 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170526911992909, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170526911992909\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6525888754206823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6525888754206823\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:16,558] Trial 208 finished with value: 0.7855526464424925 and parameters: {'learning_rate': 0.08104013954990424, 'feature_fraction': 0.7170526911992909, 'bagging_fraction': 0.6525888754206823, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7170526911992909, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170526911992909\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6525888754206823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6525888754206823\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7011977509731381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7011977509731381\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6637026100947183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6637026100947183\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7011977509731381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7011977509731381\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6637026100947183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6637026100947183\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006418 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7011977509731381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7011977509731381\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6637026100947183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6637026100947183\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:17,380] Trial 209 finished with value: 0.7878985843575816 and parameters: {'learning_rate': 0.06391799441114086, 'feature_fraction': 0.7011977509731381, 'bagging_fraction': 0.6637026100947183, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7011977509731381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7011977509731381\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6637026100947183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6637026100947183\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395298108864585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395298108864585\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8697474755191078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8697474755191078\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395298108864585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395298108864585\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8697474755191078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8697474755191078\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395298108864585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395298108864585\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8697474755191078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8697474755191078\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:18,239] Trial 210 finished with value: 0.7863481593073254 and parameters: {'learning_rate': 0.037408257521295854, 'feature_fraction': 0.7395298108864585, 'bagging_fraction': 0.8697474755191078, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7395298108864585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395298108864585\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8697474755191078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8697474755191078\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7299294469693255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299294469693255\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8198065013380001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8198065013380001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7299294469693255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299294469693255\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8198065013380001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8198065013380001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7299294469693255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299294469693255\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8198065013380001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8198065013380001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:19,137] Trial 211 finished with value: 0.7867317246578334 and parameters: {'learning_rate': 0.0422228053887103, 'feature_fraction': 0.7299294469693255, 'bagging_fraction': 0.8198065013380001, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7299294469693255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299294469693255\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8198065013380001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8198065013380001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8510190152069171, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8510190152069171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8085694100155018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085694100155018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8510190152069171, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8510190152069171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8085694100155018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085694100155018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003687 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8510190152069171, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8510190152069171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8085694100155018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085694100155018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:20,108] Trial 212 finished with value: 0.7851314078230927 and parameters: {'learning_rate': 0.04717769866747652, 'feature_fraction': 0.8510190152069171, 'bagging_fraction': 0.8085694100155018, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8510190152069171, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8510190152069171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8085694100155018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8085694100155018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7482883462684614, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482883462684614\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258048876816455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258048876816455\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7482883462684614, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482883462684614\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258048876816455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258048876816455\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7482883462684614, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482883462684614\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258048876816455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258048876816455\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:21,319] Trial 213 finished with value: 0.7904723070406321 and parameters: {'learning_rate': 0.055255598835462647, 'feature_fraction': 0.7482883462684614, 'bagging_fraction': 0.8258048876816455, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7482883462684614, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482883462684614\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258048876816455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258048876816455\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7576143595619244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576143595619244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6311332508973496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6311332508973496\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7576143595619244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576143595619244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6311332508973496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6311332508973496\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005271 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7576143595619244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576143595619244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6311332508973496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6311332508973496\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:22,476] Trial 214 finished with value: 0.7890071813207005 and parameters: {'learning_rate': 0.055742993824156734, 'feature_fraction': 0.7576143595619244, 'bagging_fraction': 0.6311332508973496, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7576143595619244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576143595619244\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6311332508973496, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6311332508973496\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7614071946796472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7614071946796472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630223323115314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630223323115314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7614071946796472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7614071946796472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630223323115314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630223323115314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7614071946796472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7614071946796472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630223323115314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630223323115314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:23,600] Trial 215 finished with value: 0.7855323826884254 and parameters: {'learning_rate': 0.055441047485044845, 'feature_fraction': 0.7614071946796472, 'bagging_fraction': 0.630223323115314, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7614071946796472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7614071946796472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630223323115314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630223323115314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7480376298830431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7480376298830431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333698579211001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333698579211001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7480376298830431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7480376298830431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333698579211001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333698579211001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010875 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7480376298830431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7480376298830431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333698579211001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333698579211001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:24,793] Trial 216 finished with value: 0.7899888949125569 and parameters: {'learning_rate': 0.07536602733869426, 'feature_fraction': 0.7480376298830431, 'bagging_fraction': 0.6333698579211001, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7480376298830431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7480376298830431\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6333698579211001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6333698579211001\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7536129995044399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536129995044399\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6132166541818677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6132166541818677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7536129995044399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536129995044399\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6132166541818677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6132166541818677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012034 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7536129995044399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536129995044399\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6132166541818677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6132166541818677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:26,045] Trial 217 finished with value: 0.7887464782032503 and parameters: {'learning_rate': 0.07157190448322115, 'feature_fraction': 0.7536129995044399, 'bagging_fraction': 0.6132166541818677, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7536129995044399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536129995044399\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6132166541818677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6132166541818677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7478093155328007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7478093155328007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6229599198255554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229599198255554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7478093155328007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7478093155328007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6229599198255554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229599198255554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011545 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7478093155328007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7478093155328007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6229599198255554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229599198255554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:27,278] Trial 218 finished with value: 0.7883477818890571 and parameters: {'learning_rate': 0.060741998475032005, 'feature_fraction': 0.7478093155328007, 'bagging_fraction': 0.6229599198255554, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7478093155328007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7478093155328007\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6229599198255554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6229599198255554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7681457064694115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681457064694115\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.635138536661995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.635138536661995\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7681457064694115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681457064694115\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.635138536661995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.635138536661995\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012881 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7681457064694115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681457064694115\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.635138536661995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.635138536661995\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:28,369] Trial 219 finished with value: 0.7886025277311701 and parameters: {'learning_rate': 0.05270862102471956, 'feature_fraction': 0.7681457064694115, 'bagging_fraction': 0.635138536661995, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7681457064694115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681457064694115\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.635138536661995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.635138536661995\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7781904946027678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7781904946027678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6398739665191423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6398739665191423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7781904946027678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7781904946027678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6398739665191423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6398739665191423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7781904946027678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7781904946027678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6398739665191423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6398739665191423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:29,164] Trial 220 finished with value: 0.7887760789085784 and parameters: {'learning_rate': 0.08770433986486037, 'feature_fraction': 0.7781904946027678, 'bagging_fraction': 0.6398739665191423, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7781904946027678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7781904946027678\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6398739665191423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6398739665191423\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7599549874704637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599549874704637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393631646503388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393631646503388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7599549874704637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599549874704637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393631646503388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393631646503388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7599549874704637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599549874704637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393631646503388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393631646503388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:29,933] Trial 221 finished with value: 0.787001094012892 and parameters: {'learning_rate': 0.0988620218468846, 'feature_fraction': 0.7599549874704637, 'bagging_fraction': 0.6393631646503388, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7599549874704637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7599549874704637\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6393631646503388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6393631646503388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.774193677670501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.774193677670501\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432000147684515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432000147684515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.774193677670501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.774193677670501\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432000147684515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432000147684515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.774193677670501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.774193677670501\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432000147684515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432000147684515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:30,728] Trial 222 finished with value: 0.7872450784673211 and parameters: {'learning_rate': 0.07889689909263105, 'feature_fraction': 0.774193677670501, 'bagging_fraction': 0.6432000147684515, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.774193677670501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.774193677670501\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432000147684515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432000147684515\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7900539576106251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7900539576106251\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6290190421173868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6290190421173868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7900539576106251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7900539576106251\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6290190421173868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6290190421173868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7900539576106251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7900539576106251\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6290190421173868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6290190421173868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:31,490] Trial 223 finished with value: 0.7853667745873572 and parameters: {'learning_rate': 0.09022801156512573, 'feature_fraction': 0.7900539576106251, 'bagging_fraction': 0.6290190421173868, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7900539576106251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7900539576106251\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6290190421173868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6290190421173868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7473638475015851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473638475015851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6487886625669017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6487886625669017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7473638475015851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473638475015851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6487886625669017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6487886625669017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7473638475015851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473638475015851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6487886625669017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6487886625669017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:32,260] Trial 224 finished with value: 0.7866117130558461 and parameters: {'learning_rate': 0.06620213182970215, 'feature_fraction': 0.7473638475015851, 'bagging_fraction': 0.6487886625669017, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7473638475015851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7473638475015851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6487886625669017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6487886625669017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7769278356947652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7769278356947652\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6354002182718944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354002182718944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7769278356947652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7769278356947652\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6354002182718944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354002182718944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7769278356947652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7769278356947652\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6354002182718944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354002182718944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:33,076] Trial 225 finished with value: 0.7891837452178176 and parameters: {'learning_rate': 0.0806342229693868, 'feature_fraction': 0.7769278356947652, 'bagging_fraction': 0.6354002182718944, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7769278356947652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7769278356947652\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6354002182718944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354002182718944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7558105417458506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7558105417458506\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6022717966312677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6022717966312677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7558105417458506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7558105417458506\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6022717966312677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6022717966312677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7558105417458506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7558105417458506\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6022717966312677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6022717966312677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:33,889] Trial 226 finished with value: 0.7846955505741088 and parameters: {'learning_rate': 0.07438632492741487, 'feature_fraction': 0.7558105417458506, 'bagging_fraction': 0.6022717966312677, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7558105417458506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7558105417458506\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6022717966312677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6022717966312677\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8177504087414671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8177504087414671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6230225728157891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6230225728157891\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8177504087414671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8177504087414671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6230225728157891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6230225728157891\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8177504087414671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8177504087414671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6230225728157891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6230225728157891\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:34,695] Trial 227 finished with value: 0.7848578216019535 and parameters: {'learning_rate': 0.05895136260192963, 'feature_fraction': 0.8177504087414671, 'bagging_fraction': 0.6230225728157891, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8177504087414671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8177504087414671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6230225728157891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6230225728157891\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7623388168791173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7623388168791173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6326186155413477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6326186155413477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7623388168791173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7623388168791173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6326186155413477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6326186155413477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7623388168791173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7623388168791173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6326186155413477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6326186155413477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:35,524] Trial 228 finished with value: 0.7884366606049106 and parameters: {'learning_rate': 0.06829095813811427, 'feature_fraction': 0.7623388168791173, 'bagging_fraction': 0.6326186155413477, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7623388168791173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7623388168791173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6326186155413477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6326186155413477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7422275744925939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7422275744925939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537427210554445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537427210554445\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7422275744925939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7422275744925939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537427210554445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537427210554445\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7422275744925939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7422275744925939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537427210554445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537427210554445\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:36,403] Trial 229 finished with value: 0.7863713118510969 and parameters: {'learning_rate': 0.05324861089509649, 'feature_fraction': 0.7422275744925939, 'bagging_fraction': 0.6537427210554445, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7422275744925939, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7422275744925939\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537427210554445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537427210554445\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7511258898054515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511258898054515\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6912392495035143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6912392495035143\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7511258898054515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511258898054515\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6912392495035143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6912392495035143\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7511258898054515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511258898054515\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6912392495035143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6912392495035143\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:37,218] Trial 230 finished with value: 0.7844668506616788 and parameters: {'learning_rate': 0.07761164569002134, 'feature_fraction': 0.7511258898054515, 'bagging_fraction': 0.6912392495035143, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7511258898054515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511258898054515\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6912392495035143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6912392495035143\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7789689026074802, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789689026074802\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6382869191108301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6382869191108301\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7789689026074802, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789689026074802\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6382869191108301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6382869191108301\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007561 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7789689026074802, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789689026074802\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6382869191108301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6382869191108301\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:38,015] Trial 231 finished with value: 0.787448427373847 and parameters: {'learning_rate': 0.09058955317525558, 'feature_fraction': 0.7789689026074802, 'bagging_fraction': 0.6382869191108301, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7789689026074802, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789689026074802\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6382869191108301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6382869191108301\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.775762531082155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775762531082155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435404515223743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435404515223743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.775762531082155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775762531082155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435404515223743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435404515223743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.775762531082155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775762531082155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435404515223743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435404515223743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:39,138] Trial 232 finished with value: 0.7855520698234008 and parameters: {'learning_rate': 0.08195042433629313, 'feature_fraction': 0.775762531082155, 'bagging_fraction': 0.6435404515223743, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.775762531082155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775762531082155\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435404515223743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435404515223743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7962835560905414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7962835560905414\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6171099750953962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6171099750953962\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7962835560905414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7962835560905414\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6171099750953962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6171099750953962\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005199 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7962835560905414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7962835560905414\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6171099750953962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6171099750953962\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:40,266] Trial 233 finished with value: 0.7869051820117389 and parameters: {'learning_rate': 0.06107698739819574, 'feature_fraction': 0.7962835560905414, 'bagging_fraction': 0.6171099750953962, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7962835560905414, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7962835560905414\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6171099750953962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6171099750953962\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7687422475270049, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687422475270049\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6299826211653273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6299826211653273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7687422475270049, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687422475270049\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6299826211653273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6299826211653273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014736 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7687422475270049, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687422475270049\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6299826211653273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6299826211653273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:41,371] Trial 234 finished with value: 0.7869397720734546 and parameters: {'learning_rate': 0.07093737453389894, 'feature_fraction': 0.7687422475270049, 'bagging_fraction': 0.6299826211653273, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7687422475270049, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687422475270049\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6299826211653273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6299826211653273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7591271823113129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591271823113129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553656809738797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553656809738797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7591271823113129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591271823113129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553656809738797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553656809738797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004992 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7591271823113129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591271823113129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553656809738797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553656809738797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:42,571] Trial 235 finished with value: 0.7888311432065492 and parameters: {'learning_rate': 0.0884285479999299, 'feature_fraction': 0.7591271823113129, 'bagging_fraction': 0.6553656809738797, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7591271823113129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7591271823113129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553656809738797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553656809738797\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7563474899172593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7563474899172593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553182075575303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553182075575303\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7563474899172593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7563474899172593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553182075575303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553182075575303\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7563474899172593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7563474899172593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553182075575303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553182075575303\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:43,836] Trial 236 finished with value: 0.78830329987155 and parameters: {'learning_rate': 0.06545944302965072, 'feature_fraction': 0.7563474899172593, 'bagging_fraction': 0.6553182075575303, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7563474899172593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7563474899172593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6553182075575303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6553182075575303\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7426638702248136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7426638702248136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6597962620297034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6597962620297034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7426638702248136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7426638702248136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6597962620297034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6597962620297034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7426638702248136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7426638702248136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6597962620297034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6597962620297034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:45,127] Trial 237 finished with value: 0.7751940942621238 and parameters: {'learning_rate': 0.01194109624236601, 'feature_fraction': 0.7426638702248136, 'bagging_fraction': 0.6597962620297034, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7426638702248136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7426638702248136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6597962620297034, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6597962620297034\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7369291548213202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369291548213202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8610677912073788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8610677912073788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7369291548213202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369291548213202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8610677912073788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8610677912073788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7369291548213202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369291548213202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8610677912073788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8610677912073788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:46,367] Trial 238 finished with value: 0.7878553702060672 and parameters: {'learning_rate': 0.048120940181764583, 'feature_fraction': 0.7369291548213202, 'bagging_fraction': 0.8610677912073788, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7369291548213202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369291548213202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8610677912073788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8610677912073788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.763227712331855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.763227712331855\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490927342842951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490927342842951\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.763227712331855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.763227712331855\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490927342842951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490927342842951\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003762 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.763227712331855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.763227712331855\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490927342842951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490927342842951\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:47,149] Trial 239 finished with value: 0.7882382388828137 and parameters: {'learning_rate': 0.07613865359485254, 'feature_fraction': 0.763227712331855, 'bagging_fraction': 0.6490927342842951, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.763227712331855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.763227712331855\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490927342842951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490927342842951\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7509122936685922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7509122936685922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7064089357783391, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064089357783391\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7509122936685922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7509122936685922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7064089357783391, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064089357783391\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7509122936685922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7509122936685922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7064089357783391, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064089357783391\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:47,973] Trial 240 finished with value: 0.7873370197905438 and parameters: {'learning_rate': 0.05589484437901779, 'feature_fraction': 0.7509122936685922, 'bagging_fraction': 0.7064089357783391, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7509122936685922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7509122936685922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7064089357783391, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7064089357783391\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7679560738285156, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679560738285156\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.640270333796342, subsample=1.0 will be ignored. Current value: bagging_fraction=0.640270333796342\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7679560738285156, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679560738285156\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.640270333796342, subsample=1.0 will be ignored. Current value: bagging_fraction=0.640270333796342\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7679560738285156, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679560738285156\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.640270333796342, subsample=1.0 will be ignored. Current value: bagging_fraction=0.640270333796342\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:48,784] Trial 241 finished with value: 0.7881826628423986 and parameters: {'learning_rate': 0.08755007811590951, 'feature_fraction': 0.7679560738285156, 'bagging_fraction': 0.640270333796342, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7679560738285156, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679560738285156\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.640270333796342, subsample=1.0 will be ignored. Current value: bagging_fraction=0.640270333796342\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7460329420610861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7460329420610861\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6479077607753614, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6479077607753614\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7460329420610861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7460329420610861\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6479077607753614, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6479077607753614\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7460329420610861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7460329420610861\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6479077607753614, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6479077607753614\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:49,573] Trial 242 finished with value: 0.7867659395741702 and parameters: {'learning_rate': 0.0924227969836475, 'feature_fraction': 0.7460329420610861, 'bagging_fraction': 0.6479077607753614, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7460329420610861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7460329420610861\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6479077607753614, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6479077607753614\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7845798174963583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7845798174963583\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6358888007249712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6358888007249712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7845798174963583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7845798174963583\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6358888007249712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6358888007249712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003955 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7845798174963583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7845798174963583\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6358888007249712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6358888007249712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:50,407] Trial 243 finished with value: 0.7877265514474558 and parameters: {'learning_rate': 0.08143346972592148, 'feature_fraction': 0.7845798174963583, 'bagging_fraction': 0.6358888007249712, 'bagging_freq': 3, 'min_child_samples': 94}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7845798174963583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7845798174963583\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6358888007249712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6358888007249712\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7608961262896616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7608961262896616\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6571973811185479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6571973811185479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7608961262896616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7608961262896616\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6571973811185479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6571973811185479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7608961262896616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7608961262896616\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6571973811185479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6571973811185479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:51,178] Trial 244 finished with value: 0.7825218711338305 and parameters: {'learning_rate': 0.0999284155209786, 'feature_fraction': 0.7608961262896616, 'bagging_fraction': 0.6571973811185479, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7608961262896616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7608961262896616\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6571973811185479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6571973811185479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6762606914109222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6762606914109222\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8736555074249087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8736555074249087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6762606914109222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6762606914109222\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8736555074249087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8736555074249087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008009 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6762606914109222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6762606914109222\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8736555074249087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8736555074249087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:52,126] Trial 245 finished with value: 0.7698135285572985 and parameters: {'learning_rate': 0.0014081048700964726, 'feature_fraction': 0.6762606914109222, 'bagging_fraction': 0.8736555074249087, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6762606914109222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6762606914109222\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8736555074249087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8736555074249087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6872110996849242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6872110996849242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6689978685019943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6689978685019943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6872110996849242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6872110996849242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6689978685019943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6689978685019943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006173 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6872110996849242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6872110996849242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6689978685019943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6689978685019943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:52,943] Trial 246 finished with value: 0.7827420742105813 and parameters: {'learning_rate': 0.06818035779340671, 'feature_fraction': 0.6872110996849242, 'bagging_fraction': 0.6689978685019943, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6872110996849242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6872110996849242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6689978685019943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6689978685019943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346368619636164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346368619636164\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6444951093634851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6444951093634851\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346368619636164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346368619636164\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6444951093634851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6444951093634851\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006580 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346368619636164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346368619636164\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6444951093634851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6444951093634851\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:53,770] Trial 247 finished with value: 0.7847525303442651 and parameters: {'learning_rate': 0.04139437891977017, 'feature_fraction': 0.7346368619636164, 'bagging_fraction': 0.6444951093634851, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7346368619636164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346368619636164\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6444951093634851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6444951093634851\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8065950697132803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065950697132803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8452139702592862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8452139702592862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8065950697132803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065950697132803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8452139702592862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8452139702592862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8065950697132803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065950697132803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8452139702592862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8452139702592862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:54,602] Trial 248 finished with value: 0.788912190230025 and parameters: {'learning_rate': 0.07824214342803769, 'feature_fraction': 0.8065950697132803, 'bagging_fraction': 0.8452139702592862, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8065950697132803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065950697132803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8452139702592862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8452139702592862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.811672792491771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.811672792491771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8527877471307368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8527877471307368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.811672792491771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.811672792491771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8527877471307368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8527877471307368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.811672792491771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.811672792491771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8527877471307368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8527877471307368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:55,450] Trial 249 finished with value: 0.7858650041076833 and parameters: {'learning_rate': 0.06188493377607456, 'feature_fraction': 0.811672792491771, 'bagging_fraction': 0.8527877471307368, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.811672792491771, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.811672792491771\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8527877471307368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8527877471307368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.799900177220173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.799900177220173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8283483006303827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8283483006303827\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.799900177220173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.799900177220173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8283483006303827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8283483006303827\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003684 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.799900177220173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.799900177220173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8283483006303827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8283483006303827\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 20:59:56,289] Trial 250 finished with value: 0.7859724076047512 and parameters: {'learning_rate': 0.07415889698916783, 'feature_fraction': 0.799900177220173, 'bagging_fraction': 0.8283483006303827, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.799900177220173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.799900177220173\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8283483006303827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8283483006303827\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.816942164220361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816942164220361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.845144088368025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.845144088368025\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.816942164220361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816942164220361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.845144088368025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.845144088368025\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.816942164220361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816942164220361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.845144088368025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.845144088368025\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:57,521] Trial 251 finished with value: 0.7864816971465216 and parameters: {'learning_rate': 0.049266244367255574, 'feature_fraction': 0.816942164220361, 'bagging_fraction': 0.845144088368025, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.816942164220361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816942164220361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.845144088368025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.845144088368025\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7532551704827956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532551704827956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8570173014716608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8570173014716608\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7532551704827956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532551704827956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8570173014716608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8570173014716608\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009739 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7532551704827956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532551704827956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8570173014716608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8570173014716608\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 20:59:58,788] Trial 252 finished with value: 0.7886675673535976 and parameters: {'learning_rate': 0.058136944946818224, 'feature_fraction': 0.7532551704827956, 'bagging_fraction': 0.8570173014716608, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7532551704827956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7532551704827956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8570173014716608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8570173014716608\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8245609338351068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8245609338351068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8641277630875394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8641277630875394\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8245609338351068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8245609338351068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8641277630875394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8641277630875394\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012043 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8245609338351068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8245609338351068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8641277630875394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8641277630875394\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:00,023] Trial 253 finished with value: 0.789613662069535 and parameters: {'learning_rate': 0.07534273813160342, 'feature_fraction': 0.8245609338351068, 'bagging_fraction': 0.8641277630875394, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8245609338351068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8245609338351068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8641277630875394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8641277630875394\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8292629369549004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292629369549004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8673703486687793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673703486687793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8292629369549004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292629369549004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8673703486687793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673703486687793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011045 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8292629369549004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292629369549004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8673703486687793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673703486687793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:01,448] Trial 254 finished with value: 0.7869304400344019 and parameters: {'learning_rate': 0.070490041814584, 'feature_fraction': 0.8292629369549004, 'bagging_fraction': 0.8673703486687793, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8292629369549004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292629369549004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8673703486687793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8673703486687793\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8097665945138668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8097665945138668\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8837228941899453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837228941899453\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8097665945138668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8097665945138668\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8837228941899453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837228941899453\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014826 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8097665945138668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8097665945138668\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8837228941899453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837228941899453\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:03,016] Trial 255 finished with value: 0.7859918892474166 and parameters: {'learning_rate': 0.05219348112365279, 'feature_fraction': 0.8097665945138668, 'bagging_fraction': 0.8837228941899453, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8097665945138668, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8097665945138668\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8837228941899453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8837228941899453\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8214227816882135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8214227816882135\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8451111337029493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451111337029493\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8214227816882135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8214227816882135\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8451111337029493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451111337029493\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005330 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8214227816882135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8214227816882135\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8451111337029493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451111337029493\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:04,396] Trial 256 finished with value: 0.7867136811545387 and parameters: {'learning_rate': 0.08151184122393401, 'feature_fraction': 0.8214227816882135, 'bagging_fraction': 0.8451111337029493, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8214227816882135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8214227816882135\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8451111337029493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451111337029493\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7398180125956357, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398180125956357\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8636726290978218, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8636726290978218\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7398180125956357, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398180125956357\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8636726290978218, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8636726290978218\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012517 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7398180125956357, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398180125956357\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8636726290978218, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8636726290978218\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:05,476] Trial 257 finished with value: 0.7881415948303889 and parameters: {'learning_rate': 0.06626032013391747, 'feature_fraction': 0.7398180125956357, 'bagging_fraction': 0.8636726290978218, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7398180125956357, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398180125956357\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8636726290978218, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8636726290978218\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6204813880160202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6204813880160202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390709697763465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390709697763465\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6204813880160202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6204813880160202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390709697763465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390709697763465\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6204813880160202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6204813880160202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390709697763465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390709697763465\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:06,467] Trial 258 finished with value: 0.7717401898935082 and parameters: {'learning_rate': 0.0059974048870634795, 'feature_fraction': 0.6204813880160202, 'bagging_fraction': 0.8390709697763465, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6204813880160202, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6204813880160202\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390709697763465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390709697763465\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7468944570939325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7468944570939325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8584106781906554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8584106781906554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7468944570939325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7468944570939325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8584106781906554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8584106781906554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006951 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7468944570939325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7468944570939325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8584106781906554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8584106781906554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:07,401] Trial 259 finished with value: 0.7873253383967233 and parameters: {'learning_rate': 0.041744758254488354, 'feature_fraction': 0.7468944570939325, 'bagging_fraction': 0.8584106781906554, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7468944570939325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7468944570939325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8584106781906554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8584106781906554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8408964331283334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8408964331283334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8789663786302396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8789663786302396\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8408964331283334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8408964331283334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8789663786302396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8789663786302396\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8408964331283334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8408964331283334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8789663786302396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8789663786302396\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:08,265] Trial 260 finished with value: 0.7867005046659862 and parameters: {'learning_rate': 0.06010056524267409, 'feature_fraction': 0.8408964331283334, 'bagging_fraction': 0.8789663786302396, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8408964331283334, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8408964331283334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8789663786302396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8789663786302396\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8059748530251367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059748530251367\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6817172899583527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6817172899583527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8059748530251367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059748530251367\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6817172899583527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6817172899583527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8059748530251367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059748530251367\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6817172899583527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6817172899583527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:09,150] Trial 261 finished with value: 0.7870674021406144 and parameters: {'learning_rate': 0.04737841166154574, 'feature_fraction': 0.8059748530251367, 'bagging_fraction': 0.6817172899583527, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8059748530251367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8059748530251367\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6817172899583527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6817172899583527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.72662539327035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72662539327035\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8504600040582014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8504600040582014\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.72662539327035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72662539327035\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8504600040582014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8504600040582014\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006746 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.72662539327035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72662539327035\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8504600040582014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8504600040582014\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:10,021] Trial 262 finished with value: 0.7896349660082438 and parameters: {'learning_rate': 0.09987375373635199, 'feature_fraction': 0.72662539327035, 'bagging_fraction': 0.8504600040582014, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.72662539327035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72662539327035\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8504600040582014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8504600040582014\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9561867522875478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9561867522875478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8502552671201128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8502552671201128\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9561867522875478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9561867522875478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8502552671201128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8502552671201128\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9561867522875478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9561867522875478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8502552671201128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8502552671201128\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:10,866] Trial 263 finished with value: 0.781975829016327 and parameters: {'learning_rate': 0.09862103074827736, 'feature_fraction': 0.9561867522875478, 'bagging_fraction': 0.8502552671201128, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9561867522875478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9561867522875478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8502552671201128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8502552671201128\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7258359823520167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258359823520167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8692512693972528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8692512693972528\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7258359823520167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258359823520167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8692512693972528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8692512693972528\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7258359823520167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258359823520167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8692512693972528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8692512693972528\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:11,724] Trial 264 finished with value: 0.7875141142746137 and parameters: {'learning_rate': 0.08937005076545046, 'feature_fraction': 0.7258359823520167, 'bagging_fraction': 0.8692512693972528, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7258359823520167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258359823520167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8692512693972528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8692512693972528\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7327428419936248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327428419936248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344397271882776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344397271882776\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7327428419936248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327428419936248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344397271882776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344397271882776\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7327428419936248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327428419936248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344397271882776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344397271882776\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:12,573] Trial 265 finished with value: 0.7874665551854676 and parameters: {'learning_rate': 0.08677295733870893, 'feature_fraction': 0.7327428419936248, 'bagging_fraction': 0.8344397271882776, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7327428419936248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327428419936248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344397271882776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344397271882776\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7232196665509757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7232196665509757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8513398751346335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8513398751346335\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7232196665509757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7232196665509757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8513398751346335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8513398751346335\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006953 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7232196665509757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7232196665509757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8513398751346335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8513398751346335\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:13,415] Trial 266 finished with value: 0.7857885444567638 and parameters: {'learning_rate': 0.0995152464914846, 'feature_fraction': 0.7232196665509757, 'bagging_fraction': 0.8513398751346335, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7232196665509757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7232196665509757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8513398751346335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8513398751346335\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7185357173563436, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7185357173563436\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8412481255434388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8412481255434388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7185357173563436, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7185357173563436\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8412481255434388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8412481255434388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003668 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7185357173563436, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7185357173563436\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8412481255434388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8412481255434388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:14,244] Trial 267 finished with value: 0.7896362883105775 and parameters: {'learning_rate': 0.07944250521294736, 'feature_fraction': 0.7185357173563436, 'bagging_fraction': 0.8412481255434388, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7185357173563436, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7185357173563436\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8412481255434388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8412481255434388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7154598173162025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7154598173162025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8404293473359598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404293473359598\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7154598173162025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7154598173162025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8404293473359598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404293473359598\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7154598173162025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7154598173162025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8404293473359598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404293473359598\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:15,143] Trial 268 finished with value: 0.7885162572721511 and parameters: {'learning_rate': 0.07977810049782269, 'feature_fraction': 0.7154598173162025, 'bagging_fraction': 0.8404293473359598, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7154598173162025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7154598173162025\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8404293473359598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404293473359598\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322640284281299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322640284281299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277066826957133, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277066826957133\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7322640284281299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322640284281299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277066826957133, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277066826957133\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013446 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322640284281299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322640284281299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277066826957133, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277066826957133\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:16,301] Trial 269 finished with value: 0.7875196446394607 and parameters: {'learning_rate': 0.08213547401078546, 'feature_fraction': 0.7322640284281299, 'bagging_fraction': 0.8277066826957133, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7322640284281299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322640284281299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277066826957133, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277066826957133\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7217390933452111, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7217390933452111\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8476774036579601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8476774036579601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7217390933452111, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7217390933452111\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8476774036579601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8476774036579601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010008 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7217390933452111, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7217390933452111\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8476774036579601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8476774036579601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:17,520] Trial 270 finished with value: 0.7877307964606447 and parameters: {'learning_rate': 0.0752464948120224, 'feature_fraction': 0.7217390933452111, 'bagging_fraction': 0.8476774036579601, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7217390933452111, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7217390933452111\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8476774036579601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8476774036579601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7078477458923297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7078477458923297\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356628736559993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356628736559993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7078477458923297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7078477458923297\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356628736559993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356628736559993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7078477458923297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7078477458923297\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356628736559993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356628736559993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:18,704] Trial 271 finished with value: 0.7865127390081558 and parameters: {'learning_rate': 0.056004609933847864, 'feature_fraction': 0.7078477458923297, 'bagging_fraction': 0.8356628736559993, 'bagging_freq': 3, 'min_child_samples': 58}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7078477458923297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7078477458923297\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356628736559993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356628736559993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7439545263823694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7439545263823694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8211439909317517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8211439909317517\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7439545263823694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7439545263823694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8211439909317517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8211439909317517\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7439545263823694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7439545263823694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8211439909317517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8211439909317517\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:20,069] Trial 272 finished with value: 0.7848891157114187 and parameters: {'learning_rate': 0.038420129303061906, 'feature_fraction': 0.7439545263823694, 'bagging_fraction': 0.8211439909317517, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7439545263823694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7439545263823694\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8211439909317517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8211439909317517\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7390989688335482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390989688335482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8552051702570224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8552051702570224\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7390989688335482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390989688335482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8552051702570224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8552051702570224\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7390989688335482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390989688335482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8552051702570224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8552051702570224\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:21,370] Trial 273 finished with value: 0.7904919162953009 and parameters: {'learning_rate': 0.0901275076635986, 'feature_fraction': 0.7390989688335482, 'bagging_fraction': 0.8552051702570224, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7390989688335482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390989688335482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8552051702570224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8552051702570224\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7365054365160796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365054365160796\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597114961060993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597114961060993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7365054365160796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365054365160796\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597114961060993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597114961060993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7365054365160796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365054365160796\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597114961060993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597114961060993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:22,654] Trial 274 finished with value: 0.787646323339466 and parameters: {'learning_rate': 0.09985550727259662, 'feature_fraction': 0.7365054365160796, 'bagging_fraction': 0.8597114961060993, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7365054365160796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365054365160796\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8597114961060993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597114961060993\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7187813598831554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7187813598831554\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865205964150808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865205964150808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7187813598831554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7187813598831554\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865205964150808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865205964150808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015582 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7187813598831554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7187813598831554\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865205964150808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865205964150808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:23,745] Trial 275 finished with value: 0.7896405136607282 and parameters: {'learning_rate': 0.08556906695214465, 'feature_fraction': 0.7187813598831554, 'bagging_fraction': 0.865205964150808, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7187813598831554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7187813598831554\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865205964150808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865205964150808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722517574492089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722517574492089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8761089691529956, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761089691529956\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722517574492089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722517574492089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8761089691529956, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761089691529956\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722517574492089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722517574492089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8761089691529956, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761089691529956\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:24,594] Trial 276 finished with value: 0.7871874541687737 and parameters: {'learning_rate': 0.08157734058238217, 'feature_fraction': 0.722517574492089, 'bagging_fraction': 0.8761089691529956, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.722517574492089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722517574492089\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8761089691529956, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761089691529956\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7159882220363646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7159882220363646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8660552017913388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8660552017913388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7159882220363646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7159882220363646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8660552017913388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8660552017913388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007114 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7159882220363646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7159882220363646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8660552017913388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8660552017913388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:25,499] Trial 277 finished with value: 0.7894314451030229 and parameters: {'learning_rate': 0.0457718980787879, 'feature_fraction': 0.7159882220363646, 'bagging_fraction': 0.8660552017913388, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7159882220363646, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7159882220363646\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8660552017913388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8660552017913388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170973812276664, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170973812276664\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8618088729135163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8618088729135163\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170973812276664, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170973812276664\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8618088729135163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8618088729135163\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7170973812276664, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170973812276664\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8618088729135163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8618088729135163\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:26,353] Trial 278 finished with value: 0.7877041805146647 and parameters: {'learning_rate': 0.0636900098887631, 'feature_fraction': 0.7170973812276664, 'bagging_fraction': 0.8618088729135163, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7170973812276664, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7170973812276664\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8618088729135163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8618088729135163\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7265539951761113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265539951761113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8666099256583665, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8666099256583665\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7265539951761113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265539951761113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8666099256583665, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8666099256583665\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7265539951761113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265539951761113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8666099256583665, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8666099256583665\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:27,254] Trial 279 finished with value: 0.7880931861407153 and parameters: {'learning_rate': 0.05283427360142546, 'feature_fraction': 0.7265539951761113, 'bagging_fraction': 0.8666099256583665, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7265539951761113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265539951761113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8666099256583665, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8666099256583665\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7129126222359803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7129126222359803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.87054679942226, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87054679942226\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7129126222359803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7129126222359803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.87054679942226, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87054679942226\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7129126222359803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7129126222359803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.87054679942226, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87054679942226\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:28,071] Trial 280 finished with value: 0.784817753112396 and parameters: {'learning_rate': 0.07514160795893558, 'feature_fraction': 0.7129126222359803, 'bagging_fraction': 0.87054679942226, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7129126222359803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7129126222359803\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.87054679942226, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87054679942226\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728099802319382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728099802319382\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8516090126903915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8516090126903915\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728099802319382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728099802319382\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8516090126903915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8516090126903915\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003706 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728099802319382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728099802319382\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8516090126903915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8516090126903915\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:28,956] Trial 281 finished with value: 0.7866774437743247 and parameters: {'learning_rate': 0.046453608840857405, 'feature_fraction': 0.728099802319382, 'bagging_fraction': 0.8516090126903915, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.728099802319382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728099802319382\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8516090126903915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8516090126903915\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175121345319702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175121345319702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8556152099454899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8556152099454899\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175121345319702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175121345319702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8556152099454899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8556152099454899\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006634 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7175121345319702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175121345319702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8556152099454899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8556152099454899\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:29,795] Trial 282 finished with value: 0.7883597507569945 and parameters: {'learning_rate': 0.08549293673761224, 'feature_fraction': 0.7175121345319702, 'bagging_fraction': 0.8556152099454899, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7175121345319702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175121345319702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8556152099454899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8556152099454899\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7348696850368028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7348696850368028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8629603748173195, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8629603748173195\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7348696850368028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7348696850368028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8629603748173195, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8629603748173195\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7348696850368028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7348696850368028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8629603748173195, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8629603748173195\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:30,604] Trial 283 finished with value: 0.7877199507911581 and parameters: {'learning_rate': 0.0676192246382928, 'feature_fraction': 0.7348696850368028, 'bagging_fraction': 0.8629603748173195, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7348696850368028, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7348696850368028\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8629603748173195, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8629603748173195\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7071714876366848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7071714876366848\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8430147130927841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430147130927841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7071714876366848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7071714876366848\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8430147130927841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430147130927841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7071714876366848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7071714876366848\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8430147130927841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430147130927841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:31,492] Trial 284 finished with value: 0.7865052935333698 and parameters: {'learning_rate': 0.05955732999358534, 'feature_fraction': 0.7071714876366848, 'bagging_fraction': 0.8430147130927841, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7071714876366848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7071714876366848\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8430147130927841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8430147130927841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737346071163057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737346071163057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9000889263159331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9000889263159331\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737346071163057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737346071163057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9000889263159331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9000889263159331\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737346071163057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737346071163057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9000889263159331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9000889263159331\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:32,359] Trial 285 finished with value: 0.7875062656186168 and parameters: {'learning_rate': 0.08908656881809626, 'feature_fraction': 0.737346071163057, 'bagging_fraction': 0.9000889263159331, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.737346071163057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737346071163057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9000889263159331, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9000889263159331\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7284570528386661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7284570528386661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8757406800566261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8757406800566261\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7284570528386661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7284570528386661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8757406800566261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8757406800566261\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006509 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7284570528386661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7284570528386661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8757406800566261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8757406800566261\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:33,234] Trial 286 finished with value: 0.7881489199122151 and parameters: {'learning_rate': 0.07189175150064808, 'feature_fraction': 0.7284570528386661, 'bagging_fraction': 0.8757406800566261, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7284570528386661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7284570528386661\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8757406800566261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8757406800566261\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7025531131361702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7025531131361702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8834690422178149, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8834690422178149\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7025531131361702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7025531131361702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8834690422178149, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8834690422178149\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006491 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7025531131361702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7025531131361702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8834690422178149, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8834690422178149\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:34,434] Trial 287 finished with value: 0.7877671929127684 and parameters: {'learning_rate': 0.05171591261126868, 'feature_fraction': 0.7025531131361702, 'bagging_fraction': 0.8834690422178149, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7025531131361702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7025531131361702\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8834690422178149, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8834690422178149\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7171144411654061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7171144411654061\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571457442824841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571457442824841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7171144411654061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7171144411654061\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571457442824841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571457442824841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005137 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7171144411654061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7171144411654061\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571457442824841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571457442824841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:35,603] Trial 288 finished with value: 0.7873889234180182 and parameters: {'learning_rate': 0.07858007949478207, 'feature_fraction': 0.7171144411654061, 'bagging_fraction': 0.8571457442824841, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7171144411654061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7171144411654061\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571457442824841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571457442824841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7219168382191934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219168382191934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8482068294187782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8482068294187782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7219168382191934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219168382191934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8482068294187782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8482068294187782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010147 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7219168382191934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219168382191934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8482068294187782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8482068294187782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:36,879] Trial 289 finished with value: 0.7885504372398036 and parameters: {'learning_rate': 0.04382031373938455, 'feature_fraction': 0.7219168382191934, 'bagging_fraction': 0.8482068294187782, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7219168382191934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219168382191934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8482068294187782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8482068294187782\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.742413578714023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.742413578714023\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8670472044128537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8670472044128537\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.742413578714023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.742413578714023\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8670472044128537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8670472044128537\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009948 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.742413578714023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.742413578714023\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8670472044128537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8670472044128537\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:38,304] Trial 290 finished with value: 0.7806383909393925 and parameters: {'learning_rate': 0.03208374295967543, 'feature_fraction': 0.742413578714023, 'bagging_fraction': 0.8670472044128537, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.742413578714023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.742413578714023\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8670472044128537, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8670472044128537\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7113791480437551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113791480437551\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8887489308427317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8887489308427317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7113791480437551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113791480437551\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8887489308427317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8887489308427317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012966 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7113791480437551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113791480437551\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8887489308427317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8887489308427317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:39,612] Trial 291 finished with value: 0.7876685219166498 and parameters: {'learning_rate': 0.06371477186137907, 'feature_fraction': 0.7113791480437551, 'bagging_fraction': 0.8887489308427317, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7113791480437551, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7113791480437551\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8887489308427317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8887489308427317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7323115811425751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7323115811425751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8547572252330601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8547572252330601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7323115811425751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7323115811425751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8547572252330601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8547572252330601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7323115811425751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7323115811425751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8547572252330601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8547572252330601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:40,858] Trial 292 finished with value: 0.7852235190915692 and parameters: {'learning_rate': 0.09652228240612153, 'feature_fraction': 0.7323115811425751, 'bagging_fraction': 0.8547572252330601, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7323115811425751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7323115811425751\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8547572252330601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8547572252330601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979875058067094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979875058067094\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9438968074538368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9438968074538368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6979875058067094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979875058067094\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9438968074538368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9438968074538368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011242 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6979875058067094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979875058067094\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9438968074538368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9438968074538368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:42,083] Trial 293 finished with value: 0.7872821622209272 and parameters: {'learning_rate': 0.07217502854999543, 'feature_fraction': 0.6979875058067094, 'bagging_fraction': 0.9438968074538368, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6979875058067094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6979875058067094\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9438968074538368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9438968074538368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7484061513546312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484061513546312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8456026178597768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8456026178597768\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7484061513546312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484061513546312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8456026178597768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8456026178597768\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006431 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7484061513546312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484061513546312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8456026178597768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8456026178597768\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:42,968] Trial 294 finished with value: 0.787672565215878 and parameters: {'learning_rate': 0.05569807333564196, 'feature_fraction': 0.7484061513546312, 'bagging_fraction': 0.8456026178597768, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7484061513546312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484061513546312\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8456026178597768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8456026178597768\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7255733044282306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7255733044282306\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414089330297056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414089330297056\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7255733044282306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7255733044282306\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414089330297056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414089330297056\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7255733044282306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7255733044282306\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414089330297056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414089330297056\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:43,793] Trial 295 finished with value: 0.7796362945199147 and parameters: {'learning_rate': 0.09992316653199744, 'feature_fraction': 0.7255733044282306, 'bagging_fraction': 0.7414089330297056, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7255733044282306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7255733044282306\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414089330297056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414089330297056\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8228904352337992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8228904352337992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8709871859172043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8709871859172043\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8228904352337992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8228904352337992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8709871859172043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8709871859172043\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8228904352337992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8228904352337992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8709871859172043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8709871859172043\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:44,690] Trial 296 finished with value: 0.7705651425298807 and parameters: {'learning_rate': 0.008539122400806787, 'feature_fraction': 0.8228904352337992, 'bagging_fraction': 0.8709871859172043, 'bagging_freq': 3, 'min_child_samples': 88}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8228904352337992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8228904352337992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8709871859172043, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8709871859172043\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6413325212556154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6413325212556154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861256368702365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861256368702365\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6413325212556154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6413325212556154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861256368702365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861256368702365\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6413325212556154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6413325212556154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861256368702365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861256368702365\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:45,605] Trial 297 finished with value: 0.7699700344840112 and parameters: {'learning_rate': 0.000705901454764322, 'feature_fraction': 0.6413325212556154, 'bagging_fraction': 0.861256368702365, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6413325212556154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6413325212556154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861256368702365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861256368702365\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393506980816464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393506980816464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6277670370420357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6277670370420357\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393506980816464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393506980816464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6277670370420357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6277670370420357\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393506980816464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393506980816464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6277670370420357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6277670370420357\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:46,447] Trial 298 finished with value: 0.7870950078703319 and parameters: {'learning_rate': 0.036276426418260004, 'feature_fraction': 0.7393506980816464, 'bagging_fraction': 0.6277670370420357, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7393506980816464, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393506980816464\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6277670370420357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6277670370420357\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.711093008642729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.711093008642729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8764217186150786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8764217186150786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.711093008642729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.711093008642729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8764217186150786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8764217186150786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007055 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.711093008642729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.711093008642729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8764217186150786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8764217186150786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:47,307] Trial 299 finished with value: 0.7879392139502549 and parameters: {'learning_rate': 0.08152179610757787, 'feature_fraction': 0.711093008642729, 'bagging_fraction': 0.8764217186150786, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.711093008642729, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.711093008642729\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8764217186150786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8764217186150786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319333256048625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319333256048625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8347430678037137, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8347430678037137\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319333256048625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319333256048625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8347430678037137, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8347430678037137\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7319333256048625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319333256048625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8347430678037137, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8347430678037137\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:48,195] Trial 300 finished with value: 0.7871727790343338 and parameters: {'learning_rate': 0.05975757585018749, 'feature_fraction': 0.7319333256048625, 'bagging_fraction': 0.8347430678037137, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7319333256048625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319333256048625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8347430678037137, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8347430678037137\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7179483687134345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7179483687134345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8560734384577806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560734384577806\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7179483687134345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7179483687134345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8560734384577806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560734384577806\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7179483687134345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7179483687134345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8560734384577806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560734384577806\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:49,050] Trial 301 finished with value: 0.7870908475391117 and parameters: {'learning_rate': 0.04799034159321507, 'feature_fraction': 0.7179483687134345, 'bagging_fraction': 0.8560734384577806, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7179483687134345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7179483687134345\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8560734384577806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560734384577806\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6705247784537579, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6705247784537579\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6187764953726669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6187764953726669\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6705247784537579, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6705247784537579\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6187764953726669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6187764953726669\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6705247784537579, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6705247784537579\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6187764953726669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6187764953726669\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:49,847] Trial 302 finished with value: 0.7855096804003988 and parameters: {'learning_rate': 0.0678178137973748, 'feature_fraction': 0.6705247784537579, 'bagging_fraction': 0.6187764953726669, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6705247784537579, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6705247784537579\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6187764953726669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6187764953726669\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451757603021438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451757603021438\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8639813352990621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8639813352990621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451757603021438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451757603021438\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8639813352990621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8639813352990621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7451757603021438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451757603021438\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8639813352990621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8639813352990621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:50,707] Trial 303 finished with value: 0.7893190801419135 and parameters: {'learning_rate': 0.08722398989505879, 'feature_fraction': 0.7451757603021438, 'bagging_fraction': 0.8639813352990621, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7451757603021438, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451757603021438\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8639813352990621, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8639813352990621\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7534041469212849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7534041469212849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8669155557534788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669155557534788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7534041469212849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7534041469212849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8669155557534788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669155557534788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7534041469212849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7534041469212849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8669155557534788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669155557534788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:51,544] Trial 304 finished with value: 0.7884091229875558 and parameters: {'learning_rate': 0.08871824343240746, 'feature_fraction': 0.7534041469212849, 'bagging_fraction': 0.8669155557534788, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7534041469212849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7534041469212849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8669155557534788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8669155557534788\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7429680771323178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429680771323178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734098525415857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734098525415857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7429680771323178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429680771323178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734098525415857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734098525415857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003635 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7429680771323178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429680771323178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734098525415857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734098525415857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:00:52,656] Trial 305 finished with value: 0.7885751899979895 and parameters: {'learning_rate': 0.04307660638500084, 'feature_fraction': 0.7429680771323178, 'bagging_fraction': 0.8734098525415857, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7429680771323178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429680771323178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8734098525415857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734098525415857\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7477717318950337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7477717318950337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7214034842092449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7214034842092449\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7477717318950337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7477717318950337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7214034842092449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7214034842092449\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7477717318950337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7477717318950337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7214034842092449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7214034842092449\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:53,851] Trial 306 finished with value: 0.7862039906537638 and parameters: {'learning_rate': 0.05248020721010212, 'feature_fraction': 0.7477717318950337, 'bagging_fraction': 0.7214034842092449, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7477717318950337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7477717318950337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7214034842092449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7214034842092449\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7390223276656387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390223276656387\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8607421011421602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8607421011421602\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7390223276656387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390223276656387\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8607421011421602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8607421011421602\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7390223276656387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390223276656387\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8607421011421602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8607421011421602\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:55,022] Trial 307 finished with value: 0.7873169814398738 and parameters: {'learning_rate': 0.08843338066434041, 'feature_fraction': 0.7390223276656387, 'bagging_fraction': 0.8607421011421602, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7390223276656387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390223276656387\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8607421011421602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8607421011421602\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7241884778581854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7241884778581854\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865242155001769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865242155001769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7241884778581854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7241884778581854\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865242155001769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865242155001769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009840 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7241884778581854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7241884778581854\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865242155001769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865242155001769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:56,287] Trial 308 finished with value: 0.7842239158003338 and parameters: {'learning_rate': 0.06540967217741386, 'feature_fraction': 0.7241884778581854, 'bagging_fraction': 0.865242155001769, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7241884778581854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7241884778581854\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.865242155001769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.865242155001769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7299700483278212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299700483278212\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8823020440650546, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823020440650546\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7299700483278212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299700483278212\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8823020440650546, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823020440650546\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013306 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7299700483278212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299700483278212\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8823020440650546, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823020440650546\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:57,612] Trial 309 finished with value: 0.7872110035513564 and parameters: {'learning_rate': 0.0744929074647013, 'feature_fraction': 0.7299700483278212, 'bagging_fraction': 0.8823020440650546, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7299700483278212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7299700483278212\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8823020440650546, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823020440650546\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7028399043008569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7028399043008569\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6312169941562287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6312169941562287\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7028399043008569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7028399043008569\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6312169941562287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6312169941562287\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012579 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7028399043008569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7028399043008569\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6312169941562287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6312169941562287\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:00:58,900] Trial 310 finished with value: 0.7902486989793492 and parameters: {'learning_rate': 0.06032812027040553, 'feature_fraction': 0.7028399043008569, 'bagging_fraction': 0.6312169941562287, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7028399043008569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7028399043008569\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6312169941562287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6312169941562287\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7009937806125496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7009937806125496\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6231825544184572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6231825544184572\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7009937806125496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7009937806125496\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6231825544184572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6231825544184572\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013004 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7009937806125496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7009937806125496\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6231825544184572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6231825544184572\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:00,039] Trial 311 finished with value: 0.7891719516830873 and parameters: {'learning_rate': 0.08522017844780785, 'feature_fraction': 0.7009937806125496, 'bagging_fraction': 0.6231825544184572, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7009937806125496, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7009937806125496\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6231825544184572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6231825544184572\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6997058810050335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6997058810050335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6174792612251063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6174792612251063\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6997058810050335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6997058810050335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6174792612251063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6174792612251063\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6997058810050335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6997058810050335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6174792612251063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6174792612251063\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:00,996] Trial 312 finished with value: 0.7688279615498226 and parameters: {'learning_rate': 0.00010709562151202153, 'feature_fraction': 0.6997058810050335, 'bagging_fraction': 0.6174792612251063, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6997058810050335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6997058810050335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6174792612251063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6174792612251063\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6923848585129471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923848585129471\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6263390707536309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6263390707536309\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6923848585129471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923848585129471\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6263390707536309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6263390707536309\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6923848585129471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923848585129471\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6263390707536309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6263390707536309\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:01,793] Trial 313 finished with value: 0.784561351327367 and parameters: {'learning_rate': 0.09065708198623447, 'feature_fraction': 0.6923848585129471, 'bagging_fraction': 0.6263390707536309, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6923848585129471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6923848585129471\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6263390707536309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6263390707536309\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6858081842436405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6858081842436405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6053514235681254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6053514235681254\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6858081842436405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6858081842436405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6053514235681254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6053514235681254\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006728 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6858081842436405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6858081842436405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6053514235681254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6053514235681254\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:02,656] Trial 314 finished with value: 0.7856187591426007 and parameters: {'learning_rate': 0.08027196069828504, 'feature_fraction': 0.6858081842436405, 'bagging_fraction': 0.6053514235681254, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6858081842436405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6858081842436405\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6053514235681254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6053514235681254\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7039764248082143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7039764248082143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6106250878829036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6106250878829036\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7039764248082143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7039764248082143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6106250878829036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6106250878829036\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010970 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7039764248082143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7039764248082143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6106250878829036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6106250878829036\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:03,587] Trial 315 finished with value: 0.783285317955931 and parameters: {'learning_rate': 0.0999615722159475, 'feature_fraction': 0.7039764248082143, 'bagging_fraction': 0.6106250878829036, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7039764248082143, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7039764248082143\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6106250878829036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6106250878829036\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7014798069888647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7014798069888647\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6261799772586253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6261799772586253\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7014798069888647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7014798069888647\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6261799772586253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6261799772586253\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007636 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7014798069888647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7014798069888647\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6261799772586253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6261799772586253\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:04,444] Trial 316 finished with value: 0.7879883871245451 and parameters: {'learning_rate': 0.0763381545008306, 'feature_fraction': 0.7014798069888647, 'bagging_fraction': 0.6261799772586253, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7014798069888647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7014798069888647\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6261799772586253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6261799772586253\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086436321495125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086436321495125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630495499110801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630495499110801\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086436321495125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086436321495125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630495499110801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630495499110801\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086436321495125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086436321495125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630495499110801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630495499110801\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:05,281] Trial 317 finished with value: 0.7871888150882048 and parameters: {'learning_rate': 0.06550570922583351, 'feature_fraction': 0.7086436321495125, 'bagging_fraction': 0.630495499110801, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7086436321495125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086436321495125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.630495499110801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.630495499110801\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7092016168036214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092016168036214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.618925027818433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.618925027818433\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7092016168036214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092016168036214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.618925027818433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.618925027818433\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006503 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7092016168036214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092016168036214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.618925027818433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.618925027818433\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:06,164] Trial 318 finished with value: 0.7874602700070109 and parameters: {'learning_rate': 0.08671930551265689, 'feature_fraction': 0.7092016168036214, 'bagging_fraction': 0.618925027818433, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7092016168036214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7092016168036214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.618925027818433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.618925027818433\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.693705104091057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.693705104091057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295196365255243, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295196365255243\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.693705104091057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.693705104091057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295196365255243, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295196365255243\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.693705104091057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.693705104091057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295196365255243, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295196365255243\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:06,965] Trial 319 finished with value: 0.7713828450552147 and parameters: {'learning_rate': 0.0042349551016573495, 'feature_fraction': 0.693705104091057, 'bagging_fraction': 0.6295196365255243, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.693705104091057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.693705104091057\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295196365255243, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295196365255243\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6785677127677632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6785677127677632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6353615353456141, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6353615353456141\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6785677127677632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6785677127677632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6353615353456141, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6353615353456141\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6785677127677632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6785677127677632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6353615353456141, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6353615353456141\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:07,735] Trial 320 finished with value: 0.7871356636843969 and parameters: {'learning_rate': 0.07074630376981217, 'feature_fraction': 0.6785677127677632, 'bagging_fraction': 0.6353615353456141, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6785677127677632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6785677127677632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6353615353456141, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6353615353456141\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717532369540029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717532369540029\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6348533935441105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6348533935441105\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717532369540029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717532369540029\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6348533935441105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6348533935441105\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717532369540029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717532369540029\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6348533935441105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6348533935441105\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:08,455] Trial 321 finished with value: 0.7886405344922114 and parameters: {'learning_rate': 0.059245353424846804, 'feature_fraction': 0.717532369540029, 'bagging_fraction': 0.6348533935441105, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.717532369540029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717532369540029\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6348533935441105, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6348533935441105\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7000246656216789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000246656216789\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238250297485874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238250297485874\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7000246656216789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000246656216789\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238250297485874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238250297485874\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7000246656216789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000246656216789\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238250297485874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238250297485874\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:09,200] Trial 322 finished with value: 0.7844273699626634 and parameters: {'learning_rate': 0.08667058273162992, 'feature_fraction': 0.7000246656216789, 'bagging_fraction': 0.6238250297485874, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7000246656216789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000246656216789\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6238250297485874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6238250297485874\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7120901160968162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120901160968162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6412953110216046, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6412953110216046\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7120901160968162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120901160968162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6412953110216046, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6412953110216046\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007643 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7120901160968162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120901160968162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6412953110216046, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6412953110216046\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:10,071] Trial 323 finished with value: 0.7904409176056291 and parameters: {'learning_rate': 0.07197475947955187, 'feature_fraction': 0.7120901160968162, 'bagging_fraction': 0.6412953110216046, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7120901160968162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120901160968162\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6412953110216046, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6412953110216046\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086814387631706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086814387631706\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.850774670409262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.850774670409262\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086814387631706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086814387631706\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.850774670409262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.850774670409262\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7086814387631706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086814387631706\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.850774670409262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.850774670409262\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:11,148] Trial 324 finished with value: 0.7871854332472792 and parameters: {'learning_rate': 0.07618599226810677, 'feature_fraction': 0.7086814387631706, 'bagging_fraction': 0.850774670409262, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7086814387631706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086814387631706\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.850774670409262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.850774670409262\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6903306099002963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6903306099002963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7769602780298192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769602780298192\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6903306099002963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6903306099002963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7769602780298192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769602780298192\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011753 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6903306099002963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6903306099002963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7769602780298192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769602780298192\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:12,285] Trial 325 finished with value: 0.7823586827912938 and parameters: {'learning_rate': 0.09948574142048237, 'feature_fraction': 0.6903306099002963, 'bagging_fraction': 0.7769602780298192, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6903306099002963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6903306099002963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7769602780298192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769602780298192\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7181345606005458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7181345606005458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.69893042966476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.69893042966476\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7181345606005458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7181345606005458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.69893042966476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.69893042966476\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013998 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7181345606005458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7181345606005458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.69893042966476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.69893042966476\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:13,551] Trial 326 finished with value: 0.7692850609286421 and parameters: {'learning_rate': 0.0004511235098922257, 'feature_fraction': 0.7181345606005458, 'bagging_fraction': 0.69893042966476, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7181345606005458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7181345606005458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.69893042966476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.69893042966476\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7127826738087294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7127826738087294\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638733751991527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638733751991527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7127826738087294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7127826738087294\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638733751991527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638733751991527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013768 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7127826738087294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7127826738087294\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638733751991527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638733751991527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:14,795] Trial 327 finished with value: 0.7896550695321921 and parameters: {'learning_rate': 0.06951206680170977, 'feature_fraction': 0.7127826738087294, 'bagging_fraction': 0.638733751991527, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7127826738087294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7127826738087294\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.638733751991527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.638733751991527\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7121494916152301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121494916152301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6407061877202709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6407061877202709\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7121494916152301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121494916152301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6407061877202709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6407061877202709\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011899 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7121494916152301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121494916152301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6407061877202709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6407061877202709\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:16,057] Trial 328 finished with value: 0.786837728268376 and parameters: {'learning_rate': 0.08125885585150777, 'feature_fraction': 0.7121494916152301, 'bagging_fraction': 0.6407061877202709, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7121494916152301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121494916152301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6407061877202709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6407061877202709\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6969340238544779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969340238544779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6413857700190667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6413857700190667\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6969340238544779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969340238544779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6413857700190667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6413857700190667\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015136 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6969340238544779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969340238544779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6413857700190667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6413857700190667\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:17,287] Trial 329 finished with value: 0.7879625989412369 and parameters: {'learning_rate': 0.07051865684059544, 'feature_fraction': 0.6969340238544779, 'bagging_fraction': 0.6413857700190667, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6969340238544779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6969340238544779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6413857700190667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6413857700190667\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7046180216395286, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7046180216395286\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6465869924419019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6465869924419019\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7046180216395286, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7046180216395286\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6465869924419019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6465869924419019\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006646 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7046180216395286, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7046180216395286\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6465869924419019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6465869924419019\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:18,524] Trial 330 finished with value: 0.7823987876070195 and parameters: {'learning_rate': 0.08599618054772948, 'feature_fraction': 0.7046180216395286, 'bagging_fraction': 0.6465869924419019, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7046180216395286, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7046180216395286\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6465869924419019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6465869924419019\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156982723817347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156982723817347\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.637076477013232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.637076477013232\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7156982723817347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156982723817347\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.637076477013232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.637076477013232\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156982723817347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156982723817347\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.637076477013232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.637076477013232\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:19,434] Trial 331 finished with value: 0.7888012282294286 and parameters: {'learning_rate': 0.06760055039739346, 'feature_fraction': 0.7156982723817347, 'bagging_fraction': 0.637076477013232, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7156982723817347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156982723817347\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.637076477013232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.637076477013232\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851644811565718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851644811565718\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6209792464975463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6209792464975463\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851644811565718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851644811565718\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6209792464975463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6209792464975463\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851644811565718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851644811565718\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6209792464975463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6209792464975463\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:20,258] Trial 332 finished with value: 0.7886039270729645 and parameters: {'learning_rate': 0.07662951513487172, 'feature_fraction': 0.6851644811565718, 'bagging_fraction': 0.6209792464975463, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6851644811565718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851644811565718\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6209792464975463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6209792464975463\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6599270301781232, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6599270301781232\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.838422775247247, subsample=1.0 will be ignored. Current value: bagging_fraction=0.838422775247247\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6599270301781232, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6599270301781232\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.838422775247247, subsample=1.0 will be ignored. Current value: bagging_fraction=0.838422775247247\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6599270301781232, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6599270301781232\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.838422775247247, subsample=1.0 will be ignored. Current value: bagging_fraction=0.838422775247247\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:21,131] Trial 333 finished with value: 0.7888620323175194 and parameters: {'learning_rate': 0.08873712183853563, 'feature_fraction': 0.6599270301781232, 'bagging_fraction': 0.838422775247247, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6599270301781232, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6599270301781232\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.838422775247247, subsample=1.0 will be ignored. Current value: bagging_fraction=0.838422775247247\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712537410035671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712537410035671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8144979021942232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144979021942232\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712537410035671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712537410035671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8144979021942232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144979021942232\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712537410035671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712537410035671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8144979021942232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144979021942232\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:22,015] Trial 334 finished with value: 0.7889405407288133 and parameters: {'learning_rate': 0.06357923779852737, 'feature_fraction': 0.712537410035671, 'bagging_fraction': 0.8144979021942232, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.712537410035671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712537410035671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8144979021942232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8144979021942232\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8485838183201362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8485838183201362\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571942783617478, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571942783617478\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8485838183201362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8485838183201362\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571942783617478, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571942783617478\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003832 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8485838183201362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8485838183201362\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571942783617478, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571942783617478\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:22,878] Trial 335 finished with value: 0.7844655237656779 and parameters: {'learning_rate': 0.07599699101769525, 'feature_fraction': 0.8485838183201362, 'bagging_fraction': 0.8571942783617478, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8485838183201362, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8485838183201362\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8571942783617478, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8571942783617478\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7040550749479885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7040550749479885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6483232940534036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6483232940534036\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7040550749479885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7040550749479885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6483232940534036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6483232940534036\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7040550749479885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7040550749479885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6483232940534036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6483232940534036\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:23,676] Trial 336 finished with value: 0.7840584389839387 and parameters: {'learning_rate': 0.08895657002906183, 'feature_fraction': 0.7040550749479885, 'bagging_fraction': 0.6483232940534036, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7040550749479885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7040550749479885\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6483232940534036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6483232940534036\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7212541386227737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7212541386227737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8042447630609267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042447630609267\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7212541386227737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7212541386227737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8042447630609267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042447630609267\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7212541386227737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7212541386227737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8042447630609267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042447630609267\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:24,552] Trial 337 finished with value: 0.7888003691575223 and parameters: {'learning_rate': 0.06336750713199743, 'feature_fraction': 0.7212541386227737, 'bagging_fraction': 0.8042447630609267, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7212541386227737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7212541386227737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8042447630609267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8042447630609267\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6974607251037377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6974607251037377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6418957769835618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6418957769835618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6974607251037377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6974607251037377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6418957769835618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6418957769835618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6974607251037377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6974607251037377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6418957769835618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6418957769835618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:25,428] Trial 338 finished with value: 0.7722140483873514 and parameters: {'learning_rate': 0.0022239868588393263, 'feature_fraction': 0.6974607251037377, 'bagging_fraction': 0.6418957769835618, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6974607251037377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6974607251037377\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6418957769835618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6418957769835618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.724125441784815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724125441784815\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8286474305689191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8286474305689191\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.724125441784815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724125441784815\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8286474305689191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8286474305689191\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.724125441784815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724125441784815\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8286474305689191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8286474305689191\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:26,283] Trial 339 finished with value: 0.7882049711523078 and parameters: {'learning_rate': 0.07586315029848549, 'feature_fraction': 0.724125441784815, 'bagging_fraction': 0.8286474305689191, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.724125441784815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724125441784815\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8286474305689191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8286474305689191\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071764490422336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071764490422336\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6334178859392267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6334178859392267\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071764490422336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071764490422336\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6334178859392267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6334178859392267\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071764490422336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071764490422336\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6334178859392267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6334178859392267\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:27,068] Trial 340 finished with value: 0.7843406990857358 and parameters: {'learning_rate': 0.09576422241837221, 'feature_fraction': 0.9071764490422336, 'bagging_fraction': 0.6334178859392267, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9071764490422336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071764490422336\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6334178859392267, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6334178859392267\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.835862646731791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.835862646731791\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7952792871461308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7952792871461308\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.835862646731791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.835862646731791\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7952792871461308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7952792871461308\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.835862646731791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.835862646731791\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7952792871461308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7952792871461308\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:27,876] Trial 341 finished with value: 0.7849878734375314 and parameters: {'learning_rate': 0.09973564417960781, 'feature_fraction': 0.835862646731791, 'bagging_fraction': 0.7952792871461308, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.835862646731791, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.835862646731791\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7952792871461308, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7952792871461308\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6499633936750947, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499633936750947\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7129676388060645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7129676388060645\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6499633936750947, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499633936750947\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7129676388060645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7129676388060645\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6499633936750947, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499633936750947\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7129676388060645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7129676388060645\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:28,694] Trial 342 finished with value: 0.7864415629323116 and parameters: {'learning_rate': 0.06715992576155212, 'feature_fraction': 0.6499633936750947, 'bagging_fraction': 0.7129676388060645, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6499633936750947, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499633936750947\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7129676388060645, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7129676388060645\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7080189133118577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7080189133118577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8912405723504294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8912405723504294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7080189133118577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7080189133118577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8912405723504294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8912405723504294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7080189133118577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7080189133118577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8912405723504294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8912405723504294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:29,840] Trial 343 finished with value: 0.7846571865426643 and parameters: {'learning_rate': 0.08241616623080289, 'feature_fraction': 0.7080189133118577, 'bagging_fraction': 0.8912405723504294, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7080189133118577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7080189133118577\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8912405723504294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8912405723504294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7169064364578973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169064364578973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6112140205838198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6112140205838198\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7169064364578973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169064364578973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6112140205838198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6112140205838198\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007360 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7169064364578973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169064364578973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6112140205838198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6112140205838198\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:30,996] Trial 344 finished with value: 0.7844905040962931 and parameters: {'learning_rate': 0.05440252314574492, 'feature_fraction': 0.7169064364578973, 'bagging_fraction': 0.6112140205838198, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7169064364578973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169064364578973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6112140205838198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6112140205838198\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6957020933404687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6957020933404687\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6592256750757681, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6592256750757681\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6957020933404687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6957020933404687\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6592256750757681, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6592256750757681\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006024 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6957020933404687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6957020933404687\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6592256750757681, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6592256750757681\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:32,171] Trial 345 finished with value: 0.7870893482898496 and parameters: {'learning_rate': 0.06111200818641951, 'feature_fraction': 0.6957020933404687, 'bagging_fraction': 0.6592256750757681, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6957020933404687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6957020933404687\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6592256750757681, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6592256750757681\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6810968077750745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6810968077750745\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8763452905249751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8763452905249751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6810968077750745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6810968077750745\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8763452905249751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8763452905249751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011841 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6810968077750745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6810968077750745\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8763452905249751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8763452905249751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:33,503] Trial 346 finished with value: 0.7874609794166411 and parameters: {'learning_rate': 0.07270722755215356, 'feature_fraction': 0.6810968077750745, 'bagging_fraction': 0.8763452905249751, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6810968077750745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6810968077750745\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8763452905249751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8763452905249751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7244371037198735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7244371037198735\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8469927765667058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8469927765667058\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7244371037198735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7244371037198735\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8469927765667058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8469927765667058\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006900 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7244371037198735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7244371037198735\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8469927765667058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8469927765667058\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:34,816] Trial 347 finished with value: 0.7892551507068218 and parameters: {'learning_rate': 0.08313237336929129, 'feature_fraction': 0.7244371037198735, 'bagging_fraction': 0.8469927765667058, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7244371037198735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7244371037198735\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8469927765667058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8469927765667058\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7276212067932301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276212067932301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8408114690204506, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8408114690204506\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7276212067932301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276212067932301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8408114690204506, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8408114690204506\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005236 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7276212067932301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276212067932301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8408114690204506, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8408114690204506\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:36,121] Trial 348 finished with value: 0.786365860385907 and parameters: {'learning_rate': 0.06641966886436804, 'feature_fraction': 0.7276212067932301, 'bagging_fraction': 0.8408114690204506, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7276212067932301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276212067932301\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8408114690204506, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8408114690204506\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7249695572790711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7249695572790711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8490677052513601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8490677052513601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7249695572790711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7249695572790711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8490677052513601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8490677052513601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7249695572790711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7249695572790711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8490677052513601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8490677052513601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:37,338] Trial 349 finished with value: 0.7834173955274131 and parameters: {'learning_rate': 0.05762179482163442, 'feature_fraction': 0.7249695572790711, 'bagging_fraction': 0.8490677052513601, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7249695572790711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7249695572790711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8490677052513601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8490677052513601\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7186967672745411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7186967672745411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8531099760353943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8531099760353943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7186967672745411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7186967672745411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8531099760353943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8531099760353943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006426 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7186967672745411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7186967672745411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8531099760353943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8531099760353943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:38,185] Trial 350 finished with value: 0.7884603701664005 and parameters: {'learning_rate': 0.07534006513939917, 'feature_fraction': 0.7186967672745411, 'bagging_fraction': 0.8531099760353943, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7186967672745411, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7186967672745411\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8531099760353943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8531099760353943\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7257186092639973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257186092639973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8623841583511086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623841583511086\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7257186092639973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257186092639973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8623841583511086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623841583511086\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007927 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7257186092639973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257186092639973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8623841583511086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623841583511086\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:39,032] Trial 351 finished with value: 0.7843179752573629 and parameters: {'learning_rate': 0.09993556849382465, 'feature_fraction': 0.7257186092639973, 'bagging_fraction': 0.8623841583511086, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7257186092639973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257186092639973\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8623841583511086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623841583511086\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7102132208570879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7102132208570879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8439830646505214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8439830646505214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7102132208570879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7102132208570879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8439830646505214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8439830646505214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006502 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7102132208570879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7102132208570879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8439830646505214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8439830646505214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:39,885] Trial 352 finished with value: 0.7868769335697622 and parameters: {'learning_rate': 0.08250410651738085, 'feature_fraction': 0.7102132208570879, 'bagging_fraction': 0.8439830646505214, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7102132208570879, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7102132208570879\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8439830646505214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8439830646505214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7324164627186529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7324164627186529\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8674668080185338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8674668080185338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7324164627186529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7324164627186529\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8674668080185338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8674668080185338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7324164627186529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7324164627186529\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8674668080185338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8674668080185338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:40,757] Trial 353 finished with value: 0.7886700753878733 and parameters: {'learning_rate': 0.06918478489047651, 'feature_fraction': 0.7324164627186529, 'bagging_fraction': 0.8674668080185338, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7324164627186529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7324164627186529\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8674668080185338, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8674668080185338\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717533628390016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717533628390016\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8302300440558074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8302300440558074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717533628390016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717533628390016\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8302300440558074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8302300440558074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.717533628390016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717533628390016\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8302300440558074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8302300440558074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:41,669] Trial 354 finished with value: 0.7870545803847636 and parameters: {'learning_rate': 0.048150573216306815, 'feature_fraction': 0.717533628390016, 'bagging_fraction': 0.8302300440558074, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.717533628390016, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717533628390016\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8302300440558074, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8302300440558074\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6679728327858977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6679728327858977\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8533198284254524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8533198284254524\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6679728327858977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6679728327858977\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8533198284254524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8533198284254524\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6679728327858977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6679728327858977\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8533198284254524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8533198284254524\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:42,553] Trial 355 finished with value: 0.7863559224606241 and parameters: {'learning_rate': 0.05859174788644302, 'feature_fraction': 0.6679728327858977, 'bagging_fraction': 0.8533198284254524, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6679728327858977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6679728327858977\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8533198284254524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8533198284254524\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.731429445394562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.731429445394562\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390038213038997, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390038213038997\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.731429445394562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.731429445394562\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390038213038997, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390038213038997\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.731429445394562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.731429445394562\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390038213038997, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390038213038997\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:43,350] Trial 356 finished with value: 0.7904007748759225 and parameters: {'learning_rate': 0.08574014138816831, 'feature_fraction': 0.731429445394562, 'bagging_fraction': 0.8390038213038997, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.731429445394562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.731429445394562\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8390038213038997, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8390038213038997\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7301742184800747, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301742184800747\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8192629332302851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8192629332302851\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7301742184800747, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301742184800747\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8192629332302851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8192629332302851\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003559 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7301742184800747, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301742184800747\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8192629332302851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8192629332302851\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:44,155] Trial 357 finished with value: 0.7815190167632022 and parameters: {'learning_rate': 0.08866672351042774, 'feature_fraction': 0.7301742184800747, 'bagging_fraction': 0.8192629332302851, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7301742184800747, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301742184800747\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8192629332302851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8192629332302851\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131657700242862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131657700242862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356586615922372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356586615922372\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131657700242862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131657700242862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356586615922372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356586615922372\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003758 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131657700242862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131657700242862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356586615922372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356586615922372\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:44,993] Trial 358 finished with value: 0.7870260688606633 and parameters: {'learning_rate': 0.06942987149682427, 'feature_fraction': 0.7131657700242862, 'bagging_fraction': 0.8356586615922372, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7131657700242862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131657700242862\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8356586615922372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8356586615922372\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346863808230875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346863808230875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406859657315049, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406859657315049\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346863808230875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346863808230875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406859657315049, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406859657315049\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7346863808230875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346863808230875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406859657315049, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406859657315049\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:45,908] Trial 359 finished with value: 0.7692331266424901 and parameters: {'learning_rate': 0.00021711574861365597, 'feature_fraction': 0.7346863808230875, 'bagging_fraction': 0.8406859657315049, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7346863808230875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346863808230875\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406859657315049, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406859657315049\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234390645015824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234390645015824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8269307628439936, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8269307628439936\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234390645015824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234390645015824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8269307628439936, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8269307628439936\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7234390645015824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234390645015824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8269307628439936, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8269307628439936\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:46,851] Trial 360 finished with value: 0.774964861213687 and parameters: {'learning_rate': 0.015279017915443293, 'feature_fraction': 0.7234390645015824, 'bagging_fraction': 0.8269307628439936, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7234390645015824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7234390645015824\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8269307628439936, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8269307628439936\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8583226343928976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8583226343928976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467689266681618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467689266681618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8583226343928976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8583226343928976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467689266681618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467689266681618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003884 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8583226343928976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8583226343928976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467689266681618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467689266681618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:48,062] Trial 361 finished with value: 0.7677288056418099 and parameters: {'learning_rate': 0.0010632521504718162, 'feature_fraction': 0.8583226343928976, 'bagging_fraction': 0.8467689266681618, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8583226343928976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8583226343928976\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467689266681618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467689266681618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.709820192111965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.709820192111965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8632818627556097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8632818627556097\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.709820192111965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.709820192111965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8632818627556097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8632818627556097\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.709820192111965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.709820192111965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8632818627556097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8632818627556097\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:49,300] Trial 362 finished with value: 0.7890402111015286 and parameters: {'learning_rate': 0.050035184278247345, 'feature_fraction': 0.709820192111965, 'bagging_fraction': 0.8632818627556097, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.709820192111965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.709820192111965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8632818627556097, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8632818627556097\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7213714519725989, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213714519725989\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.854005109819147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854005109819147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7213714519725989, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213714519725989\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.854005109819147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854005109819147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012532 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7213714519725989, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213714519725989\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.854005109819147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854005109819147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:50,479] Trial 363 finished with value: 0.7865628491767618 and parameters: {'learning_rate': 0.09982614393486526, 'feature_fraction': 0.7213714519725989, 'bagging_fraction': 0.854005109819147, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7213714519725989, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213714519725989\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.854005109819147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.854005109819147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7310669024957775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7310669024957775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8708846303050903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8708846303050903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7310669024957775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7310669024957775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8708846303050903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8708846303050903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009631 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7310669024957775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7310669024957775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8708846303050903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8708846303050903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:51,706] Trial 364 finished with value: 0.788329251272119 and parameters: {'learning_rate': 0.0799416470251481, 'feature_fraction': 0.7310669024957775, 'bagging_fraction': 0.8708846303050903, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7310669024957775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7310669024957775\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8708846303050903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8708846303050903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7037370537044482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7037370537044482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368312819006166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368312819006166\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7037370537044482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7037370537044482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368312819006166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368312819006166\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011362 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7037370537044482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7037370537044482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368312819006166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368312819006166\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:53,028] Trial 365 finished with value: 0.7851048607084684 and parameters: {'learning_rate': 0.06171136334494035, 'feature_fraction': 0.7037370537044482, 'bagging_fraction': 0.8368312819006166, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7037370537044482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7037370537044482\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368312819006166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368312819006166\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6897298628764266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6897298628764266\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8458997993948901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8458997993948901\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6897298628764266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6897298628764266\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8458997993948901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8458997993948901\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011774 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6897298628764266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6897298628764266\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8458997993948901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8458997993948901\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:54,329] Trial 366 finished with value: 0.7889430030450846 and parameters: {'learning_rate': 0.08708314381610799, 'feature_fraction': 0.6897298628764266, 'bagging_fraction': 0.8458997993948901, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6897298628764266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6897298628764266\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8458997993948901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8458997993948901\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6305639477402566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305639477402566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8573345902455777, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8573345902455777\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6305639477402566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305639477402566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8573345902455777, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8573345902455777\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010733 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6305639477402566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305639477402566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8573345902455777, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8573345902455777\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:55,616] Trial 367 finished with value: 0.7854162486033142 and parameters: {'learning_rate': 0.07287178793129201, 'feature_fraction': 0.6305639477402566, 'bagging_fraction': 0.8573345902455777, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6305639477402566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305639477402566\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8573345902455777, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8573345902455777\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7361167740296574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361167740296574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8770741021176862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770741021176862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7361167740296574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361167740296574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8770741021176862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770741021176862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7361167740296574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361167740296574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8770741021176862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770741021176862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:56,585] Trial 368 finished with value: 0.7877229876715852 and parameters: {'learning_rate': 0.053409146193862854, 'feature_fraction': 0.7361167740296574, 'bagging_fraction': 0.8770741021176862, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7361167740296574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7361167740296574\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8770741021176862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770741021176862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7190830164058727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7190830164058727\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8233530658264882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8233530658264882\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7190830164058727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7190830164058727\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8233530658264882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8233530658264882\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003548 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7190830164058727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7190830164058727\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8233530658264882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8233530658264882\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:57,437] Trial 369 finished with value: 0.7888806305399997 and parameters: {'learning_rate': 0.06175255648520122, 'feature_fraction': 0.7190830164058727, 'bagging_fraction': 0.8233530658264882, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7190830164058727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7190830164058727\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8233530658264882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8233530658264882\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712296854959326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712296854959326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8332333069191786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332333069191786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712296854959326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712296854959326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8332333069191786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332333069191786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.712296854959326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712296854959326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8332333069191786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332333069191786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:01:58,354] Trial 370 finished with value: 0.7889177229841022 and parameters: {'learning_rate': 0.03865736068031702, 'feature_fraction': 0.712296854959326, 'bagging_fraction': 0.8332333069191786, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.712296854959326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712296854959326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8332333069191786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8332333069191786\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7265965470949384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265965470949384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6550282554058556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6550282554058556\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7265965470949384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265965470949384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6550282554058556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6550282554058556\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7265965470949384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265965470949384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6550282554058556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6550282554058556\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:01:59,162] Trial 371 finished with value: 0.7870397465974911 and parameters: {'learning_rate': 0.07757110413421514, 'feature_fraction': 0.7265965470949384, 'bagging_fraction': 0.6550282554058556, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7265965470949384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7265965470949384\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6550282554058556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6550282554058556\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386465689286956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386465689286956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8587261942586111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8587261942586111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386465689286956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386465689286956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8587261942586111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8587261942586111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007762 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386465689286956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386465689286956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8587261942586111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8587261942586111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:00,071] Trial 372 finished with value: 0.7867717372305256 and parameters: {'learning_rate': 0.0884802780578841, 'feature_fraction': 0.7386465689286956, 'bagging_fraction': 0.8587261942586111, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7386465689286956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386465689286956\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8587261942586111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8587261942586111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7012117037094228, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7012117037094228\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8441330145046615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8441330145046615\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7012117037094228, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7012117037094228\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8441330145046615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8441330145046615\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006666 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7012117037094228, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7012117037094228\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8441330145046615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8441330145046615\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:00,998] Trial 373 finished with value: 0.787886616276816 and parameters: {'learning_rate': 0.04692391001131727, 'feature_fraction': 0.7012117037094228, 'bagging_fraction': 0.8441330145046615, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7012117037094228, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7012117037094228\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8441330145046615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8441330145046615\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7128292238040876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128292238040876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8650844742635317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8650844742635317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7128292238040876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128292238040876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8650844742635317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8650844742635317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7128292238040876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128292238040876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8650844742635317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8650844742635317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:01,890] Trial 374 finished with value: 0.7866612786706885 and parameters: {'learning_rate': 0.06917067765623312, 'feature_fraction': 0.7128292238040876, 'bagging_fraction': 0.8650844742635317, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7128292238040876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128292238040876\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8650844742635317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8650844742635317\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6933547138617233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6933547138617233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6626612493006987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6626612493006987\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6933547138617233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6933547138617233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6626612493006987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6626612493006987\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007601 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6933547138617233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6933547138617233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6626612493006987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6626612493006987\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:02,784] Trial 375 finished with value: 0.7882379143455087 and parameters: {'learning_rate': 0.05613839315490749, 'feature_fraction': 0.6933547138617233, 'bagging_fraction': 0.6626612493006987, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6933547138617233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6933547138617233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6626612493006987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6626612493006987\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6743473308865248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743473308865248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8866306540539335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8866306540539335\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6743473308865248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743473308865248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8866306540539335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8866306540539335\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6743473308865248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743473308865248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8866306540539335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8866306540539335\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:03,650] Trial 376 finished with value: 0.7853030704525379 and parameters: {'learning_rate': 0.08984890486777475, 'feature_fraction': 0.6743473308865248, 'bagging_fraction': 0.8866306540539335, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 160 with value: 0.7914369906862723.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6743473308865248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743473308865248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8866306540539335, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8866306540539335\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006426 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:04,505] Trial 377 finished with value: 0.7922997372262195 and parameters: {'learning_rate': 0.07571003025023251, 'feature_fraction': 0.7420711826318525, 'bagging_fraction': 0.7072662201846903, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722503744786481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722503744786481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6488160958578751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6488160958578751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722503744786481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722503744786481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6488160958578751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6488160958578751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.722503744786481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722503744786481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6488160958578751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6488160958578751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:05,291] Trial 378 finished with value: 0.7873182663125177 and parameters: {'learning_rate': 0.0755103392665829, 'feature_fraction': 0.722503744786481, 'bagging_fraction': 0.6488160958578751, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.722503744786481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722503744786481\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6488160958578751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6488160958578751\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7064094772196386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7064094772196386\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8517295566545651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8517295566545651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7064094772196386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7064094772196386\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8517295566545651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8517295566545651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7064094772196386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7064094772196386\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8517295566545651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8517295566545651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:06,371] Trial 379 finished with value: 0.7830484799491104 and parameters: {'learning_rate': 0.08235449160108367, 'feature_fraction': 0.7064094772196386, 'bagging_fraction': 0.8517295566545651, 'bagging_freq': 3, 'min_child_samples': 74}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7064094772196386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7064094772196386\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8517295566545651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8517295566545651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8323944564787034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8323944564787034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7330593995112625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7330593995112625\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8323944564787034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8323944564787034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7330593995112625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7330593995112625\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004976 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8323944564787034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8323944564787034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7330593995112625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7330593995112625\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:07,545] Trial 380 finished with value: 0.7877969983714349 and parameters: {'learning_rate': 0.06903061339408852, 'feature_fraction': 0.8323944564787034, 'bagging_fraction': 0.7330593995112625, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8323944564787034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8323944564787034\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7330593995112625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7330593995112625\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7443254850379271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7443254850379271\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749552884719561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749552884719561\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7443254850379271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7443254850379271\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749552884719561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749552884719561\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010858 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7443254850379271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7443254850379271\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749552884719561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749552884719561\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:08,782] Trial 381 finished with value: 0.7865996679917626 and parameters: {'learning_rate': 0.09927665969429489, 'feature_fraction': 0.7443254850379271, 'bagging_fraction': 0.8749552884719561, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7443254850379271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7443254850379271\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749552884719561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749552884719561\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7303073389734257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7303073389734257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537636559709147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537636559709147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7303073389734257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7303073389734257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537636559709147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537636559709147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7303073389734257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7303073389734257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537636559709147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537636559709147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:09,886] Trial 382 finished with value: 0.7880583411545484 and parameters: {'learning_rate': 0.08305737585231972, 'feature_fraction': 0.7303073389734257, 'bagging_fraction': 0.6537636559709147, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7303073389734257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7303073389734257\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6537636559709147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6537636559709147\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7168335537584948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168335537584948\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414123697620288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414123697620288\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7168335537584948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168335537584948\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414123697620288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414123697620288\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011158 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7168335537584948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168335537584948\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414123697620288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414123697620288\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:11,184] Trial 383 finished with value: 0.7880137400256113 and parameters: {'learning_rate': 0.06483924661076582, 'feature_fraction': 0.7168335537584948, 'bagging_fraction': 0.7414123697620288, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7168335537584948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168335537584948\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7414123697620288, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7414123697620288\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813737397021036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813737397021036\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406454282978908, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406454282978908\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6813737397021036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813737397021036\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406454282978908, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406454282978908\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011621 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6813737397021036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813737397021036\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406454282978908, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406454282978908\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:12,551] Trial 384 finished with value: 0.7857797472080449 and parameters: {'learning_rate': 0.07668778158864384, 'feature_fraction': 0.6813737397021036, 'bagging_fraction': 0.8406454282978908, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6813737397021036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813737397021036\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8406454282978908, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8406454282978908\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7063330903414224, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7063330903414224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861776486439172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861776486439172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7063330903414224, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7063330903414224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861776486439172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861776486439172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7063330903414224, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7063330903414224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861776486439172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861776486439172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:13,974] Trial 385 finished with value: 0.7769648107013933 and parameters: {'learning_rate': 0.017767561690755173, 'feature_fraction': 0.7063330903414224, 'bagging_fraction': 0.861776486439172, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7063330903414224, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7063330903414224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.861776486439172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.861776486439172\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7282448821414325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282448821414325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8698644510407482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8698644510407482\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7282448821414325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282448821414325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8698644510407482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8698644510407482\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014701 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7282448821414325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282448821414325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8698644510407482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8698644510407482\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:15,041] Trial 386 finished with value: 0.7804111780533844 and parameters: {'learning_rate': 0.09061822735742663, 'feature_fraction': 0.7282448821414325, 'bagging_fraction': 0.8698644510407482, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7282448821414325, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282448821414325\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8698644510407482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8698644510407482\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8254044695432233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254044695432233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8139544332345111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8139544332345111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8254044695432233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254044695432233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8139544332345111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8139544332345111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004234 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8254044695432233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254044695432233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8139544332345111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8139544332345111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:15,915] Trial 387 finished with value: 0.7873845254842408 and parameters: {'learning_rate': 0.06901596218092923, 'feature_fraction': 0.8254044695432233, 'bagging_fraction': 0.8139544332345111, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8254044695432233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8254044695432233\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8139544332345111, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8139544332345111\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385802930933247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385802930933247\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6422182183727431, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6422182183727431\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385802930933247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385802930933247\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6422182183727431, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6422182183727431\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7385802930933247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385802930933247\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6422182183727431, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6422182183727431\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:16,737] Trial 388 finished with value: 0.7804662091286805 and parameters: {'learning_rate': 0.09980982160757912, 'feature_fraction': 0.7385802930933247, 'bagging_fraction': 0.6422182183727431, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7385802930933247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7385802930933247\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6422182183727431, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6422182183727431\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6531020245177274, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6531020245177274\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85238185986922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85238185986922\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6531020245177274, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6531020245177274\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85238185986922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85238185986922\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004065 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6531020245177274, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6531020245177274\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85238185986922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85238185986922\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:17,594] Trial 389 finished with value: 0.7886702454387723 and parameters: {'learning_rate': 0.0604939416538588, 'feature_fraction': 0.6531020245177274, 'bagging_fraction': 0.85238185986922, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6531020245177274, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6531020245177274\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.85238185986922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85238185986922\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6894669347206472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894669347206472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7868714070186436, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7868714070186436\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6894669347206472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894669347206472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7868714070186436, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7868714070186436\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6894669347206472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894669347206472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7868714070186436, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7868714070186436\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:18,444] Trial 390 finished with value: 0.7872567269166084 and parameters: {'learning_rate': 0.07873395731559074, 'feature_fraction': 0.6894669347206472, 'bagging_fraction': 0.7868714070186436, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6894669347206472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894669347206472\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7868714070186436, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7868714070186436\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7198556790012017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7198556790012017\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6715156266749296, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6715156266749296\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7198556790012017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7198556790012017\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6715156266749296, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6715156266749296\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006607 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7198556790012017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7198556790012017\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6715156266749296, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6715156266749296\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:19,246] Trial 391 finished with value: 0.7856268485199825 and parameters: {'learning_rate': 0.0862476335909884, 'feature_fraction': 0.7198556790012017, 'bagging_fraction': 0.6715156266749296, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7198556790012017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7198556790012017\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6715156266749296, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6715156266749296\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6133979692947911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6133979692947911\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6633941399638381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6633941399638381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6133979692947911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6133979692947911\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6633941399638381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6633941399638381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009897 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6133979692947911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6133979692947911\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6633941399638381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6633941399638381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:20,086] Trial 392 finished with value: 0.7844321957022039 and parameters: {'learning_rate': 0.0716955259475162, 'feature_fraction': 0.6133979692947911, 'bagging_fraction': 0.6633941399638381, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6133979692947911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6133979692947911\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6633941399638381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6633941399638381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7001557893170407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7001557893170407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8316526689055769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8316526689055769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7001557893170407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7001557893170407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8316526689055769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8316526689055769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006161 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7001557893170407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7001557893170407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8316526689055769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8316526689055769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:21,028] Trial 393 finished with value: 0.7808287599902554 and parameters: {'learning_rate': 0.028648667078688933, 'feature_fraction': 0.7001557893170407, 'bagging_fraction': 0.8316526689055769, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7001557893170407, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7001557893170407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8316526689055769, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8316526689055769\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7458030157122914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458030157122914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7239938685663521, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239938685663521\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7458030157122914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458030157122914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7239938685663521, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239938685663521\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006509 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7458030157122914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458030157122914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7239938685663521, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239938685663521\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:21,894] Trial 394 finished with value: 0.7873063733743517 and parameters: {'learning_rate': 0.06334662858587563, 'feature_fraction': 0.7458030157122914, 'bagging_fraction': 0.7239938685663521, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7458030157122914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458030157122914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7239938685663521, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239938685663521\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.729561613221502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729561613221502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8582071900300657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582071900300657\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.729561613221502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729561613221502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8582071900300657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582071900300657\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006613 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.729561613221502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729561613221502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8582071900300657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582071900300657\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:22,796] Trial 395 finished with value: 0.7852950490226372 and parameters: {'learning_rate': 0.08769821942849781, 'feature_fraction': 0.729561613221502, 'bagging_fraction': 0.8582071900300657, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.729561613221502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729561613221502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8582071900300657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582071900300657\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7146266359537451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7146266359537451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7086453987374651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7086453987374651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7146266359537451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7146266359537451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7086453987374651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7086453987374651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7146266359537451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7146266359537451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7086453987374651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7086453987374651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:23,627] Trial 396 finished with value: 0.7884972827807732 and parameters: {'learning_rate': 0.07342339796165069, 'feature_fraction': 0.7146266359537451, 'bagging_fraction': 0.7086453987374651, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7146266359537451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7146266359537451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7086453987374651, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7086453987374651\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7354490645682764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7354490645682764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8794750528783185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8794750528783185\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7354490645682764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7354490645682764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8794750528783185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8794750528783185\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7354490645682764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7354490645682764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8794750528783185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8794750528783185\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:24,477] Trial 397 finished with value: 0.7873080908171052 and parameters: {'learning_rate': 0.053202662087476676, 'feature_fraction': 0.7354490645682764, 'bagging_fraction': 0.8794750528783185, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7354490645682764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7354490645682764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8794750528783185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8794750528783185\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7083968368993423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7083968368993423\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490396299957989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490396299957989\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7083968368993423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7083968368993423\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490396299957989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490396299957989\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009028 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7083968368993423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7083968368993423\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490396299957989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490396299957989\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:25,645] Trial 398 finished with value: 0.7866974261732413 and parameters: {'learning_rate': 0.04474204686109955, 'feature_fraction': 0.7083968368993423, 'bagging_fraction': 0.6490396299957989, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7083968368993423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7083968368993423\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6490396299957989, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6490396299957989\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7220338100648721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7220338100648721\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8689565696398119, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8689565696398119\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7220338100648721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7220338100648721\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8689565696398119, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8689565696398119\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005001 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7220338100648721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7220338100648721\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8689565696398119, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8689565696398119\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:26,811] Trial 399 finished with value: 0.7878193522560873 and parameters: {'learning_rate': 0.07771661104989282, 'feature_fraction': 0.7220338100648721, 'bagging_fraction': 0.8689565696398119, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7220338100648721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7220338100648721\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8689565696398119, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8689565696398119\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.818872597204292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.818872597204292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7600786811093457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7600786811093457\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.818872597204292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.818872597204292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7600786811093457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7600786811093457\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006187 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.818872597204292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.818872597204292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7600786811093457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7600786811093457\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:28,069] Trial 400 finished with value: 0.7877742237464523 and parameters: {'learning_rate': 0.05952182425843147, 'feature_fraction': 0.818872597204292, 'bagging_fraction': 0.7600786811093457, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.818872597204292, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.818872597204292\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7600786811093457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7600786811093457\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6920621989228628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920621989228628\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467572521392489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467572521392489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6920621989228628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920621989228628\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467572521392489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467572521392489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013080 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6920621989228628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920621989228628\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467572521392489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467572521392489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:29,387] Trial 401 finished with value: 0.7872746096338269 and parameters: {'learning_rate': 0.06736012861077137, 'feature_fraction': 0.6920621989228628, 'bagging_fraction': 0.8467572521392489, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6920621989228628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920621989228628\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8467572521392489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8467572521392489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.749957965191021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.749957965191021\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.824052912193876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.824052912193876\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.749957965191021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.749957965191021\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.824052912193876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.824052912193876\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.749957965191021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.749957965191021\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.824052912193876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.824052912193876\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:30,639] Trial 402 finished with value: 0.7894647390013289 and parameters: {'learning_rate': 0.08991373678752082, 'feature_fraction': 0.749957965191021, 'bagging_fraction': 0.824052912193876, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.749957965191021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.749957965191021\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.824052912193876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.824052912193876\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7536330680754886, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536330680754886\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8084043374518305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084043374518305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7536330680754886, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536330680754886\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8084043374518305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084043374518305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013192 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7536330680754886, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536330680754886\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8084043374518305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084043374518305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:31,929] Trial 403 finished with value: 0.7857587870512451 and parameters: {'learning_rate': 0.08906303303794075, 'feature_fraction': 0.7536330680754886, 'bagging_fraction': 0.8084043374518305, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7536330680754886, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7536330680754886\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8084043374518305, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8084043374518305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7549046452819974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549046452819974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277481774317368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277481774317368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7549046452819974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549046452819974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277481774317368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277481774317368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7549046452819974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549046452819974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277481774317368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277481774317368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:33,247] Trial 404 finished with value: 0.7734939847377446 and parameters: {'learning_rate': 0.007199363183935739, 'feature_fraction': 0.7549046452819974, 'bagging_fraction': 0.8277481774317368, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7549046452819974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7549046452819974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8277481774317368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277481774317368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7452411981185922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7452411981185922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184122214694012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184122214694012\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7452411981185922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7452411981185922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184122214694012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184122214694012\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7452411981185922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7452411981185922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184122214694012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184122214694012\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:34,087] Trial 405 finished with value: 0.7887703790937244 and parameters: {'learning_rate': 0.09049322016104558, 'feature_fraction': 0.7452411981185922, 'bagging_fraction': 0.8184122214694012, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7452411981185922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7452411981185922\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8184122214694012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8184122214694012\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7507247822008808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7507247822008808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8377081339645248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8377081339645248\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7507247822008808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7507247822008808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8377081339645248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8377081339645248\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7507247822008808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7507247822008808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8377081339645248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8377081339645248\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:35,074] Trial 406 finished with value: 0.7709072408955221 and parameters: {'learning_rate': 0.003314923810820059, 'feature_fraction': 0.7507247822008808, 'bagging_fraction': 0.8377081339645248, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7507247822008808, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7507247822008808\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8377081339645248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8377081339645248\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420993269134104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420993269134104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8218918498042251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8218918498042251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420993269134104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420993269134104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8218918498042251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8218918498042251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420993269134104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420993269134104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8218918498042251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8218918498042251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:35,944] Trial 407 finished with value: 0.7823826529250965 and parameters: {'learning_rate': 0.09911888472018981, 'feature_fraction': 0.7420993269134104, 'bagging_fraction': 0.8218918498042251, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7420993269134104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420993269134104\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8218918498042251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8218918498042251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393445328672776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393445328672776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8395498458919841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8395498458919841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393445328672776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393445328672776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8395498458919841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8395498458919841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7393445328672776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393445328672776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8395498458919841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8395498458919841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:36,778] Trial 408 finished with value: 0.79059833921032 and parameters: {'learning_rate': 0.07887949119298099, 'feature_fraction': 0.7393445328672776, 'bagging_fraction': 0.8395498458919841, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7393445328672776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7393445328672776\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8395498458919841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8395498458919841\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7584514999289818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7584514999289818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8325391163489775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8325391163489775\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7584514999289818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7584514999289818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8325391163489775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8325391163489775\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003988 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7584514999289818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7584514999289818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8325391163489775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8325391163489775\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:37,618] Trial 409 finished with value: 0.7870636011262865 and parameters: {'learning_rate': 0.0999616032235879, 'feature_fraction': 0.7584514999289818, 'bagging_fraction': 0.8325391163489775, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7584514999289818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7584514999289818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8325391163489775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8325391163489775\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737086383217806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737086383217806\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8147058649314207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8147058649314207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737086383217806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737086383217806\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8147058649314207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8147058649314207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.737086383217806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737086383217806\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8147058649314207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8147058649314207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:38,479] Trial 410 finished with value: 0.7905075276001323 and parameters: {'learning_rate': 0.07587329332119716, 'feature_fraction': 0.737086383217806, 'bagging_fraction': 0.8147058649314207, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.737086383217806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.737086383217806\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8147058649314207, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8147058649314207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358277116519596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358277116519596\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8088453948042388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8088453948042388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358277116519596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358277116519596\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8088453948042388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8088453948042388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003609 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7358277116519596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358277116519596\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8088453948042388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8088453948042388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:39,299] Trial 411 finished with value: 0.7893235079654404 and parameters: {'learning_rate': 0.07444935897624223, 'feature_fraction': 0.7358277116519596, 'bagging_fraction': 0.8088453948042388, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7358277116519596, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358277116519596\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8088453948042388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8088453948042388\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386164151478131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386164151478131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800702399327489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800702399327489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386164151478131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386164151478131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800702399327489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800702399327489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7386164151478131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386164151478131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800702399327489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800702399327489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:40,154] Trial 412 finished with value: 0.7880166093692985 and parameters: {'learning_rate': 0.06537213112239611, 'feature_fraction': 0.7386164151478131, 'bagging_fraction': 0.800702399327489, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7386164151478131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386164151478131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800702399327489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800702399327489\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851170910730561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851170910730561\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8230530609241316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8230530609241316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851170910730561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851170910730561\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8230530609241316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8230530609241316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003671 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6851170910730561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851170910730561\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8230530609241316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8230530609241316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:41,012] Trial 413 finished with value: 0.7892284275675281 and parameters: {'learning_rate': 0.07608384023208938, 'feature_fraction': 0.6851170910730561, 'bagging_fraction': 0.8230530609241316, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6851170910730561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851170910730561\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8230530609241316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8230530609241316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6671403320083593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6671403320083593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8185625024496652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8185625024496652\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6671403320083593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6671403320083593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8185625024496652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8185625024496652\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6671403320083593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6671403320083593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8185625024496652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8185625024496652\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:41,899] Trial 414 finished with value: 0.7868500969630741 and parameters: {'learning_rate': 0.05952654396952694, 'feature_fraction': 0.6671403320083593, 'bagging_fraction': 0.8185625024496652, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6671403320083593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6671403320083593\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8185625024496652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8185625024496652\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9336952859355037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9336952859355037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8106405915571311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106405915571311\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9336952859355037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9336952859355037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8106405915571311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106405915571311\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9336952859355037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9336952859355037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8106405915571311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106405915571311\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:42,812] Trial 415 finished with value: 0.7876620639932612 and parameters: {'learning_rate': 0.07010687057529033, 'feature_fraction': 0.9336952859355037, 'bagging_fraction': 0.8106405915571311, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9336952859355037, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9336952859355037\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8106405915571311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106405915571311\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6016243289711453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6016243289711453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363859968421311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363859968421311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6016243289711453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6016243289711453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363859968421311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363859968421311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6016243289711453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6016243289711453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363859968421311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363859968421311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:43,936] Trial 416 finished with value: 0.7863654335186708 and parameters: {'learning_rate': 0.0799651592965026, 'feature_fraction': 0.6016243289711453, 'bagging_fraction': 0.8363859968421311, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6016243289711453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6016243289711453\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363859968421311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363859968421311\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7003652370021757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7003652370021757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8170764964304368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8170764964304368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7003652370021757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7003652370021757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8170764964304368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8170764964304368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7003652370021757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7003652370021757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8170764964304368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8170764964304368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:45,113] Trial 417 finished with value: 0.7844189241886882 and parameters: {'learning_rate': 0.06666529175105153, 'feature_fraction': 0.7003652370021757, 'bagging_fraction': 0.8170764964304368, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7003652370021757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7003652370021757\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8170764964304368, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8170764964304368\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.732916942823923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732916942823923\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8034103230115273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8034103230115273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.732916942823923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732916942823923\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8034103230115273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8034103230115273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013176 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.732916942823923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732916942823923\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8034103230115273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8034103230115273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:46,317] Trial 418 finished with value: 0.7870312557961462 and parameters: {'learning_rate': 0.08080810210852439, 'feature_fraction': 0.732916942823923, 'bagging_fraction': 0.8034103230115273, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.732916942823923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732916942823923\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8034103230115273, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8034103230115273\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6770652262711984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6770652262711984\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8247346465176304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8247346465176304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6770652262711984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6770652262711984\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8247346465176304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8247346465176304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010879 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6770652262711984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6770652262711984\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8247346465176304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8247346465176304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:47,695] Trial 419 finished with value: 0.7876893669747632 and parameters: {'learning_rate': 0.05509255962893259, 'feature_fraction': 0.6770652262711984, 'bagging_fraction': 0.8247346465176304, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6770652262711984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6770652262711984\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8247346465176304, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8247346465176304\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7476479994074737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476479994074737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8304802698847618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8304802698847618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7476479994074737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476479994074737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8304802698847618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8304802698847618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7476479994074737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476479994074737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8304802698847618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8304802698847618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:49,013] Trial 420 finished with value: 0.7871523299292957 and parameters: {'learning_rate': 0.07412530782726807, 'feature_fraction': 0.7476479994074737, 'bagging_fraction': 0.8304802698847618, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7476479994074737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476479994074737\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8304802698847618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8304802698847618\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7141355052802478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141355052802478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258104043450933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258104043450933\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7141355052802478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141355052802478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258104043450933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258104043450933\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7141355052802478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141355052802478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258104043450933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258104043450933\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:50,264] Trial 421 finished with value: 0.7876084133984438 and parameters: {'learning_rate': 0.09997602304777566, 'feature_fraction': 0.7141355052802478, 'bagging_fraction': 0.8258104043450933, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7141355052802478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141355052802478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8258104043450933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8258104043450933\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6221656735398742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6221656735398742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8110241078739941, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8110241078739941\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6221656735398742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6221656735398742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8110241078739941, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8110241078739941\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010466 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6221656735398742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6221656735398742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8110241078739941, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8110241078739941\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:51,521] Trial 422 finished with value: 0.7873287719707198 and parameters: {'learning_rate': 0.062287159632934616, 'feature_fraction': 0.6221656735398742, 'bagging_fraction': 0.8110241078739941, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6221656735398742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6221656735398742\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8110241078739941, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8110241078739941\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6449617244519726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6449617244519726\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8405480748974613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8405480748974613\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6449617244519726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6449617244519726\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8405480748974613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8405480748974613\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6449617244519726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6449617244519726\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8405480748974613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8405480748974613\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:52,372] Trial 423 finished with value: 0.7880150559818022 and parameters: {'learning_rate': 0.08723287738646435, 'feature_fraction': 0.6449617244519726, 'bagging_fraction': 0.8405480748974613, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6449617244519726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6449617244519726\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8405480748974613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8405480748974613\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7292210805773801, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7292210805773801\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6335760925468251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6335760925468251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7292210805773801, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7292210805773801\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6335760925468251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6335760925468251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7292210805773801, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7292210805773801\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6335760925468251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6335760925468251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:53,202] Trial 424 finished with value: 0.782594181089419 and parameters: {'learning_rate': 0.07049661519723567, 'feature_fraction': 0.7292210805773801, 'bagging_fraction': 0.6335760925468251, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7292210805773801, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7292210805773801\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6335760925468251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6335760925468251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8762799094024055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762799094024055\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303205519617307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303205519617307\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8762799094024055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762799094024055\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303205519617307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303205519617307\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006019 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8762799094024055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762799094024055\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303205519617307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303205519617307\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:54,125] Trial 425 finished with value: 0.787258083988323 and parameters: {'learning_rate': 0.05099370280770236, 'feature_fraction': 0.8762799094024055, 'bagging_fraction': 0.8303205519617307, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8762799094024055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762799094024055\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8303205519617307, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8303205519617307\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395475331728177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395475331728177\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6385752593312928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6385752593312928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395475331728177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395475331728177\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6385752593312928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6385752593312928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7395475331728177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395475331728177\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6385752593312928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6385752593312928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:54,946] Trial 426 finished with value: 0.7877059725303754 and parameters: {'learning_rate': 0.08130010411097312, 'feature_fraction': 0.7395475331728177, 'bagging_fraction': 0.6385752593312928, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7395475331728177, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7395475331728177\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6385752593312928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6385752593312928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6982443989081883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982443989081883\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8186195846431978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186195846431978\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6982443989081883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982443989081883\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8186195846431978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186195846431978\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6982443989081883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982443989081883\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8186195846431978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186195846431978\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:55,856] Trial 427 finished with value: 0.7878394794823398 and parameters: {'learning_rate': 0.059441372803887754, 'feature_fraction': 0.6982443989081883, 'bagging_fraction': 0.8186195846431978, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6982443989081883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982443989081883\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8186195846431978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186195846431978\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6356936851783769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6356936851783769\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8388550799502928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388550799502928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6356936851783769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6356936851783769\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8388550799502928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388550799502928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6356936851783769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6356936851783769\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8388550799502928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388550799502928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:56,693] Trial 428 finished with value: 0.785938782828489 and parameters: {'learning_rate': 0.08759751565641015, 'feature_fraction': 0.6356936851783769, 'bagging_fraction': 0.8388550799502928, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6356936851783769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6356936851783769\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8388550799502928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388550799502928\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7087502960640226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7087502960640226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8501899482162844, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8501899482162844\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7087502960640226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7087502960640226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8501899482162844, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8501899482162844\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003846 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7087502960640226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7087502960640226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8501899482162844, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8501899482162844\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:02:57,575] Trial 429 finished with value: 0.7891095607722568 and parameters: {'learning_rate': 0.06960590810769104, 'feature_fraction': 0.7087502960640226, 'bagging_fraction': 0.8501899482162844, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7087502960640226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7087502960640226\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8501899482162844, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8501899482162844\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8144932963848498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144932963848498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7164564585746479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7164564585746479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8144932963848498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144932963848498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7164564585746479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7164564585746479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8144932963848498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144932963848498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7164564585746479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7164564585746479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:58,443] Trial 430 finished with value: 0.7862393204082808 and parameters: {'learning_rate': 0.07883351473180132, 'feature_fraction': 0.8144932963848498, 'bagging_fraction': 0.7164564585746479, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8144932963848498, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144932963848498\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7164564585746479, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7164564585746479\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7538138606090622, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7538138606090622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.988938046025103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.988938046025103\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7538138606090622, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7538138606090622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.988938046025103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.988938046025103\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003616 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7538138606090622, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7538138606090622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.988938046025103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.988938046025103\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:02:59,322] Trial 431 finished with value: 0.7850050889582567 and parameters: {'learning_rate': 0.06269202815102352, 'feature_fraction': 0.7538138606090622, 'bagging_fraction': 0.988938046025103, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7538138606090622, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7538138606090622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.988938046025103, subsample=1.0 will be ignored. Current value: bagging_fraction=0.988938046025103\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7219740658733107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219740658733107\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6253293451665162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6253293451665162\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7219740658733107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219740658733107\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6253293451665162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6253293451665162\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7219740658733107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219740658733107\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6253293451665162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6253293451665162\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:00,168] Trial 432 finished with value: 0.7847679888135307 and parameters: {'learning_rate': 0.08900930772684103, 'feature_fraction': 0.7219740658733107, 'bagging_fraction': 0.6253293451665162, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7219740658733107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7219740658733107\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6253293451665162, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6253293451665162\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8253890997587818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8253890997587818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6861917517514395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6861917517514395\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8253890997587818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8253890997587818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6861917517514395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6861917517514395\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8253890997587818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8253890997587818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6861917517514395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6861917517514395\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:01,044] Trial 433 finished with value: 0.7859038822699618 and parameters: {'learning_rate': 0.05422603892140484, 'feature_fraction': 0.8253890997587818, 'bagging_fraction': 0.6861917517514395, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8253890997587818, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8253890997587818\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6861917517514395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6861917517514395\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7337137609248489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337137609248489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432999134648627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432999134648627\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7337137609248489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337137609248489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432999134648627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432999134648627\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7337137609248489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337137609248489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432999134648627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432999134648627\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:02,068] Trial 434 finished with value: 0.7869733445360058 and parameters: {'learning_rate': 0.07419949165313933, 'feature_fraction': 0.7337137609248489, 'bagging_fraction': 0.6432999134648627, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7337137609248489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337137609248489\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6432999134648627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6432999134648627\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7061955950222981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061955950222981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8257052775004972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8257052775004972\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7061955950222981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061955950222981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8257052775004972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8257052775004972\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011971 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7061955950222981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061955950222981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8257052775004972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8257052775004972\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:03,304] Trial 435 finished with value: 0.7869947249524845 and parameters: {'learning_rate': 0.06606493525768163, 'feature_fraction': 0.7061955950222981, 'bagging_fraction': 0.8257052775004972, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7061955950222981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061955950222981\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8257052775004972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8257052775004972\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7640578740187736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640578740187736\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842188875908477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842188875908477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7640578740187736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640578740187736\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842188875908477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842188875908477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010968 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7640578740187736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640578740187736\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842188875908477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842188875908477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:04,707] Trial 436 finished with value: 0.7723876603355583 and parameters: {'learning_rate': 0.010690861702362503, 'feature_fraction': 0.7640578740187736, 'bagging_fraction': 0.842188875908477, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7640578740187736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7640578740187736\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842188875908477, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842188875908477\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6937524141258217, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6937524141258217\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7467421290256833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7467421290256833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6937524141258217, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6937524141258217\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7467421290256833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7467421290256833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6937524141258217, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6937524141258217\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7467421290256833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7467421290256833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:05,994] Trial 437 finished with value: 0.7867004186629027 and parameters: {'learning_rate': 0.07981307795084375, 'feature_fraction': 0.6937524141258217, 'bagging_fraction': 0.7467421290256833, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6937524141258217, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6937524141258217\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7467421290256833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7467421290256833\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8412787563473904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8412787563473904\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8566364115625813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566364115625813\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8412787563473904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8412787563473904\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8566364115625813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566364115625813\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8412787563473904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8412787563473904\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8566364115625813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566364115625813\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:07,316] Trial 438 finished with value: 0.7804589102097063 and parameters: {'learning_rate': 0.09980163081296055, 'feature_fraction': 0.8412787563473904, 'bagging_fraction': 0.8566364115625813, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8412787563473904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8412787563473904\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8566364115625813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8566364115625813\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6621781610073934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621781610073934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9015380466659351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9015380466659351\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6621781610073934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621781610073934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9015380466659351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9015380466659351\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011436 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6621781610073934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621781610073934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9015380466659351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9015380466659351\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:08,678] Trial 439 finished with value: 0.7864070869467987 and parameters: {'learning_rate': 0.051729339404060555, 'feature_fraction': 0.6621781610073934, 'bagging_fraction': 0.9015380466659351, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6621781610073934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621781610073934\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9015380466659351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9015380466659351\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7449730253298337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7449730253298337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295745661719467, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295745661719467\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7449730253298337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7449730253298337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295745661719467, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295745661719467\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010531 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7449730253298337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7449730253298337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295745661719467, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295745661719467\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:09,871] Trial 440 finished with value: 0.7867334983551589 and parameters: {'learning_rate': 0.08845945615107358, 'feature_fraction': 0.7449730253298337, 'bagging_fraction': 0.6295745661719467, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7449730253298337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7449730253298337\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6295745661719467, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6295745661719467\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7165613166903709, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7165613166903709\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8154069603248912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154069603248912\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7165613166903709, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7165613166903709\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8154069603248912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154069603248912\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006772 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7165613166903709, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7165613166903709\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8154069603248912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154069603248912\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:10,744] Trial 441 finished with value: 0.7860814659080351 and parameters: {'learning_rate': 0.06013739770165154, 'feature_fraction': 0.7165613166903709, 'bagging_fraction': 0.8154069603248912, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7165613166903709, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7165613166903709\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8154069603248912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8154069603248912\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728783004205068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728783004205068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6566254732869017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6566254732869017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728783004205068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728783004205068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6566254732869017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6566254732869017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.728783004205068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728783004205068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6566254732869017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6566254732869017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:11,578] Trial 442 finished with value: 0.7881895366695366 and parameters: {'learning_rate': 0.072673645013506, 'feature_fraction': 0.728783004205068, 'bagging_fraction': 0.6566254732869017, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.728783004205068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.728783004205068\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6566254732869017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6566254732869017\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6864910328671654, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6864910328671654\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435174414995442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435174414995442\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6864910328671654, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6864910328671654\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435174414995442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435174414995442\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007671 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6864910328671654, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6864910328671654\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435174414995442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435174414995442\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:12,438] Trial 443 finished with value: 0.7876699721976662 and parameters: {'learning_rate': 0.048134136580028, 'feature_fraction': 0.6864910328671654, 'bagging_fraction': 0.6435174414995442, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6864910328671654, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6864910328671654\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6435174414995442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6435174414995442\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7367267147774421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7367267147774421\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832859862637543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832859862637543\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7367267147774421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7367267147774421\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832859862637543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832859862637543\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7367267147774421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7367267147774421\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832859862637543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832859862637543\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:13,308] Trial 444 finished with value: 0.7901736839934085 and parameters: {'learning_rate': 0.08037321163181436, 'feature_fraction': 0.7367267147774421, 'bagging_fraction': 0.832859862637543, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7367267147774421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7367267147774421\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832859862637543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832859862637543\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7481765581202314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481765581202314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9181859826382748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9181859826382748\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7481765581202314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481765581202314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9181859826382748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9181859826382748\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006495 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7481765581202314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481765581202314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9181859826382748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9181859826382748\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:14,222] Trial 445 finished with value: 0.7852234929234434 and parameters: {'learning_rate': 0.08248060538033486, 'feature_fraction': 0.7481765581202314, 'bagging_fraction': 0.9181859826382748, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7481765581202314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481765581202314\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9181859826382748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9181859826382748\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.736599592952422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.736599592952422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8313546286336868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313546286336868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.736599592952422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.736599592952422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8313546286336868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313546286336868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.736599592952422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.736599592952422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8313546286336868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313546286336868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:15,076] Trial 446 finished with value: 0.7872653811046534 and parameters: {'learning_rate': 0.08920343669640288, 'feature_fraction': 0.736599592952422, 'bagging_fraction': 0.8313546286336868, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.736599592952422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.736599592952422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8313546286336868, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8313546286336868\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7421670698005136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7421670698005136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382659502100013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382659502100013\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7421670698005136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7421670698005136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382659502100013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382659502100013\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7421670698005136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7421670698005136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382659502100013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382659502100013\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:15,903] Trial 447 finished with value: 0.7891134586364619 and parameters: {'learning_rate': 0.07172340769762364, 'feature_fraction': 0.7421670698005136, 'bagging_fraction': 0.8382659502100013, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7421670698005136, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7421670698005136\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382659502100013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382659502100013\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486348468548925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486348468548925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8220838226651582, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8220838226651582\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486348468548925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486348468548925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8220838226651582, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8220838226651582\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7486348468548925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486348468548925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8220838226651582, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8220838226651582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:16,781] Trial 448 finished with value: 0.7891459046031468 and parameters: {'learning_rate': 0.07934368711900712, 'feature_fraction': 0.7486348468548925, 'bagging_fraction': 0.8220838226651582, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7486348468548925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486348468548925\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8220838226651582, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8220838226651582\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7571223740997698, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7571223740997698\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8334809697424641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8334809697424641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7571223740997698, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7571223740997698\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8334809697424641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8334809697424641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006998 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7571223740997698, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7571223740997698\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8334809697424641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8334809697424641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:17,699] Trial 449 finished with value: 0.7904490124323559 and parameters: {'learning_rate': 0.06424781831503765, 'feature_fraction': 0.7571223740997698, 'bagging_fraction': 0.8334809697424641, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7571223740997698, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7571223740997698\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8334809697424641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8334809697424641\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7627767882319265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7627767882319265\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368846029474405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368846029474405\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7627767882319265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7627767882319265\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368846029474405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368846029474405\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7627767882319265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7627767882319265\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368846029474405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368846029474405\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:18,599] Trial 450 finished with value: 0.7876909114536185 and parameters: {'learning_rate': 0.06734328781060946, 'feature_fraction': 0.7627767882319265, 'bagging_fraction': 0.8368846029474405, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7627767882319265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7627767882319265\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8368846029474405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8368846029474405\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7559349223783671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7559349223783671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382346816721366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382346816721366\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7559349223783671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7559349223783671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382346816721366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382346816721366\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7559349223783671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7559349223783671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382346816721366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382346816721366\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:19,454] Trial 451 finished with value: 0.7822210477725309 and parameters: {'learning_rate': 0.09949380281283876, 'feature_fraction': 0.7559349223783671, 'bagging_fraction': 0.8382346816721366, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7559349223783671, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7559349223783671\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382346816721366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382346816721366\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.750859205585691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.750859205585691\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8453304201044317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8453304201044317\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.750859205585691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.750859205585691\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8453304201044317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8453304201044317\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006825 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.750859205585691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.750859205585691\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8453304201044317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8453304201044317\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:20,554] Trial 452 finished with value: 0.7884105675831335 and parameters: {'learning_rate': 0.07736404481165293, 'feature_fraction': 0.750859205585691, 'bagging_fraction': 0.8453304201044317, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.750859205585691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.750859205585691\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8453304201044317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8453304201044317\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7404973485979743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404973485979743\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344108679763944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344108679763944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7404973485979743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404973485979743\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344108679763944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344108679763944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010715 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7404973485979743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404973485979743\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344108679763944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344108679763944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:21,754] Trial 453 finished with value: 0.7867280191255043 and parameters: {'learning_rate': 0.06510848899856736, 'feature_fraction': 0.7404973485979743, 'bagging_fraction': 0.8344108679763944, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7404973485979743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404973485979743\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8344108679763944, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8344108679763944\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7681198564369458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681198564369458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8289726484803803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289726484803803\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7681198564369458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681198564369458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8289726484803803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289726484803803\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012745 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7681198564369458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681198564369458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8289726484803803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289726484803803\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:22,947] Trial 454 finished with value: 0.7843955938239142 and parameters: {'learning_rate': 0.08782172085397488, 'feature_fraction': 0.7681198564369458, 'bagging_fraction': 0.8289726484803803, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7681198564369458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7681198564369458\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8289726484803803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289726484803803\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7573931543189952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573931543189952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8491289895461698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8491289895461698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7573931543189952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573931543189952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8491289895461698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8491289895461698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7573931543189952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573931543189952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8491289895461698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8491289895461698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:24,183] Trial 455 finished with value: 0.7854871825013513 and parameters: {'learning_rate': 0.07108427930351696, 'feature_fraction': 0.7573931543189952, 'bagging_fraction': 0.8491289895461698, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7573931543189952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573931543189952\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8491289895461698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8491289895461698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322934574002793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322934574002793\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6741356061289459, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6741356061289459\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7322934574002793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322934574002793\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6741356061289459, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6741356061289459\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7322934574002793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322934574002793\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6741356061289459, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6741356061289459\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:25,522] Trial 456 finished with value: 0.7700505093234297 and parameters: {'learning_rate': 0.0014707144809489587, 'feature_fraction': 0.7322934574002793, 'bagging_fraction': 0.6741356061289459, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7322934574002793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7322934574002793\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6741356061289459, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6741356061289459\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7401814757031607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7401814757031607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.634668759233502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634668759233502\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7401814757031607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7401814757031607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.634668759233502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634668759233502\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010945 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7401814757031607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7401814757031607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.634668759233502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634668759233502\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:26,787] Trial 457 finished with value: 0.7881308126638344 and parameters: {'learning_rate': 0.08016014918032104, 'feature_fraction': 0.7401814757031607, 'bagging_fraction': 0.634668759233502, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7401814757031607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7401814757031607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.634668759233502, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634668759233502\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7262916118377478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7262916118377478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6183172141542173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6183172141542173\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7262916118377478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7262916118377478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6183172141542173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6183172141542173\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014847 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7262916118377478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7262916118377478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6183172141542173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6183172141542173\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:28,091] Trial 458 finished with value: 0.7856283522480434 and parameters: {'learning_rate': 0.060459829287473725, 'feature_fraction': 0.7262916118377478, 'bagging_fraction': 0.6183172141542173, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7262916118377478, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7262916118377478\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6183172141542173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6183172141542173\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7458642370829404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458642370829404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6460923629943988, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6460923629943988\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7458642370829404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458642370829404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6460923629943988, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6460923629943988\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7458642370829404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458642370829404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6460923629943988, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6460923629943988\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:29,047] Trial 459 finished with value: 0.7846285055532036 and parameters: {'learning_rate': 0.08733321931461628, 'feature_fraction': 0.7458642370829404, 'bagging_fraction': 0.6460923629943988, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7458642370829404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458642370829404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6460923629943988, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6460923629943988\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7352774170024248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7352774170024248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7007722504135385, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7007722504135385\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7352774170024248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7352774170024248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7007722504135385, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7007722504135385\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006883 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7352774170024248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7352774170024248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7007722504135385, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7007722504135385\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:29,912] Trial 460 finished with value: 0.78750178716995 and parameters: {'learning_rate': 0.07015115337760924, 'feature_fraction': 0.7352774170024248, 'bagging_fraction': 0.7007722504135385, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7352774170024248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7352774170024248\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7007722504135385, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7007722504135385\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.753131586709315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.753131586709315\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6608902705719251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6608902705719251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.753131586709315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.753131586709315\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6608902705719251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6608902705719251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.753131586709315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.753131586709315\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6608902705719251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6608902705719251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:30,701] Trial 461 finished with value: 0.7845887080934351 and parameters: {'learning_rate': 0.0994521344950091, 'feature_fraction': 0.753131586709315, 'bagging_fraction': 0.6608902705719251, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.753131586709315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.753131586709315\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6608902705719251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6608902705719251\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7261684081404773, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7261684081404773\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8279695330839169, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279695330839169\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7261684081404773, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7261684081404773\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8279695330839169, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279695330839169\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003821 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7261684081404773, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7261684081404773\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8279695330839169, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279695330839169\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:31,551] Trial 462 finished with value: 0.7889591957962122 and parameters: {'learning_rate': 0.07792730300834078, 'feature_fraction': 0.7261684081404773, 'bagging_fraction': 0.8279695330839169, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7261684081404773, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7261684081404773\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8279695330839169, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8279695330839169\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7402140914401963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402140914401963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9535325911734591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9535325911734591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7402140914401963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402140914401963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9535325911734591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9535325911734591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006159 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7402140914401963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402140914401963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9535325911734591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9535325911734591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:32,493] Trial 463 finished with value: 0.788548701709219 and parameters: {'learning_rate': 0.060656422888883454, 'feature_fraction': 0.7402140914401963, 'bagging_fraction': 0.9535325911734591, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7402140914401963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402140914401963\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9535325911734591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9535325911734591\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7229717609403902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7229717609403902\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7298885647482752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7298885647482752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7229717609403902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7229717609403902\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7298885647482752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7298885647482752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7229717609403902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7229717609403902\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7298885647482752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7298885647482752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:33,345] Trial 464 finished with value: 0.7879453292781802 and parameters: {'learning_rate': 0.0897461705380191, 'feature_fraction': 0.7229717609403902, 'bagging_fraction': 0.7298885647482752, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7229717609403902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7229717609403902\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7298885647482752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7298885647482752\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8626038494518106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8626038494518106\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8465053191465064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8465053191465064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8626038494518106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8626038494518106\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8465053191465064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8465053191465064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003674 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8626038494518106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8626038494518106\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8465053191465064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8465053191465064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:34,214] Trial 465 finished with value: 0.7849658877368474 and parameters: {'learning_rate': 0.06668474333349558, 'feature_fraction': 0.8626038494518106, 'bagging_fraction': 0.8465053191465064, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8626038494518106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8626038494518106\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8465053191465064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8465053191465064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6764613731091302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6764613731091302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6522299102729257, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6522299102729257\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6764613731091302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6764613731091302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6522299102729257, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6522299102729257\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008406 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6764613731091302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6764613731091302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6522299102729257, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6522299102729257\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:35,049] Trial 466 finished with value: 0.7833458862767171 and parameters: {'learning_rate': 0.07689151951894511, 'feature_fraction': 0.6764613731091302, 'bagging_fraction': 0.6522299102729257, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6764613731091302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6764613731091302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6522299102729257, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6522299102729257\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.732216365341369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732216365341369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6907664447916698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6907664447916698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.732216365341369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732216365341369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6907664447916698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6907664447916698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.732216365341369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732216365341369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6907664447916698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6907664447916698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:35,914] Trial 467 finished with value: 0.7697091065676301 and parameters: {'learning_rate': 0.0008617561433026825, 'feature_fraction': 0.732216365341369, 'bagging_fraction': 0.6907664447916698, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.732216365341369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732216365341369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6907664447916698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6907664447916698\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034403368754103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034403368754103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8544719837193636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544719837193636\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034403368754103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034403368754103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8544719837193636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544719837193636\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034403368754103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034403368754103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8544719837193636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544719837193636\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:36,807] Trial 468 finished with value: 0.7854099049631975 and parameters: {'learning_rate': 0.08910322281628014, 'feature_fraction': 0.7034403368754103, 'bagging_fraction': 0.8544719837193636, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7034403368754103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034403368754103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8544719837193636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544719837193636\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7488850286255038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7488850286255038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8125645097806473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8125645097806473\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7488850286255038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7488850286255038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8125645097806473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8125645097806473\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7488850286255038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7488850286255038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8125645097806473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8125645097806473\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:37,739] Trial 469 finished with value: 0.7874308257987396 and parameters: {'learning_rate': 0.06196623201073638, 'feature_fraction': 0.7488850286255038, 'bagging_fraction': 0.8125645097806473, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7488850286255038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7488850286255038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8125645097806473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8125645097806473\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7615422563651812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7615422563651812\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6384645914854744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6384645914854744\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7615422563651812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7615422563651812\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6384645914854744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6384645914854744\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7615422563651812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7615422563651812\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6384645914854744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6384645914854744\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:38,545] Trial 470 finished with value: 0.7889861283524303 and parameters: {'learning_rate': 0.07285110275751656, 'feature_fraction': 0.7615422563651812, 'bagging_fraction': 0.6384645914854744, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7615422563651812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7615422563651812\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6384645914854744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6384645914854744\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7180603280020038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7180603280020038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7718935934110381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7718935934110381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7180603280020038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7180603280020038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7718935934110381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7718935934110381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012711 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7180603280020038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7180603280020038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7718935934110381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7718935934110381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:39,754] Trial 471 finished with value: 0.7892005096055004 and parameters: {'learning_rate': 0.0806511551274943, 'feature_fraction': 0.7180603280020038, 'bagging_fraction': 0.7718935934110381, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7180603280020038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7180603280020038\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7718935934110381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7718935934110381\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7403461285359426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7403461285359426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.841389504608314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.841389504608314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7403461285359426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7403461285359426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.841389504608314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.841389504608314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009928 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7403461285359426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7403461285359426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.841389504608314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.841389504608314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:40,900] Trial 472 finished with value: 0.7817103723430563 and parameters: {'learning_rate': 0.09964939293255633, 'feature_fraction': 0.7403461285359426, 'bagging_fraction': 0.841389504608314, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7403461285359426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7403461285359426\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.841389504608314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.841389504608314\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7120159402265451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120159402265451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800835206216186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800835206216186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7120159402265451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120159402265451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800835206216186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800835206216186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011223 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7120159402265451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120159402265451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800835206216186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800835206216186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:42,098] Trial 473 finished with value: 0.7902117387753923 and parameters: {'learning_rate': 0.05586624663382781, 'feature_fraction': 0.7120159402265451, 'bagging_fraction': 0.800835206216186, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7120159402265451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7120159402265451\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.800835206216186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.800835206216186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7077577196869991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077577196869991\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7949646058351322, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949646058351322\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7077577196869991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077577196869991\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7949646058351322, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949646058351322\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009996 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7077577196869991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077577196869991\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7949646058351322, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949646058351322\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:43,351] Trial 474 finished with value: 0.7882976984265913 and parameters: {'learning_rate': 0.058001109178454614, 'feature_fraction': 0.7077577196869991, 'bagging_fraction': 0.7949646058351322, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7077577196869991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077577196869991\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7949646058351322, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7949646058351322\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7121733343800711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121733343800711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7925228802268214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925228802268214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7121733343800711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121733343800711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7925228802268214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925228802268214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010679 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7121733343800711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121733343800711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7925228802268214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925228802268214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:44,683] Trial 475 finished with value: 0.7874933977148173 and parameters: {'learning_rate': 0.05269994660830522, 'feature_fraction': 0.7121733343800711, 'bagging_fraction': 0.7925228802268214, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7121733343800711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7121733343800711\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7925228802268214, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925228802268214\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6921784929265928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6921784929265928\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8049871651063689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049871651063689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6921784929265928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6921784929265928\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8049871651063689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049871651063689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010803 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6921784929265928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6921784929265928\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8049871651063689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049871651063689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:45,980] Trial 476 finished with value: 0.788354609285481 and parameters: {'learning_rate': 0.06012363145922277, 'feature_fraction': 0.6921784929265928, 'bagging_fraction': 0.8049871651063689, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6921784929265928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6921784929265928\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8049871651063689, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8049871651063689\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6978988273220739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978988273220739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6282604460758554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6282604460758554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6978988273220739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978988273220739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6282604460758554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6282604460758554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011144 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6978988273220739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978988273220739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6282604460758554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6282604460758554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:47,234] Trial 477 finished with value: 0.7890601793271209 and parameters: {'learning_rate': 0.0544609509887377, 'feature_fraction': 0.6978988273220739, 'bagging_fraction': 0.6282604460758554, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6978988273220739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978988273220739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6282604460758554, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6282604460758554\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.719308697248514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.719308697248514\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6790947937081262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6790947937081262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.719308697248514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.719308697248514\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6790947937081262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6790947937081262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009945 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.719308697248514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.719308697248514\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6790947937081262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6790947937081262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:48,167] Trial 478 finished with value: 0.7867112014119673 and parameters: {'learning_rate': 0.06730012166195706, 'feature_fraction': 0.719308697248514, 'bagging_fraction': 0.6790947937081262, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.719308697248514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.719308697248514\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6790947937081262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6790947937081262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7070651594122015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070651594122015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7991530707825679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7991530707825679\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7070651594122015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070651594122015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7991530707825679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7991530707825679\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007521 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7070651594122015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070651594122015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7991530707825679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7991530707825679\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:49,053] Trial 479 finished with value: 0.7847733524283687 and parameters: {'learning_rate': 0.06732983238509689, 'feature_fraction': 0.7070651594122015, 'bagging_fraction': 0.7991530707825679, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7070651594122015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7070651594122015\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7991530707825679, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7991530707825679\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7247790883542917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7247790883542917\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664866319128262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664866319128262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7247790883542917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7247790883542917\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664866319128262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664866319128262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7247790883542917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7247790883542917\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664866319128262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664866319128262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:49,931] Trial 480 finished with value: 0.7872959204910939 and parameters: {'learning_rate': 0.057337999043117684, 'feature_fraction': 0.7247790883542917, 'bagging_fraction': 0.664866319128262, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7247790883542917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7247790883542917\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.664866319128262, subsample=1.0 will be ignored. Current value: bagging_fraction=0.664866319128262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131675693254214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131675693254214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8574592727508671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574592727508671\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131675693254214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131675693254214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8574592727508671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574592727508671\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7131675693254214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131675693254214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8574592727508671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574592727508671\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:50,821] Trial 481 finished with value: 0.7871955179556753 and parameters: {'learning_rate': 0.07226008423296051, 'feature_fraction': 0.7131675693254214, 'bagging_fraction': 0.8574592727508671, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7131675693254214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7131675693254214\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8574592727508671, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8574592727508671\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6989762806610849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6989762806610849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6443966718138858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6443966718138858\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6989762806610849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6989762806610849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6443966718138858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6443966718138858\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6989762806610849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6989762806610849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6443966718138858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6443966718138858\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:51,657] Trial 482 finished with value: 0.7872879225193761 and parameters: {'learning_rate': 0.06276317675715763, 'feature_fraction': 0.6989762806610849, 'bagging_fraction': 0.6443966718138858, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6989762806610849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6989762806610849\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6443966718138858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6443966718138858\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7282190618792672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282190618792672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329153074189772, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329153074189772\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7282190618792672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282190618792672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329153074189772, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329153074189772\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7282190618792672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282190618792672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329153074189772, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329153074189772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:52,514] Trial 483 finished with value: 0.7854288877964278 and parameters: {'learning_rate': 0.07685684628630714, 'feature_fraction': 0.7282190618792672, 'bagging_fraction': 0.6329153074189772, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7282190618792672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282190618792672\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6329153074189772, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6329153074189772\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6817236096834322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6817236096834322\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.653606883681062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.653606883681062\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6817236096834322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6817236096834322\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.653606883681062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.653606883681062\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6817236096834322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6817236096834322\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.653606883681062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.653606883681062\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:53,372] Trial 484 finished with value: 0.7869431339055809 and parameters: {'learning_rate': 0.05616272835461212, 'feature_fraction': 0.6817236096834322, 'bagging_fraction': 0.653606883681062, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6817236096834322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6817236096834322\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.653606883681062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.653606883681062\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156942311857873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156942311857873\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7775967907296379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775967907296379\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156942311857873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156942311857873\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7775967907296379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775967907296379\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7156942311857873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156942311857873\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7775967907296379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775967907296379\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:54,232] Trial 485 finished with value: 0.7878834623525274 and parameters: {'learning_rate': 0.06780292881260881, 'feature_fraction': 0.7156942311857873, 'bagging_fraction': 0.7775967907296379, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7156942311857873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156942311857873\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7775967907296379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775967907296379\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034295064851804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034295064851804\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7898273031398735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7898273031398735\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034295064851804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034295064851804\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7898273031398735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7898273031398735\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006683 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7034295064851804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034295064851804\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7898273031398735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7898273031398735\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:55,119] Trial 486 finished with value: 0.7866098550919903 and parameters: {'learning_rate': 0.08225493016546756, 'feature_fraction': 0.7034295064851804, 'bagging_fraction': 0.7898273031398735, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7034295064851804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7034295064851804\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7898273031398735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7898273031398735\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6861276338308298, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861276338308298\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8520507825580808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8520507825580808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6861276338308298, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861276338308298\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8520507825580808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8520507825580808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6861276338308298, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861276338308298\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8520507825580808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8520507825580808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:56,032] Trial 487 finished with value: 0.7902222140114687 and parameters: {'learning_rate': 0.05132479127943624, 'feature_fraction': 0.6861276338308298, 'bagging_fraction': 0.8520507825580808, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6861276338308298, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861276338308298\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8520507825580808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8520507825580808\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6867272382975309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6867272382975309\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8508973118311549, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8508973118311549\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6867272382975309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6867272382975309\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8508973118311549, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8508973118311549\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6867272382975309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6867272382975309\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8508973118311549, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8508973118311549\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
            "[I 2024-07-12 21:03:56,942] Trial 488 finished with value: 0.7896907416878736 and parameters: {'learning_rate': 0.050495769901921034, 'feature_fraction': 0.6867272382975309, 'bagging_fraction': 0.8508973118311549, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6867272382975309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6867272382975309\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8508973118311549, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8508973118311549\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6717984062481716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6717984062481716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8448414764635743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448414764635743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6717984062481716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6717984062481716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8448414764635743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448414764635743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006469 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6717984062481716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6717984062481716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8448414764635743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448414764635743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:58,080] Trial 489 finished with value: 0.7888777322520912 and parameters: {'learning_rate': 0.047967213331104604, 'feature_fraction': 0.6717984062481716, 'bagging_fraction': 0.8448414764635743, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6717984062481716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6717984062481716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8448414764635743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8448414764635743\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6844289799888764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6844289799888764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8031634203589249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8031634203589249\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6844289799888764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6844289799888764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8031634203589249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8031634203589249\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010023 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6844289799888764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6844289799888764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8031634203589249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8031634203589249\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:03:59,303] Trial 490 finished with value: 0.7875947898920863 and parameters: {'learning_rate': 0.04354101692695065, 'feature_fraction': 0.6844289799888764, 'bagging_fraction': 0.8031634203589249, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6844289799888764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6844289799888764\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8031634203589249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8031634203589249\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.689281824538361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689281824538361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832263409790484, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832263409790484\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.689281824538361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689281824538361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832263409790484, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832263409790484\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010484 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.689281824538361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689281824538361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832263409790484, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832263409790484\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:00,602] Trial 491 finished with value: 0.7845258556521278 and parameters: {'learning_rate': 0.03877837864308549, 'feature_fraction': 0.689281824538361, 'bagging_fraction': 0.832263409790484, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.689281824538361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.689281824538361\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.832263409790484, subsample=1.0 will be ignored. Current value: bagging_fraction=0.832263409790484\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6743392248807508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743392248807508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8514982993711511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8514982993711511\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6743392248807508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743392248807508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8514982993711511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8514982993711511\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009536 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6743392248807508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743392248807508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8514982993711511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8514982993711511\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:01,905] Trial 492 finished with value: 0.7894959805468904 and parameters: {'learning_rate': 0.04786628299193693, 'feature_fraction': 0.6743392248807508, 'bagging_fraction': 0.8514982993711511, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6743392248807508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6743392248807508\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8514982993711511, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8514982993711511\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.684850913199004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.684850913199004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6233377062344186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6233377062344186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.684850913199004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.684850913199004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6233377062344186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6233377062344186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012089 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.684850913199004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.684850913199004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6233377062344186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6233377062344186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:03,213] Trial 493 finished with value: 0.7886767774328224 and parameters: {'learning_rate': 0.05223781188455673, 'feature_fraction': 0.684850913199004, 'bagging_fraction': 0.6233377062344186, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.684850913199004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.684850913199004\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6233377062344186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6233377062344186\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6790900783846605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790900783846605\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842485235847499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842485235847499\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6790900783846605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790900783846605\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842485235847499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842485235847499\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008344 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6790900783846605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790900783846605\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842485235847499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842485235847499\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:04,677] Trial 494 finished with value: 0.7707428954569266 and parameters: {'learning_rate': 0.005240748810266175, 'feature_fraction': 0.6790900783846605, 'bagging_fraction': 0.842485235847499, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6790900783846605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6790900783846605\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.842485235847499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.842485235847499\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6932194644749607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6932194644749607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6695952143273803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695952143273803\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6932194644749607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6932194644749607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6695952143273803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695952143273803\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011215 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6932194644749607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6932194644749607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6695952143273803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695952143273803\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:05,948] Trial 495 finished with value: 0.7867563994877977 and parameters: {'learning_rate': 0.05212839299458043, 'feature_fraction': 0.6932194644749607, 'bagging_fraction': 0.6695952143273803, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6932194644749607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6932194644749607\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6695952143273803, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695952143273803\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.668447730829178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.668447730829178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6383332634735829, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6383332634735829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.668447730829178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.668447730829178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6383332634735829, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6383332634735829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.668447730829178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.668447730829178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6383332634735829, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6383332634735829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:06,916] Trial 496 finished with value: 0.7883685751388987 and parameters: {'learning_rate': 0.04108481624235735, 'feature_fraction': 0.668447730829178, 'bagging_fraction': 0.6383332634735829, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.668447730829178, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.668447730829178\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6383332634735829, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6383332634735829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6611216533882739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6611216533882739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6127893084561862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6127893084561862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6611216533882739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6611216533882739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6127893084561862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6127893084561862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6611216533882739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6611216533882739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6127893084561862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6127893084561862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:07,797] Trial 497 finished with value: 0.7879061528055878 and parameters: {'learning_rate': 0.05416984434012629, 'feature_fraction': 0.6611216533882739, 'bagging_fraction': 0.6127893084561862, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6611216533882739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6611216533882739\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6127893084561862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6127893084561862\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939979673620484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939979673620484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485387866778897, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485387866778897\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939979673620484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939979673620484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485387866778897, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485387866778897\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006558 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3861\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 29\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6939979673620484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939979673620484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485387866778897, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485387866778897\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:08,691] Trial 498 finished with value: 0.7864591484247393 and parameters: {'learning_rate': 0.04769989357425129, 'feature_fraction': 0.6939979673620484, 'bagging_fraction': 0.6485387866778897, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6939979673620484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6939979673620484\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6485387866778897, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6485387866778897\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6853376597690665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6853376597690665\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7101074328221703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101074328221703\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6853376597690665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6853376597690665\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7101074328221703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101074328221703\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-1eee79ec0f99>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006981 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6853376597690665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6853376597690665\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7101074328221703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101074328221703\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-12 21:04:09,574] Trial 499 finished with value: 0.7891652780750165 and parameters: {'learning_rate': 0.057687750418406326, 'feature_fraction': 0.6853376597690665, 'bagging_fraction': 0.7101074328221703, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 377 with value: 0.7922997372262195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6853376597690665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6853376597690665\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7101074328221703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7101074328221703\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "Best parameters found: {'learning_rate': 0.07571003025023251, 'feature_fraction': 0.7420711826318525, 'bagging_fraction': 0.7072662201846903, 'bagging_freq': 3, 'min_child_samples': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan hyperparameter terbaik\n",
        "best_model = lgb.LGBMClassifier(**best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi probabilitas untuk data validasi\n",
        "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Evaluasi model menggunakan Average Precision Score\n",
        "average_precision = average_precision_score(y_val, y_pred_proba)\n",
        "print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# Optional: Evaluasi model menggunakan classification report\n",
        "y_pred = best_model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "9yRThn0nxtQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef27ad1c-9b5a-4544-e14b-8252fe2c9220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 8689, number of negative: 8682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3863\n",
            "[LightGBM] [Info] Number of data points in the train set: 17371, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500201 -> initscore=0.000806\n",
            "[LightGBM] [Info] Start training from score 0.000806\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "Average Precision Score: 0.7923\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.70      0.74      2175\n",
            "         1.0       0.73      0.81      0.77      2168\n",
            "\n",
            "    accuracy                           0.75      4343\n",
            "   macro avg       0.76      0.75      0.75      4343\n",
            "weighted avg       0.76      0.75      0.75      4343\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Melatih model dengan hyperparameter terbaik\n",
        "# best_model = lgb.LGBMClassifier(**best_params)\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Prediksi probabilitas untuk data validasi\n",
        "# y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# # Evaluasi model menggunakan Average Precision Score\n",
        "# average_precision = average_precision_score(y_val, y_pred_proba)\n",
        "# print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# # # Optional: Evaluasi model menggunakan classification report\n",
        "# # y_pred = best_model.predict(X_test)\n",
        "# # print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "zflzt1DcJMV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'user_id': data_test['user_id'],\n",
        "    'label': y_pred_proba\n",
        "})\n",
        "\n",
        "# Menyimpan hasil prediksi ke CSV\n",
        "submission.to_csv('submission20.csv', index=False)"
      ],
      "metadata": {
        "id": "BpWT9QaJV5V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3d5d74-6a88-4327-f839-5c07e753f3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7420711826318525, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7420711826318525\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7072662201846903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072662201846903\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subs = pd.read_csv('/content/submission20.csv')\n",
        "print(subs[subs['label'] >= 0.5])"
      ],
      "metadata": {
        "id": "4d0VUhJzYxH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c613250c-0545-4a90-9448-5af4e2f2334f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user_id     label\n",
            "0             4  0.737762\n",
            "5           107  0.676763\n",
            "9           118  0.635783\n",
            "13          200  0.532191\n",
            "14          205  0.571864\n",
            "...         ...       ...\n",
            "367692  3700418  0.618967\n",
            "367693  3700453  0.657326\n",
            "367697  3700510  0.690487\n",
            "367698  3700517  0.568303\n",
            "367699  3700526  0.618766\n",
            "\n",
            "[118684 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "SKnhkHR_TFlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3-4qJMATHtR",
        "outputId": "2e5814d1-e010-4a1f-eebd-73f128ecd56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.metrics import average_precision_score, classification_report\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'map',\n",
        "        'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
        "        'tree_method': 'hist'  # 'hist' untuk mempercepat training pada dataset besar\n",
        "    }\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "    bst = xgb.train(param, dtrain, evals=[(dval, 'eval')], verbose_eval=False)\n",
        "\n",
        "    y_pred_proba = bst.predict(dval)\n",
        "    aps = average_precision_score(y_val, y_pred_proba)\n",
        "    return aps\n"
      ],
      "metadata": {
        "id": "6trrVAx8TIGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best parameters found: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9RBEk0jTRJg",
        "outputId": "a32be797-7a5e-459a-fb79-7d5a0a935028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-06 04:28:54,887] A new study created in memory with name: no-name-7ba72b98-4aed-4d1f-8ad0-4f4335194d3f\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:28:57,534] Trial 0 finished with value: 0.5515213556750724 and parameters: {'eta': 0.00237761812539428, 'gamma': 2.235245842642401e-05, 'max_depth': 3, 'min_child_weight': 0.07784212341116323, 'subsample': 0.9602722699641292, 'colsample_bytree': 0.9953459706681365, 'lambda': 0.001625958935491798, 'alpha': 0.0006719027653537368}. Best is trial 0 with value: 0.5515213556750724.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:00,309] Trial 1 finished with value: 0.5668961929616918 and parameters: {'eta': 0.04733813232074101, 'gamma': 8.639571288671879e-08, 'max_depth': 7, 'min_child_weight': 0.09449522437677121, 'subsample': 0.8011891733114717, 'colsample_bytree': 0.6114221984223496, 'lambda': 2.3078574656720158e-06, 'alpha': 0.05659717187879928}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:03,384] Trial 2 finished with value: 0.5641193955753596 and parameters: {'eta': 0.00048309630635723626, 'gamma': 1.1716923752987428e-07, 'max_depth': 9, 'min_child_weight': 0.0012458005923875375, 'subsample': 0.7906880314884132, 'colsample_bytree': 0.9360996875818177, 'lambda': 1.9845260429033163e-08, 'alpha': 1.0486457913208218e-06}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:05,269] Trial 3 finished with value: 0.5668857256867974 and parameters: {'eta': 0.006505128509977941, 'gamma': 1.0099162728104124e-08, 'max_depth': 9, 'min_child_weight': 0.10563340101466911, 'subsample': 0.7332051760639176, 'colsample_bytree': 0.8737062918804754, 'lambda': 0.015035651359323842, 'alpha': 5.2481270600160065e-06}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:06,464] Trial 4 finished with value: 0.5620474764907188 and parameters: {'eta': 0.043627462284635446, 'gamma': 0.0018672902947359682, 'max_depth': 4, 'min_child_weight': 0.033512490561358944, 'subsample': 0.681482357208556, 'colsample_bytree': 0.652344415400487, 'lambda': 0.0011089167028763497, 'alpha': 1.2475830809201207e-07}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:08,050] Trial 5 finished with value: 0.5665996096451233 and parameters: {'eta': 0.0052176437979621505, 'gamma': 0.5596790140044484, 'max_depth': 8, 'min_child_weight': 0.0108010739542836, 'subsample': 0.7101718705078914, 'colsample_bytree': 0.9818056345602381, 'lambda': 1.9874299264305502e-05, 'alpha': 0.00011320252566684612}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:09,150] Trial 6 finished with value: 0.5650242458073608 and parameters: {'eta': 0.009112300971210218, 'gamma': 0.017788064879781657, 'max_depth': 6, 'min_child_weight': 0.002927354577039742, 'subsample': 0.7875922402698333, 'colsample_bytree': 0.667809304618362, 'lambda': 2.657408075577335e-08, 'alpha': 0.00016576964353923895}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:10,974] Trial 7 finished with value: 0.5667654746460806 and parameters: {'eta': 0.028155982474330384, 'gamma': 1.5309391375374182e-08, 'max_depth': 9, 'min_child_weight': 0.162958011023999, 'subsample': 0.854465109999671, 'colsample_bytree': 0.8103506048091125, 'lambda': 0.48067950096385503, 'alpha': 2.2124675755697103e-05}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:14,276] Trial 8 finished with value: 0.5664273596035788 and parameters: {'eta': 0.0012477805690492229, 'gamma': 0.07096850530551953, 'max_depth': 10, 'min_child_weight': 0.5451811873037054, 'subsample': 0.8161231960433801, 'colsample_bytree': 0.9180332665576316, 'lambda': 0.04181314691083374, 'alpha': 0.01346497906235375}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:17,136] Trial 9 finished with value: 0.5655874615352976 and parameters: {'eta': 0.000545655988886407, 'gamma': 0.0009238955187992713, 'max_depth': 7, 'min_child_weight': 0.3668830951507504, 'subsample': 0.8196113571765388, 'colsample_bytree': 0.967926844004446, 'lambda': 3.928663388300603e-06, 'alpha': 4.147014260126215e-08}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:19,788] Trial 10 finished with value: 0.5658408415209409 and parameters: {'eta': 0.0822278298475222, 'gamma': 4.95919077339685e-06, 'max_depth': 5, 'min_child_weight': 0.012610799452190461, 'subsample': 0.6202008043188425, 'colsample_bytree': 0.7286275152896745, 'lambda': 1.281462738243339e-06, 'alpha': 0.7395283703492562}. Best is trial 1 with value: 0.5668961929616918.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:21,297] Trial 11 finished with value: 0.5670680493737393 and parameters: {'eta': 0.013453338829634131, 'gamma': 7.94923343426982e-07, 'max_depth': 8, 'min_child_weight': 0.09362150389973731, 'subsample': 0.8991274224506705, 'colsample_bytree': 0.8378677414340742, 'lambda': 0.0007718569709064453, 'alpha': 0.9065238449014684}. Best is trial 11 with value: 0.5670680493737393.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:22,444] Trial 12 finished with value: 0.5667162494864251 and parameters: {'eta': 0.012323180242810042, 'gamma': 9.504215005797061e-07, 'max_depth': 7, 'min_child_weight': 0.038502892675220425, 'subsample': 0.9193268442770796, 'colsample_bytree': 0.7839067962533138, 'lambda': 0.00013710289734670218, 'alpha': 0.45301422013427495}. Best is trial 11 with value: 0.5670680493737393.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:23,598] Trial 13 finished with value: 0.5643354459575066 and parameters: {'eta': 0.0001488748833110706, 'gamma': 5.323923334408564e-07, 'max_depth': 6, 'min_child_weight': 0.24210174528541742, 'subsample': 0.8882077782409178, 'colsample_bytree': 0.6122594834106093, 'lambda': 2.9314154983133303e-07, 'alpha': 0.0229393625027968}. Best is trial 11 with value: 0.5670680493737393.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:25,251] Trial 14 finished with value: 0.5661869148613393 and parameters: {'eta': 0.02185057847569257, 'gamma': 5.334261065322206e-05, 'max_depth': 8, 'min_child_weight': 0.8250823770193071, 'subsample': 0.9594622621894039, 'colsample_bytree': 0.8291784075013567, 'lambda': 0.00014022668220182983, 'alpha': 0.028002183907851103}. Best is trial 11 with value: 0.5670680493737393.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:26,684] Trial 15 finished with value: 0.567985257265649 and parameters: {'eta': 0.0625280277523367, 'gamma': 1.6553441182116352e-07, 'max_depth': 8, 'min_child_weight': 0.01207472940400972, 'subsample': 0.8806698683957589, 'colsample_bytree': 0.7206879340671685, 'lambda': 2.4900105426889744e-05, 'alpha': 0.002212917839812345}. Best is trial 15 with value: 0.567985257265649.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:28,636] Trial 16 finished with value: 0.5650631161048033 and parameters: {'eta': 0.07392966351027916, 'gamma': 4.956496384470931e-06, 'max_depth': 10, 'min_child_weight': 0.011538946827693403, 'subsample': 0.9048077716921608, 'colsample_bytree': 0.7448200379548752, 'lambda': 0.0010291792999214866, 'alpha': 0.0034632329403628415}. Best is trial 15 with value: 0.567985257265649.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:30,304] Trial 17 finished with value: 0.5681769992186779 and parameters: {'eta': 0.01507993193222766, 'gamma': 7.726114539042302e-07, 'max_depth': 8, 'min_child_weight': 0.005798908454357489, 'subsample': 0.9748591916788597, 'colsample_bytree': 0.7280062611728556, 'lambda': 2.4810304380132794e-05, 'alpha': 0.002841543076053948}. Best is trial 17 with value: 0.5681769992186779.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:32,290] Trial 18 finished with value: 0.5683384654677323 and parameters: {'eta': 0.09935435585710989, 'gamma': 0.0004940401373085424, 'max_depth': 5, 'min_child_weight': 0.00431435031147332, 'subsample': 0.9795430156887752, 'colsample_bytree': 0.7292791740531029, 'lambda': 2.382924287422541e-05, 'alpha': 0.0008248680326856175}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:34,451] Trial 19 finished with value: 0.5633113445926762 and parameters: {'eta': 0.02423142092570373, 'gamma': 0.0017266091759145757, 'max_depth': 5, 'min_child_weight': 0.0030055333128902553, 'subsample': 0.9999080418507456, 'colsample_bytree': 0.6874813271559556, 'lambda': 1.894325478460369e-05, 'alpha': 1.5768581774465447e-05}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:36,754] Trial 20 finished with value: 0.5601741911659099 and parameters: {'eta': 0.0028045230830363076, 'gamma': 0.00022846519797428726, 'max_depth': 5, 'min_child_weight': 0.004689172772774103, 'subsample': 0.997929266283459, 'colsample_bytree': 0.7692726586008276, 'lambda': 1.4245550262545252e-07, 'alpha': 0.0012555432905556067}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:38,776] Trial 21 finished with value: 0.5659688826443826 and parameters: {'eta': 0.09509513762493536, 'gamma': 8.491020136157833e-06, 'max_depth': 4, 'min_child_weight': 0.0057424496359492665, 'subsample': 0.9500681134728296, 'colsample_bytree': 0.7073972642435603, 'lambda': 2.7561436655843054e-05, 'alpha': 0.000625501959128309}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:40,128] Trial 22 finished with value: 0.5682733123603313 and parameters: {'eta': 0.050194476417071775, 'gamma': 8.044707496930518e-08, 'max_depth': 8, 'min_child_weight': 0.001252783232843363, 'subsample': 0.9420937009344014, 'colsample_bytree': 0.7481572662090611, 'lambda': 6.482136655535282e-06, 'alpha': 0.0052860385974556005}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:41,039] Trial 23 finished with value: 0.5668002647845608 and parameters: {'eta': 0.03323725642876983, 'gamma': 0.00011270477735231987, 'max_depth': 6, 'min_child_weight': 0.0012911849991861818, 'subsample': 0.9379776698982476, 'colsample_bytree': 0.7537672370997615, 'lambda': 6.350919090187874e-07, 'alpha': 0.13644827866025505}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:42,362] Trial 24 finished with value: 0.5659184932141235 and parameters: {'eta': 0.016786709719480875, 'gamma': 4.4719152840457424e-08, 'max_depth': 7, 'min_child_weight': 0.0020495391982220537, 'subsample': 0.9765700445945972, 'colsample_bytree': 0.6619734414591997, 'lambda': 5.342878446178838e-06, 'alpha': 0.0057038442733936}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:43,915] Trial 25 finished with value: 0.5643819540875867 and parameters: {'eta': 0.0431863532788493, 'gamma': 0.00955882175194655, 'max_depth': 9, 'min_child_weight': 0.006156813720562065, 'subsample': 0.8587881622877864, 'colsample_bytree': 0.7880672642589142, 'lambda': 0.0001731046922215689, 'alpha': 0.0002730103891159342}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:44,759] Trial 26 finished with value: 0.5613071431006734 and parameters: {'eta': 0.00504877405747231, 'gamma': 1.913675307671634e-06, 'max_depth': 4, 'min_child_weight': 0.0025190797145752853, 'subsample': 0.9326386162836748, 'colsample_bytree': 0.8663625958625188, 'lambda': 1.0313562859754031e-07, 'alpha': 3.160997173306583e-05}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:45,686] Trial 27 finished with value: 0.5578893294194958 and parameters: {'eta': 0.04707252916116986, 'gamma': 1.6096073225781595e-05, 'max_depth': 3, 'min_child_weight': 0.0011413912356772315, 'subsample': 0.9891752314827048, 'colsample_bytree': 0.6959407536116051, 'lambda': 7.28204244942345e-06, 'alpha': 0.007597291805764273}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:46,928] Trial 28 finished with value: 0.564938959680948 and parameters: {'eta': 0.09109445389682828, 'gamma': 0.00034790802952324834, 'max_depth': 8, 'min_child_weight': 0.023241010981386923, 'subsample': 0.968136655069409, 'colsample_bytree': 0.7391960041859014, 'lambda': 0.005721178338373449, 'alpha': 0.06869554155023257}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:48,046] Trial 29 finished with value: 0.5650367929232882 and parameters: {'eta': 0.001435747579409628, 'gamma': 2.9148827786417005e-05, 'max_depth': 6, 'min_child_weight': 0.004080986197842437, 'subsample': 0.9329992678264046, 'colsample_bytree': 0.7582895459099724, 'lambda': 0.00030378761585391536, 'alpha': 0.000502121677854045}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:49,374] Trial 30 finished with value: 0.5637195117555581 and parameters: {'eta': 0.009950254484390821, 'gamma': 3.620222842535904e-08, 'max_depth': 5, 'min_child_weight': 0.00173723605399196, 'subsample': 0.8557865352030894, 'colsample_bytree': 0.6806632041515746, 'lambda': 3.975103599452645e-05, 'alpha': 0.0015503986670632585}. Best is trial 18 with value: 0.5683384654677323.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:51,626] Trial 31 finished with value: 0.5687792535387736 and parameters: {'eta': 0.056026071204936176, 'gamma': 2.456137597769549e-07, 'max_depth': 8, 'min_child_weight': 0.007420821075800074, 'subsample': 0.9607633577779365, 'colsample_bytree': 0.7125732056814885, 'lambda': 5.877713690547971e-05, 'alpha': 0.0020064324308037527}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:53,889] Trial 32 finished with value: 0.5682156441935649 and parameters: {'eta': 0.05735807127117374, 'gamma': 2.246705635456528e-07, 'max_depth': 7, 'min_child_weight': 0.007297995986421838, 'subsample': 0.9636127783806017, 'colsample_bytree': 0.6377515693393, 'lambda': 5.808699427601584e-05, 'alpha': 6.85640644747056e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:55,003] Trial 33 finished with value: 0.5683171976937484 and parameters: {'eta': 0.03445629197965041, 'gamma': 3.1314703461069943e-07, 'max_depth': 7, 'min_child_weight': 0.01853821268768517, 'subsample': 0.9539551221152643, 'colsample_bytree': 0.6330725499843679, 'lambda': 1.0528615683383251e-06, 'alpha': 6.41057891641922e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:56,349] Trial 34 finished with value: 0.5659575643054017 and parameters: {'eta': 0.036261316739126144, 'gamma': 4.380906734883786e-08, 'max_depth': 9, 'min_child_weight': 0.04569728497627734, 'subsample': 0.9246401965914806, 'colsample_bytree': 0.6064211346962557, 'lambda': 1.3231047343780608e-06, 'alpha': 3.3664765286622115e-06}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:57,447] Trial 35 finished with value: 0.5675235939714118 and parameters: {'eta': 0.0253149811129046, 'gamma': 2.2042065744292214e-07, 'max_depth': 7, 'min_child_weight': 0.024648790733873997, 'subsample': 0.9110494135514664, 'colsample_bytree': 0.6356668063155086, 'lambda': 7.598823758668853e-06, 'alpha': 0.00043834791484204355}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:58,139] Trial 36 finished with value: 0.5663590514883976 and parameters: {'eta': 0.06060319047906292, 'gamma': 1.1900891045164882e-08, 'max_depth': 6, 'min_child_weight': 0.017222782725474763, 'subsample': 0.9516707856091849, 'colsample_bytree': 0.7072712577005114, 'lambda': 2.1799537175332466e-06, 'alpha': 1.5043219431971294e-06}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:29:58,974] Trial 37 finished with value: 0.558729759949083 and parameters: {'eta': 0.03875117015342877, 'gamma': 3.0730164053125197e-06, 'max_depth': 3, 'min_child_weight': 0.003527641005552193, 'subsample': 0.8749446207548587, 'colsample_bytree': 0.6306958837470578, 'lambda': 1.115242368323854e-08, 'alpha': 8.773391685836452e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:00,114] Trial 38 finished with value: 0.5649242836769223 and parameters: {'eta': 0.006894978597375124, 'gamma': 0.007667911123978687, 'max_depth': 9, 'min_child_weight': 0.0018536687847084587, 'subsample': 0.9802775096596594, 'colsample_bytree': 0.6746527036043539, 'lambda': 8.481793681957368e-08, 'alpha': 1.2671718664188958e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:00,958] Trial 39 finished with value: 0.5675748041071917 and parameters: {'eta': 0.06103114979698197, 'gamma': 6.652401138669409e-08, 'max_depth': 8, 'min_child_weight': 0.009297883782467358, 'subsample': 0.8336543868117259, 'colsample_bytree': 0.7695439795495164, 'lambda': 6.313365005904696e-07, 'alpha': 3.699536116184416e-07}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:01,705] Trial 40 finished with value: 0.5676613640983668 and parameters: {'eta': 0.0963623360695903, 'gamma': 3.4258942255421325e-07, 'max_depth': 7, 'min_child_weight': 0.05429056914291074, 'subsample': 0.7856742710362188, 'colsample_bytree': 0.819407945798777, 'lambda': 0.0004437222261410733, 'alpha': 0.00019548754262372972}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:02,480] Trial 41 finished with value: 0.5679355330410176 and parameters: {'eta': 0.054494702237278494, 'gamma': 1.1558559394319143e-07, 'max_depth': 7, 'min_child_weight': 0.007920551741699875, 'subsample': 0.9547828170978951, 'colsample_bytree': 0.6389608341325899, 'lambda': 8.143776177361588e-05, 'alpha': 6.176963373773658e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:03,327] Trial 42 finished with value: 0.5666034790471784 and parameters: {'eta': 0.03109865732196746, 'gamma': 1.8980764554976832e-06, 'max_depth': 7, 'min_child_weight': 0.017675663939306464, 'subsample': 0.7630170189190277, 'colsample_bytree': 0.6454674322488335, 'lambda': 6.3114533780199e-05, 'alpha': 5.02005826688101e-05}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:04,166] Trial 43 finished with value: 0.5686651119278052 and parameters: {'eta': 0.021724209088009337, 'gamma': 2.3956485643883535e-08, 'max_depth': 8, 'min_child_weight': 0.008481647137259943, 'subsample': 0.9479231524208143, 'colsample_bytree': 0.6230709414188128, 'lambda': 0.002883798598261222, 'alpha': 0.0013280663055808184}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:04,946] Trial 44 finished with value: 0.5651823471033669 and parameters: {'eta': 0.020132249573719157, 'gamma': 1.4459807408139745e-08, 'max_depth': 8, 'min_child_weight': 0.018380776380716408, 'subsample': 0.6615051839915391, 'colsample_bytree': 0.6183691597457656, 'lambda': 0.004884304387142685, 'alpha': 0.0011852520261042786}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:05,853] Trial 45 finished with value: 0.5677854432065268 and parameters: {'eta': 0.04371241208691274, 'gamma': 2.795468928574071e-08, 'max_depth': 9, 'min_child_weight': 0.004201878806116133, 'subsample': 0.9373836789011756, 'colsample_bytree': 0.7109706781440659, 'lambda': 0.060392450687213606, 'alpha': 0.012501817419689257}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:06,856] Trial 46 finished with value: 0.5657873816671016 and parameters: {'eta': 0.02799391403546617, 'gamma': 0.37632786255124917, 'max_depth': 10, 'min_child_weight': 0.027162370157690637, 'subsample': 0.9017535264574983, 'colsample_bytree': 0.6646951024373698, 'lambda': 0.0030690629705428184, 'alpha': 0.005852567037620967}. Best is trial 31 with value: 0.5687792535387736.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:07,733] Trial 47 finished with value: 0.5688226554569188 and parameters: {'eta': 0.07407695498884471, 'gamma': 1.0671539849220109e-07, 'max_depth': 8, 'min_child_weight': 0.009070058267940695, 'subsample': 0.91691562192502, 'colsample_bytree': 0.6928999520609256, 'lambda': 1.0431197162414811e-05, 'alpha': 0.051504991143113535}. Best is trial 47 with value: 0.5688226554569188.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:09,063] Trial 48 finished with value: 0.5669163133944097 and parameters: {'eta': 0.003928358591771537, 'gamma': 2.3552342827223783e-08, 'max_depth': 9, 'min_child_weight': 0.014815351159964884, 'subsample': 0.9851460608303192, 'colsample_bytree': 0.6014073229050281, 'lambda': 0.03321201401704662, 'alpha': 0.08417868343587144}. Best is trial 47 with value: 0.5688226554569188.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:10,279] Trial 49 finished with value: 0.5679633779941052 and parameters: {'eta': 0.07529983090625463, 'gamma': 4.6259268639956727e-07, 'max_depth': 8, 'min_child_weight': 0.06103137973595411, 'subsample': 0.9239313199069077, 'colsample_bytree': 0.661425044915403, 'lambda': 1.1831407694767171e-05, 'alpha': 0.2768729337546265}. Best is trial 47 with value: 0.5688226554569188.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:11,349] Trial 50 finished with value: 0.564161160333701 and parameters: {'eta': 0.000200373175244848, 'gamma': 0.0005357638366332019, 'max_depth': 6, 'min_child_weight': 0.008375237567731031, 'subsample': 0.889524388716845, 'colsample_bytree': 0.6908615309846224, 'lambda': 0.5113317524739803, 'alpha': 0.037271225627701354}. Best is trial 47 with value: 0.5688226554569188.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:12,624] Trial 51 finished with value: 0.5688892064463642 and parameters: {'eta': 0.07416849198100163, 'gamma': 9.239178788579195e-08, 'max_depth': 8, 'min_child_weight': 0.01106879555328733, 'subsample': 0.9450707977723075, 'colsample_bytree': 0.7369924992625498, 'lambda': 2.9442078922332677e-06, 'alpha': 0.016536408673366195}. Best is trial 51 with value: 0.5688892064463642.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:13,858] Trial 52 finished with value: 0.5703504219395727 and parameters: {'eta': 0.0739822102857715, 'gamma': 1.0736509524627033e-07, 'max_depth': 8, 'min_child_weight': 0.01104501045459307, 'subsample': 0.9634134151823887, 'colsample_bytree': 0.7283633421002697, 'lambda': 9.548663414506943e-07, 'alpha': 0.019579141473562947}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:15,215] Trial 53 finished with value: 0.5646161284724843 and parameters: {'eta': 0.06578433247290354, 'gamma': 1.0579646883427861e-07, 'max_depth': 9, 'min_child_weight': 0.006030586916462848, 'subsample': 0.9717366363526178, 'colsample_bytree': 0.7271196122502686, 'lambda': 2.927490769424561e-06, 'alpha': 0.013748249445272937}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:16,059] Trial 54 finished with value: 0.5671306067337758 and parameters: {'eta': 0.07514602559953085, 'gamma': 1.3891189741389147e-07, 'max_depth': 8, 'min_child_weight': 0.011151640103651413, 'subsample': 0.9101374351518944, 'colsample_bytree': 0.795533253263, 'lambda': 4.687575909833735e-07, 'alpha': 0.01466806375368336}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:16,883] Trial 55 finished with value: 0.566116172210281 and parameters: {'eta': 0.09610886032905343, 'gamma': 0.003495291294777861, 'max_depth': 8, 'min_child_weight': 0.013051318683905635, 'subsample': 0.9615210545425102, 'colsample_bytree': 0.7732495721043675, 'lambda': 1.501608770187369e-05, 'alpha': 0.2529007056382035}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:17,676] Trial 56 finished with value: 0.5678488495908482 and parameters: {'eta': 0.02035903350431396, 'gamma': 0.00010593103533693543, 'max_depth': 8, 'min_child_weight': 0.009796400844241764, 'subsample': 0.9966692124292761, 'colsample_bytree': 0.7184382166709454, 'lambda': 2.787427938853898e-06, 'alpha': 0.051641355579317455}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:18,582] Trial 57 finished with value: 0.5646179478392113 and parameters: {'eta': 0.0743889828434093, 'gamma': 8.680385107945071e-07, 'max_depth': 9, 'min_child_weight': 0.004889425015757328, 'subsample': 0.8702887160753949, 'colsample_bytree': 0.7371725326508352, 'lambda': 2.254391044883134e-07, 'alpha': 0.000908030985532947}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:19,630] Trial 58 finished with value: 0.5652425144092338 and parameters: {'eta': 0.048425142507100415, 'gamma': 1.061370864896821e-08, 'max_depth': 10, 'min_child_weight': 0.007514843859205183, 'subsample': 0.945303501376583, 'colsample_bytree': 0.690858330881769, 'lambda': 0.0017953176682153078, 'alpha': 0.00317095493348336}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:20,458] Trial 59 finished with value: 0.5661279073798837 and parameters: {'eta': 0.000808911974685738, 'gamma': 6.392865402660732e-08, 'max_depth': 8, 'min_child_weight': 0.0034509886665071003, 'subsample': 0.9172477571255752, 'colsample_bytree': 0.8033034715279114, 'lambda': 4.3067161633317495e-08, 'alpha': 0.02282667977289105}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:21,125] Trial 60 finished with value: 0.5631760172546445 and parameters: {'eta': 0.002011857701890356, 'gamma': 2.2385357567383243e-08, 'max_depth': 5, 'min_child_weight': 0.036083135487492715, 'subsample': 0.9775999777549318, 'colsample_bytree': 0.6993283788461915, 'lambda': 0.0003089230040407462, 'alpha': 0.0024715417992707714}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:21,826] Trial 61 finished with value: 0.5663060431368181 and parameters: {'eta': 0.03641069413107161, 'gamma': 3.0481787256176317e-07, 'max_depth': 7, 'min_child_weight': 0.01571246498263907, 'subsample': 0.9524377986061369, 'colsample_bytree': 0.6191725588437218, 'lambda': 1.521096880986557e-06, 'alpha': 0.0002942484919595543}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:22,550] Trial 62 finished with value: 0.5683680033382951 and parameters: {'eta': 0.07539508205601614, 'gamma': 1.5499703963495844e-06, 'max_depth': 7, 'min_child_weight': 0.022532742171301207, 'subsample': 0.9623911796250101, 'colsample_bytree': 0.6541428550631703, 'lambda': 7.961756683581153e-07, 'alpha': 0.008019446322117462}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:23,402] Trial 63 finished with value: 0.5696973998601297 and parameters: {'eta': 0.09982882745470173, 'gamma': 1.368096763332547e-06, 'max_depth': 8, 'min_child_weight': 0.010005609659993243, 'subsample': 0.9268756572258734, 'colsample_bytree': 0.675878071983937, 'lambda': 1.2035890654151809e-05, 'alpha': 0.09509387847047444}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:24,246] Trial 64 finished with value: 0.5686111879690159 and parameters: {'eta': 0.07623327616388216, 'gamma': 2.1824848965262727e-06, 'max_depth': 8, 'min_child_weight': 0.029633226047273867, 'subsample': 0.8982537023101592, 'colsample_bytree': 0.6544235872424555, 'lambda': 2.840308085148668e-07, 'alpha': 0.029323508679804818}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:25,070] Trial 65 finished with value: 0.5665265630731134 and parameters: {'eta': 0.0563900421418242, 'gamma': 7.031922117223275e-06, 'max_depth': 8, 'min_child_weight': 0.012929230154014086, 'subsample': 0.8970618922477008, 'colsample_bytree': 0.6744859861213268, 'lambda': 9.817709033149728e-06, 'alpha': 0.16690894920647617}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:26,261] Trial 66 finished with value: 0.5683569236883228 and parameters: {'eta': 0.08246142860162643, 'gamma': 1.0779379947494785e-06, 'max_depth': 8, 'min_child_weight': 0.0325016925101913, 'subsample': 0.9281256011087875, 'colsample_bytree': 0.6526888083274377, 'lambda': 0.18794926160608608, 'alpha': 0.483352460965805}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:27,585] Trial 67 finished with value: 0.5668664345201274 and parameters: {'eta': 0.04708354860880088, 'gamma': 4.654951696978604e-07, 'max_depth': 8, 'min_child_weight': 0.11771542047629895, 'subsample': 0.8414110899674447, 'colsample_bytree': 0.9288490188797077, 'lambda': 3.296838867286277e-07, 'alpha': 0.11376892526803024}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:28,992] Trial 68 finished with value: 0.5683334953786541 and parameters: {'eta': 0.01617603511942792, 'gamma': 1.573150341638429e-07, 'max_depth': 9, 'min_child_weight': 0.010054942440292178, 'subsample': 0.9399395166494043, 'colsample_bytree': 0.6848180787719266, 'lambda': 3.91153368355187e-06, 'alpha': 1.2689563277483017e-08}. Best is trial 52 with value: 0.5703504219395727.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:30,404] Trial 69 finished with value: 0.5708619319086741 and parameters: {'eta': 0.010760928925428785, 'gamma': 6.30110181964925e-08, 'max_depth': 9, 'min_child_weight': 0.006247778648155865, 'subsample': 0.8848263538166746, 'colsample_bytree': 0.701265496272921, 'lambda': 0.00017417640611774673, 'alpha': 0.042541077913079775}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:31,811] Trial 70 finished with value: 0.5703427227522596 and parameters: {'eta': 0.010220964105982385, 'gamma': 6.065878208946505e-08, 'max_depth': 9, 'min_child_weight': 0.006695295541200677, 'subsample': 0.8856532666446184, 'colsample_bytree': 0.713807822992208, 'lambda': 3.887865772540627e-05, 'alpha': 0.059726377292261594}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:33,210] Trial 71 finished with value: 0.5693934134875457 and parameters: {'eta': 0.011323121761979287, 'gamma': 5.803193665325078e-08, 'max_depth': 9, 'min_child_weight': 0.00675988235162594, 'subsample': 0.8663381933697077, 'colsample_bytree': 0.7144095571687963, 'lambda': 3.880923291372989e-05, 'alpha': 0.048077233051195885}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:34,271] Trial 72 finished with value: 0.5662132926628098 and parameters: {'eta': 0.0102897278140612, 'gamma': 5.771774598874183e-08, 'max_depth': 10, 'min_child_weight': 0.006591383903474622, 'subsample': 0.8874110861317831, 'colsample_bytree': 0.7080250354417994, 'lambda': 4.100729725996626e-05, 'alpha': 0.04696526616976392}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:35,184] Trial 73 finished with value: 0.5674496185241513 and parameters: {'eta': 0.007074915997831147, 'gamma': 9.387699664526313e-08, 'max_depth': 9, 'min_child_weight': 0.005644240470049253, 'subsample': 0.8621148327079247, 'colsample_bytree': 0.7187515820602879, 'lambda': 0.00020772290558274383, 'alpha': 0.08597004103123942}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:36,079] Trial 74 finished with value: 0.5692754517742541 and parameters: {'eta': 0.012154966549972097, 'gamma': 2.1175423931321603e-07, 'max_depth': 9, 'min_child_weight': 0.0024956069538650733, 'subsample': 0.8441562343891692, 'colsample_bytree': 0.7592974984826215, 'lambda': 4.3396790665373156e-05, 'alpha': 0.1627839081614259}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:37,137] Trial 75 finished with value: 0.5659078817354014 and parameters: {'eta': 0.01187615136598468, 'gamma': 5.225337167157446e-08, 'max_depth': 10, 'min_child_weight': 0.0031789246531852217, 'subsample': 0.8184123645905842, 'colsample_bytree': 0.7570454949627439, 'lambda': 0.0001088778173305865, 'alpha': 0.21002178977807887}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:38,056] Trial 76 finished with value: 0.5664657618474388 and parameters: {'eta': 0.005365435916185554, 'gamma': 1.9990777233730452e-07, 'max_depth': 9, 'min_child_weight': 0.002392277610715976, 'subsample': 0.8816010838960401, 'colsample_bytree': 0.7418297817965374, 'lambda': 2.9464976011197218e-05, 'alpha': 0.6732967949028767}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:38,953] Trial 77 finished with value: 0.5650746924287713 and parameters: {'eta': 0.004009748295988666, 'gamma': 4.1307265186248644e-08, 'max_depth': 9, 'min_child_weight': 0.002357964729726893, 'subsample': 0.8468420420430314, 'colsample_bytree': 0.7295103684778358, 'lambda': 1.7048489651577114e-05, 'alpha': 0.13643008211847782}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:39,838] Trial 78 finished with value: 0.567871328000328 and parameters: {'eta': 0.013857719037555151, 'gamma': 5.174117737556704e-07, 'max_depth': 9, 'min_child_weight': 0.005071968815721107, 'subsample': 0.8058364778795679, 'colsample_bytree': 0.6998951959103579, 'lambda': 5.367760981181176e-06, 'alpha': 0.020440813984072194}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:40,904] Trial 79 finished with value: 0.5672033120563351 and parameters: {'eta': 0.009100234385861846, 'gamma': 1.0862287841705881e-07, 'max_depth': 10, 'min_child_weight': 0.014007298069588043, 'subsample': 0.827243248979691, 'colsample_bytree': 0.7786063321117351, 'lambda': 0.0006039679036478071, 'alpha': 0.3768523375265543}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:41,798] Trial 80 finished with value: 0.5681195798638269 and parameters: {'eta': 0.0020646074451557417, 'gamma': 7.489541601726777e-08, 'max_depth': 9, 'min_child_weight': 0.0037118342638952796, 'subsample': 0.8631634745247977, 'colsample_bytree': 0.7544793934330686, 'lambda': 3.8017118565122074e-05, 'alpha': 0.06480608154332092}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:42,999] Trial 81 finished with value: 0.5672810376565024 and parameters: {'eta': 0.008106023341215539, 'gamma': 2.2148569091601207e-07, 'max_depth': 9, 'min_child_weight': 0.007258163965178178, 'subsample': 0.8687342438809718, 'colsample_bytree': 0.7142730607941815, 'lambda': 6.222663559996629e-05, 'alpha': 0.03461553022624381}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:45,047] Trial 82 finished with value: 0.5674462919785022 and parameters: {'eta': 0.011338792619628137, 'gamma': 2.0012338251107933e-08, 'max_depth': 9, 'min_child_weight': 0.01027697176029962, 'subsample': 0.8500878005164803, 'colsample_bytree': 0.7314071260099307, 'lambda': 0.00011061688240754208, 'alpha': 0.009051906589370865}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:46,267] Trial 83 finished with value: 0.5670383599063149 and parameters: {'eta': 0.02714903222238898, 'gamma': 3.18141278505739e-08, 'max_depth': 8, 'min_child_weight': 0.005116045714652023, 'subsample': 0.9179728391871096, 'colsample_bytree': 0.677464428581842, 'lambda': 9.821127638045984e-06, 'alpha': 0.09373070099054343}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:47,850] Trial 84 finished with value: 0.5657261750164042 and parameters: {'eta': 0.04077626301205472, 'gamma': 3.108404736304398e-07, 'max_depth': 10, 'min_child_weight': 0.0014257079838259324, 'subsample': 0.9097033450481259, 'colsample_bytree': 0.7020367377715245, 'lambda': 2.1002492560278673e-05, 'alpha': 0.0199612282125371}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:49,256] Trial 85 finished with value: 0.570115233419011 and parameters: {'eta': 0.01751744508998447, 'gamma': 1.4716082837336105e-07, 'max_depth': 9, 'min_child_weight': 0.020639026272963733, 'subsample': 0.8936736459537042, 'colsample_bytree': 0.7639535065212988, 'lambda': 0.0002830216170464114, 'alpha': 0.05180151297559071}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:50,694] Trial 86 finished with value: 0.5683046160872242 and parameters: {'eta': 0.005297638773119433, 'gamma': 1.5425638181234304e-07, 'max_depth': 9, 'min_child_weight': 0.01206540312793471, 'subsample': 0.8818309807306335, 'colsample_bytree': 0.7628820218767056, 'lambda': 0.00018387832491634123, 'alpha': 0.8970778421257557}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:51,745] Trial 87 finished with value: 0.5696645763850114 and parameters: {'eta': 0.017913267341580354, 'gamma': 5.729629038931802e-07, 'max_depth': 9, 'min_child_weight': 0.02026895096535222, 'subsample': 0.8923515588656891, 'colsample_bytree': 0.7472039396628344, 'lambda': 0.00037833847471218843, 'alpha': 0.052887118309140835}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:52,642] Trial 88 finished with value: 0.5682353597758644 and parameters: {'eta': 0.014175884179801552, 'gamma': 3.6418246899847276e-06, 'max_depth': 9, 'min_child_weight': 0.018447225647942378, 'subsample': 0.8927609866240138, 'colsample_bytree': 0.7496209109407179, 'lambda': 0.0011198792094210426, 'alpha': 0.35972504325618826}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:53,715] Trial 89 finished with value: 0.5684560437358066 and parameters: {'eta': 0.008051766398485406, 'gamma': 7.587163442171612e-07, 'max_depth': 10, 'min_child_weight': 0.02281572329649699, 'subsample': 0.8775778300491949, 'colsample_bytree': 0.7825637213438787, 'lambda': 0.00027916488838078895, 'alpha': 0.15742022487724888}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:54,577] Trial 90 finished with value: 0.5648805149069802 and parameters: {'eta': 0.018203962231527086, 'gamma': 1.570783247774078e-08, 'max_depth': 9, 'min_child_weight': 0.0027404926933412327, 'subsample': 0.8390059960490591, 'colsample_bytree': 0.7240033881067999, 'lambda': 0.0005078198863178964, 'alpha': 0.032850936847521266}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:55,465] Trial 91 finished with value: 0.5645185504366851 and parameters: {'eta': 0.023552344183372632, 'gamma': 8.340737570128027e-08, 'max_depth': 9, 'min_child_weight': 0.020027407642056416, 'subsample': 0.904587381997581, 'colsample_bytree': 0.7393287682078692, 'lambda': 0.00011666291264370796, 'alpha': 0.07704721108081845}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:56,353] Trial 92 finished with value: 0.5660072323850724 and parameters: {'eta': 0.016895263628142806, 'gamma': 4.715460241018953e-08, 'max_depth': 9, 'min_child_weight': 0.008806651246159765, 'subsample': 0.9287975922263785, 'colsample_bytree': 0.7647970027030702, 'lambda': 1.7182556002827072e-06, 'alpha': 0.05418652330853957}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:57,247] Trial 93 finished with value: 0.56542137496044 and parameters: {'eta': 0.012260843469671436, 'gamma': 6.587292376467108e-07, 'max_depth': 9, 'min_child_weight': 0.014557639112929404, 'subsample': 0.9174871541087884, 'colsample_bytree': 0.7486308138745894, 'lambda': 4.167281067912724e-06, 'alpha': 0.04151317472247116}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:58,040] Trial 94 finished with value: 0.5674641661043403 and parameters: {'eta': 0.008911558608771823, 'gamma': 4.0753560891569784e-07, 'max_depth': 8, 'min_child_weight': 0.041796002888594266, 'subsample': 0.8689129796665019, 'colsample_bytree': 0.7920555410272748, 'lambda': 8.246186685196945e-05, 'alpha': 0.010832103153062914}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:59,068] Trial 95 finished with value: 0.5663255144249795 and parameters: {'eta': 0.029492481916859173, 'gamma': 1.3793465354846012e-07, 'max_depth': 10, 'min_child_weight': 0.01113209389690855, 'subsample': 0.8897617223330083, 'colsample_bytree': 0.7333697807330259, 'lambda': 4.2603425906131806e-05, 'alpha': 0.005377008228392971}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:30:59,953] Trial 96 finished with value: 0.5667346531296038 and parameters: {'eta': 0.010321262470658064, 'gamma': 3.22969825103746e-08, 'max_depth': 9, 'min_child_weight': 0.0069988628098109325, 'subsample': 0.8567310377703464, 'colsample_bytree': 0.7210173517278254, 'lambda': 1.2534373914058962e-05, 'alpha': 0.016117491791987924}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:00,750] Trial 97 finished with value: 0.5679765832580503 and parameters: {'eta': 0.06555939735415428, 'gamma': 1.4643251573795685e-05, 'max_depth': 8, 'min_child_weight': 0.004313490173582918, 'subsample': 0.7740832862605621, 'colsample_bytree': 0.6884640348533013, 'lambda': 0.000871403684732286, 'alpha': 0.21691902648754632}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:01,749] Trial 98 finished with value: 0.5677107979978551 and parameters: {'eta': 0.005941391666582556, 'gamma': 2.5412604166048114e-07, 'max_depth': 8, 'min_child_weight': 0.008960265133472724, 'subsample': 0.7189332408296052, 'colsample_bytree': 0.7448983179765216, 'lambda': 0.00036795645967336487, 'alpha': 0.10187367070347665}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:03,164] Trial 99 finished with value: 0.5634194687990277 and parameters: {'eta': 0.003999278333661376, 'gamma': 1.233220466709639e-06, 'max_depth': 9, 'min_child_weight': 0.00637252230697095, 'subsample': 0.9013733078588055, 'colsample_bytree': 0.7737215235755066, 'lambda': 0.00018014201442709558, 'alpha': 0.026205361705652106}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:04,874] Trial 100 finished with value: 0.5590987054539996 and parameters: {'eta': 0.018233069287643986, 'gamma': 1.02589858984851e-07, 'max_depth': 10, 'min_child_weight': 0.015973904941380533, 'subsample': 0.9105046095551288, 'colsample_bytree': 0.8460283466196409, 'lambda': 7.135704969791798e-06, 'alpha': 0.06415075663938402}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:06,094] Trial 101 finished with value: 0.5680582152015294 and parameters: {'eta': 0.08939072271383929, 'gamma': 6.911377724880347e-08, 'max_depth': 8, 'min_child_weight': 0.007818598435809652, 'subsample': 0.9344260724435033, 'colsample_bytree': 0.7079760734206979, 'lambda': 2.6944067571454503e-05, 'alpha': 0.0037100827692238625}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:07,382] Trial 102 finished with value: 0.5645692706370742 and parameters: {'eta': 0.09994902326515989, 'gamma': 2.1676317075182544e-07, 'max_depth': 8, 'min_child_weight': 0.027081694986058558, 'subsample': 0.9448346592690188, 'colsample_bytree': 0.9744801857393858, 'lambda': 7.113668251941774e-05, 'alpha': 0.046428970655751106}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:08,625] Trial 103 finished with value: 0.5658189150174314 and parameters: {'eta': 0.052252294101421536, 'gamma': 1.6744588694515778e-07, 'max_depth': 9, 'min_child_weight': 0.0055189490966987996, 'subsample': 0.9228373240586681, 'colsample_bytree': 0.696904185742504, 'lambda': 0.00024550783224483057, 'alpha': 0.13792510725967705}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:09,416] Trial 104 finished with value: 0.56778340972095 and parameters: {'eta': 0.06172655465962404, 'gamma': 6.111554163003124e-07, 'max_depth': 8, 'min_child_weight': 0.012348107997372335, 'subsample': 0.8776066826821518, 'colsample_bytree': 0.7136505449171402, 'lambda': 5.0407882314480104e-05, 'alpha': 0.5337971858177586}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:10,297] Trial 105 finished with value: 0.5662000101432496 and parameters: {'eta': 0.01379086398910372, 'gamma': 0.06108937761027597, 'max_depth': 9, 'min_child_weight': 0.020929627080422574, 'subsample': 0.9713559648087461, 'colsample_bytree': 0.6787631058009045, 'lambda': 1.462257147052496e-05, 'alpha': 0.018832965753115723}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:10,996] Trial 106 finished with value: 0.5685719313306952 and parameters: {'eta': 0.08386149792150127, 'gamma': 3.562302508956256e-07, 'max_depth': 7, 'min_child_weight': 0.010060079879835062, 'subsample': 0.9864561266950147, 'colsample_bytree': 0.7242024540998528, 'lambda': 0.00013719332622267306, 'alpha': 0.20796823874099854}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:11,785] Trial 107 finished with value: 0.5705446348077388 and parameters: {'eta': 0.06601007012385308, 'gamma': 4.010824667008503e-08, 'max_depth': 8, 'min_child_weight': 0.006468951855758151, 'subsample': 0.8858885342889996, 'colsample_bytree': 0.6918046468454311, 'lambda': 3.1084000051119125e-05, 'alpha': 0.03584366144206745}. Best is trial 69 with value: 0.5708619319086741.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:12,547] Trial 108 finished with value: 0.5718042631528008 and parameters: {'eta': 0.06752875186825513, 'gamma': 3.588364234393875e-08, 'max_depth': 8, 'min_child_weight': 0.006335708049506629, 'subsample': 0.8860957716494947, 'colsample_bytree': 0.6940232561143637, 'lambda': 2.2070093519261847e-06, 'alpha': 0.034059897885153866}. Best is trial 108 with value: 0.5718042631528008.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:13,424] Trial 109 finished with value: 0.5682733967846937 and parameters: {'eta': 0.0326873543102149, 'gamma': 1.5098818135949354e-08, 'max_depth': 9, 'min_child_weight': 0.0010012175089505872, 'subsample': 0.8941748709078958, 'colsample_bytree': 0.6653808756101499, 'lambda': 2.663338190863121e-06, 'alpha': 0.029805654762969598}. Best is trial 108 with value: 0.5718042631528008.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:14,208] Trial 110 finished with value: 0.5718155885602858 and parameters: {'eta': 0.0076228491653121035, 'gamma': 3.130653468726005e-08, 'max_depth': 8, 'min_child_weight': 0.0038668264862327687, 'subsample': 0.8860740135000353, 'colsample_bytree': 0.6692436627064742, 'lambda': 1.0946066464266152e-06, 'alpha': 0.31510973446763607}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:15,001] Trial 111 finished with value: 0.5707583048481302 and parameters: {'eta': 0.0071398159676714645, 'gamma': 3.966356062256435e-08, 'max_depth': 8, 'min_child_weight': 0.004547462195293998, 'subsample': 0.8851727131692808, 'colsample_bytree': 0.6709924464149344, 'lambda': 7.278406358420021e-07, 'alpha': 0.09473871141059621}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:15,786] Trial 112 finished with value: 0.5689615729192584 and parameters: {'eta': 0.003185490668298875, 'gamma': 3.7794973395568664e-08, 'max_depth': 8, 'min_child_weight': 0.00402477726849165, 'subsample': 0.8701434531489987, 'colsample_bytree': 0.6710724302899674, 'lambda': 1.1006490669780687e-06, 'alpha': 0.2938885492159795}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:16,606] Trial 113 finished with value: 0.5641786136470271 and parameters: {'eta': 0.00742788687125577, 'gamma': 1.00852208041683e-08, 'max_depth': 8, 'min_child_weight': 0.003075818827837985, 'subsample': 0.8854818669312835, 'colsample_bytree': 0.9954938047558579, 'lambda': 7.538953602002674e-07, 'alpha': 0.09721479302426662}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:17,319] Trial 114 finished with value: 0.5684116293104158 and parameters: {'eta': 0.00629192832553524, 'gamma': 1.970311529504531e-08, 'max_depth': 7, 'min_child_weight': 0.004448731890648201, 'subsample': 0.8511845895814752, 'colsample_bytree': 0.6449130529044931, 'lambda': 1.8551290655415432e-06, 'alpha': 0.15696820403692452}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:18,200] Trial 115 finished with value: 0.5659950606198794 and parameters: {'eta': 0.009207167870008214, 'gamma': 2.8445891939597635e-08, 'max_depth': 9, 'min_child_weight': 0.001978581569702442, 'subsample': 0.8298513923045873, 'colsample_bytree': 0.6874762425974621, 'lambda': 3.7915674780279784e-07, 'alpha': 0.06250789893894104}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:19,280] Trial 116 finished with value: 0.5691758477331794 and parameters: {'eta': 0.010730437284071106, 'gamma': 5.330440262847761e-08, 'max_depth': 8, 'min_child_weight': 0.005798045399360935, 'subsample': 0.8657624752657263, 'colsample_bytree': 0.7030744479779424, 'lambda': 3.167936514905811e-05, 'alpha': 0.1133704355405878}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:20,552] Trial 117 finished with value: 0.5664669614281239 and parameters: {'eta': 0.015204218336856132, 'gamma': 6.442037038723662e-05, 'max_depth': 7, 'min_child_weight': 0.44599114303120163, 'subsample': 0.8765560206888687, 'colsample_bytree': 0.6811197738383447, 'lambda': 2.176323740557993e-07, 'alpha': 0.3383735029277513}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:23,549] Trial 118 finished with value: 0.5670037130047041 and parameters: {'eta': 0.011908774826640637, 'gamma': 4.200966533858672e-08, 'max_depth': 8, 'min_child_weight': 0.003713101631328226, 'subsample': 0.9045205054352764, 'colsample_bytree': 0.6619991761416025, 'lambda': 9.12110070783571e-07, 'alpha': 0.03813786282581074}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:26,901] Trial 119 finished with value: 0.5694381175111973 and parameters: {'eta': 0.007989151659270477, 'gamma': 6.608793853541637e-08, 'max_depth': 9, 'min_child_weight': 0.004975324553059667, 'subsample': 0.8852146999624438, 'colsample_bytree': 0.6939626721143312, 'lambda': 5.921478592577641e-07, 'alpha': 0.07297560330359874}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:28,718] Trial 120 finished with value: 0.5684570297141316 and parameters: {'eta': 0.004714869579488308, 'gamma': 1.6789069936787865e-08, 'max_depth': 9, 'min_child_weight': 0.0053490859217373244, 'subsample': 0.8946446759001714, 'colsample_bytree': 0.6950321000917471, 'lambda': 4.664018953971102e-07, 'alpha': 0.02463649272684871}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:30,439] Trial 121 finished with value: 0.5678685761181004 and parameters: {'eta': 0.009188432236209132, 'gamma': 7.257873433279184e-08, 'max_depth': 9, 'min_child_weight': 0.006564822526607289, 'subsample': 0.8578781307925946, 'colsample_bytree': 0.6691469535235899, 'lambda': 6.462435768707533e-07, 'alpha': 0.06536429162284665}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:32,169] Trial 122 finished with value: 0.5713655499415052 and parameters: {'eta': 0.00762264611298959, 'gamma': 2.7242622569011048e-08, 'max_depth': 9, 'min_child_weight': 0.004786144745269263, 'subsample': 0.8845356564728785, 'colsample_bytree': 0.6847673582673133, 'lambda': 4.898976759970763e-07, 'alpha': 0.1813990245499271}. Best is trial 110 with value: 0.5718155885602858.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:33,983] Trial 123 finished with value: 0.5725035630519906 and parameters: {'eta': 0.007630896578349045, 'gamma': 2.629646447011892e-08, 'max_depth': 9, 'min_child_weight': 0.0047089386621150964, 'subsample': 0.8843243212393389, 'colsample_bytree': 0.6810960697934275, 'lambda': 7.404682100629862e-08, 'alpha': 0.5861378611448698}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:35,645] Trial 124 finished with value: 0.5688209129143845 and parameters: {'eta': 0.006074914444245157, 'gamma': 2.6815253203135948e-08, 'max_depth': 9, 'min_child_weight': 0.004733479217247725, 'subsample': 0.8875631209487119, 'colsample_bytree': 0.6732474195732904, 'lambda': 6.164103941891804e-08, 'alpha': 0.6019813022336897}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:38,015] Trial 125 finished with value: 0.5691119250190824 and parameters: {'eta': 0.007378814445753371, 'gamma': 2.6815158066419675e-08, 'max_depth': 8, 'min_child_weight': 0.0034035275837018294, 'subsample': 0.8794817503111161, 'colsample_bytree': 0.6833859158662787, 'lambda': 1.317209629606317e-07, 'alpha': 0.46028488450617827}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:41,722] Trial 126 finished with value: 0.5685311940996711 and parameters: {'eta': 0.004553555006128429, 'gamma': 1.3611035675387353e-08, 'max_depth': 9, 'min_child_weight': 0.003998754186933962, 'subsample': 0.8989629351232269, 'colsample_bytree': 0.6487424980879308, 'lambda': 1.2355178799797033e-08, 'alpha': 0.08952975283776764}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:45,520] Trial 127 finished with value: 0.5677482699650026 and parameters: {'eta': 0.0033877546568554726, 'gamma': 3.4420048739572506e-08, 'max_depth': 8, 'min_child_weight': 0.004747401188079591, 'subsample': 0.9098459490364756, 'colsample_bytree': 0.6558625497463476, 'lambda': 2.106663800965975e-07, 'alpha': 0.23955458818863914}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:47,164] Trial 128 finished with value: 0.5681220797718928 and parameters: {'eta': 0.005672045438391465, 'gamma': 5.0309176106654736e-08, 'max_depth': 9, 'min_child_weight': 0.008262444205765747, 'subsample': 0.8834843572540311, 'colsample_bytree': 0.7006285093489698, 'lambda': 1.2406740731901745e-06, 'alpha': 0.9326219019992942}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:49,284] Trial 129 finished with value: 0.5679364295495293 and parameters: {'eta': 0.00879446929072341, 'gamma': 2.0520945996382602e-08, 'max_depth': 9, 'min_child_weight': 0.005682686448623798, 'subsample': 0.8744063903742358, 'colsample_bytree': 0.6914774343852856, 'lambda': 2.4805936897688128e-08, 'alpha': 0.20020484251565893}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:51,107] Trial 130 finished with value: 0.5695284303191083 and parameters: {'eta': 0.008335795472454803, 'gamma': 8.058094882632368e-08, 'max_depth': 8, 'min_child_weight': 0.0029468952376304905, 'subsample': 0.8953846672961439, 'colsample_bytree': 0.6798013132073035, 'lambda': 1.4946141436319712e-07, 'alpha': 0.3454436929828957}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:52,656] Trial 131 finished with value: 0.5674628850454463 and parameters: {'eta': 0.006683858514720425, 'gamma': 1.2103281031863034e-07, 'max_depth': 8, 'min_child_weight': 0.00337577454331633, 'subsample': 0.622554069532214, 'colsample_bytree': 0.6829578212128511, 'lambda': 9.455362047912876e-08, 'alpha': 0.3047534340536312}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:54,187] Trial 132 finished with value: 0.5687534142907129 and parameters: {'eta': 0.006623864473618382, 'gamma': 7.240894174594104e-08, 'max_depth': 8, 'min_child_weight': 0.003047202930345544, 'subsample': 0.8917929415584639, 'colsample_bytree': 0.6686251618829703, 'lambda': 5.3000016114605037e-08, 'alpha': 0.10723110134264169}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:55,507] Trial 133 finished with value: 0.566394897196761 and parameters: {'eta': 0.007996161253484261, 'gamma': 3.739989275515582e-08, 'max_depth': 8, 'min_child_weight': 0.006268173988504016, 'subsample': 0.9028942390183954, 'colsample_bytree': 0.6626111582260685, 'lambda': 4.823149167128867e-07, 'alpha': 0.1270194600786592}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:31:58,228] Trial 134 finished with value: 0.5618108432905953 and parameters: {'eta': 0.007919893669055655, 'gamma': 9.145632703889863e-08, 'max_depth': 4, 'min_child_weight': 0.0049355076498517276, 'subsample': 0.885827063451617, 'colsample_bytree': 0.6929540334851759, 'lambda': 1.6743589100623738e-07, 'alpha': 0.47812807978857796}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:01,447] Trial 135 finished with value: 0.5673553943136654 and parameters: {'eta': 0.010051290782633714, 'gamma': 1.438171481184952e-07, 'max_depth': 8, 'min_child_weight': 0.003997097281800955, 'subsample': 0.9119641691826662, 'colsample_bytree': 0.7075052333359425, 'lambda': 3.7221390880938205e-08, 'alpha': 0.7713880710598723}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:05,091] Trial 136 finished with value: 0.5687127048294351 and parameters: {'eta': 0.0027122933364656415, 'gamma': 6.276860575289837e-08, 'max_depth': 9, 'min_child_weight': 0.0027314543566385237, 'subsample': 0.8733173708042281, 'colsample_bytree': 0.6783274984778115, 'lambda': 3.2445819833938827e-07, 'alpha': 0.0723556187644686}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:06,762] Trial 137 finished with value: 0.5658464486428686 and parameters: {'eta': 0.00029914368069467465, 'gamma': 2.0107373673605587e-08, 'max_depth': 8, 'min_child_weight': 0.007637733633244384, 'subsample': 0.8944232101032658, 'colsample_bytree': 0.6869522970601076, 'lambda': 4.810530895636846e-07, 'alpha': 0.03872030209748361}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:08,291] Trial 138 finished with value: 0.5661718090275366 and parameters: {'eta': 0.01314424952204139, 'gamma': 4.6479526823991386e-08, 'max_depth': 9, 'min_child_weight': 0.004728191624218956, 'subsample': 0.9212289816503197, 'colsample_bytree': 0.699710674806647, 'lambda': 1.2200134568579378e-07, 'alpha': 0.18183225979574147}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:09,905] Trial 139 finished with value: 0.5659278952018838 and parameters: {'eta': 0.004393118676671159, 'gamma': 1.1634006733164039e-08, 'max_depth': 8, 'min_child_weight': 0.0069393614853018966, 'subsample': 0.8628595075018075, 'colsample_bytree': 0.9035188936797854, 'lambda': 4.13840020750383e-06, 'alpha': 0.01116369425611641}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:11,658] Trial 140 finished with value: 0.5662205748580026 and parameters: {'eta': 0.018540973129977798, 'gamma': 2.717143534802472e-08, 'max_depth': 9, 'min_child_weight': 0.005720118554152244, 'subsample': 0.9002531172209608, 'colsample_bytree': 0.6415396579139365, 'lambda': 0.9564952523839788, 'alpha': 1.0932041333890134e-07}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:13,183] Trial 141 finished with value: 0.5668061133872215 and parameters: {'eta': 0.011150336210310008, 'gamma': 5.427166100122601e-08, 'max_depth': 9, 'min_child_weight': 0.006649841095545419, 'subsample': 0.8819715003269942, 'colsample_bytree': 0.7142233332092658, 'lambda': 7.350976294225916e-08, 'alpha': 0.057804664290012624}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:15,313] Trial 142 finished with value: 0.5683820303726503 and parameters: {'eta': 0.010090879242776449, 'gamma': 8.590977926438754e-08, 'max_depth': 9, 'min_child_weight': 0.00922463046943502, 'subsample': 0.8656074616237144, 'colsample_bytree': 0.7175878720187671, 'lambda': 1.695293944981612e-06, 'alpha': 0.047621252030764026}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:16,709] Trial 143 finished with value: 0.5673016841240135 and parameters: {'eta': 0.006927313354617752, 'gamma': 1.1811719381702544e-07, 'max_depth': 9, 'min_child_weight': 0.0043897614930370876, 'subsample': 0.7493157173444448, 'colsample_bytree': 0.7058081011808013, 'lambda': 1.0442541131842409e-06, 'alpha': 0.026955457769425362}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:18,244] Trial 144 finished with value: 0.5675398140201742 and parameters: {'eta': 0.008470667454866796, 'gamma': 6.001679035623814e-08, 'max_depth': 10, 'min_child_weight': 0.2578919404374764, 'subsample': 0.8908465563538771, 'colsample_bytree': 0.6753837873961207, 'lambda': 6.470559380120757e-07, 'alpha': 0.2847304723499617}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:19,620] Trial 145 finished with value: 0.5685904885475888 and parameters: {'eta': 0.016380752532000848, 'gamma': 3.556215539323944e-08, 'max_depth': 9, 'min_child_weight': 0.007918838029778585, 'subsample': 0.8730339236778176, 'colsample_bytree': 0.6584988727340052, 'lambda': 0.0004129381670879385, 'alpha': 0.07683152498887222}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:20,865] Trial 146 finished with value: 0.5665355640541674 and parameters: {'eta': 0.06758441463942795, 'gamma': 1.6864958789843628e-07, 'max_depth': 8, 'min_child_weight': 0.0021443146232615934, 'subsample': 0.9069763691282969, 'colsample_bytree': 0.7286629800483653, 'lambda': 2.739435745212204e-07, 'alpha': 0.12851402425839925}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:22,240] Trial 147 finished with value: 0.566647504535005 and parameters: {'eta': 0.02134944955318709, 'gamma': 1.913537726718154e-08, 'max_depth': 9, 'min_child_weight': 0.005483556914689787, 'subsample': 0.8581464829600636, 'colsample_bytree': 0.695996791556374, 'lambda': 8.28436963155353e-05, 'alpha': 0.0180896148296362}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:23,267] Trial 148 finished with value: 0.5706203187117601 and parameters: {'eta': 0.013110837993039389, 'gamma': 3.9556187973419346e-08, 'max_depth': 9, 'min_child_weight': 0.0037495335874558294, 'subsample': 0.8839490299775927, 'colsample_bytree': 0.7092814338221953, 'lambda': 2.1413036251535705e-05, 'alpha': 0.039666028787565866}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:24,059] Trial 149 finished with value: 0.5695133327678857 and parameters: {'eta': 0.012670213703871405, 'gamma': 3.788394472510584e-08, 'max_depth': 8, 'min_child_weight': 0.003786693963621073, 'subsample': 0.883255218175559, 'colsample_bytree': 0.6698023331624362, 'lambda': 2.141993672753136e-06, 'alpha': 0.039680612908398645}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:24,846] Trial 150 finished with value: 0.5668366994263936 and parameters: {'eta': 0.015606258585219857, 'gamma': 2.6106146112819368e-08, 'max_depth': 8, 'min_child_weight': 0.001700115288017111, 'subsample': 0.8992371852762056, 'colsample_bytree': 0.6699946078092727, 'lambda': 2.0323320375668433e-05, 'alpha': 0.03502420361530731}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:25,629] Trial 151 finished with value: 0.5700638422538881 and parameters: {'eta': 0.013275420820287624, 'gamma': 3.7215481231498966e-08, 'max_depth': 8, 'min_child_weight': 0.0035702601950059966, 'subsample': 0.8830278485250499, 'colsample_bytree': 0.685012734812826, 'lambda': 2.222252380542077e-06, 'alpha': 0.025918662665270636}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:26,432] Trial 152 finished with value: 0.568204874124815 and parameters: {'eta': 0.014244051968811232, 'gamma': 3.8861271290625504e-08, 'max_depth': 8, 'min_child_weight': 0.0029109115329683907, 'subsample': 0.8792383550509318, 'colsample_bytree': 0.6787591346980096, 'lambda': 2.489350169313707e-06, 'alpha': 0.02273026750718546}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:27,233] Trial 153 finished with value: 0.5672607030465997 and parameters: {'eta': 0.012921275851784389, 'gamma': 1.3487168397194358e-08, 'max_depth': 8, 'min_child_weight': 0.003984241691219106, 'subsample': 0.9146459260265549, 'colsample_bytree': 0.6849783023812107, 'lambda': 6.083456712755122e-06, 'alpha': 0.013339313627266643}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:27,955] Trial 154 finished with value: 0.5683622724299892 and parameters: {'eta': 0.023740437650285405, 'gamma': 4.086109166304377e-08, 'max_depth': 7, 'min_child_weight': 0.003391140377715258, 'subsample': 0.8950955729148021, 'colsample_bytree': 0.6640444450857514, 'lambda': 1.6177985770289558e-06, 'alpha': 0.008450820570668685}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:28,729] Trial 155 finished with value: 0.5690912171803494 and parameters: {'eta': 0.010226994360656706, 'gamma': 1.963814276713045e-08, 'max_depth': 8, 'min_child_weight': 0.003714915804158965, 'subsample': 0.8725154144288684, 'colsample_bytree': 0.6853835248371073, 'lambda': 3.404095734137205e-06, 'alpha': 0.03407923349992472}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:29,520] Trial 156 finished with value: 0.5694340565703874 and parameters: {'eta': 0.0197628536696969, 'gamma': 9.424090015429987e-08, 'max_depth': 8, 'min_child_weight': 0.0029410192327179938, 'subsample': 0.8904169627189704, 'colsample_bytree': 0.6756389801250636, 'lambda': 0.0007391114388671462, 'alpha': 0.05149540118475488}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:30,323] Trial 157 finished with value: 0.5691036803334951 and parameters: {'eta': 0.012257052116893645, 'gamma': 3.0391683121314646e-08, 'max_depth': 8, 'min_child_weight': 0.002502671491769464, 'subsample': 0.8509118144689803, 'colsample_bytree': 0.7079893885665125, 'lambda': 8.391572963228481e-07, 'alpha': 0.4089869260743907}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:31,122] Trial 158 finished with value: 0.5695607020743243 and parameters: {'eta': 0.015515617142637798, 'gamma': 5.0499155239989045e-08, 'max_depth': 8, 'min_child_weight': 0.8887612927136525, 'subsample': 0.8833206551662969, 'colsample_bytree': 0.6528985866320484, 'lambda': 2.1838208798599872e-06, 'alpha': 5.028153140300164e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:31,905] Trial 159 finished with value: 0.5675158696607076 and parameters: {'eta': 0.025380203839949083, 'gamma': 1.201807194287844e-07, 'max_depth': 8, 'min_child_weight': 0.004505345522784335, 'subsample': 0.927970459945625, 'colsample_bytree': 0.6272747988920783, 'lambda': 1.1144487193322898e-06, 'alpha': 2.1859482027512645e-07}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:32,752] Trial 160 finished with value: 0.5674290458501601 and parameters: {'eta': 0.08696835175277018, 'gamma': 5.4880496121322215e-08, 'max_depth': 8, 'min_child_weight': 0.08482599604789318, 'subsample': 0.9029981201912951, 'colsample_bytree': 0.656980903850211, 'lambda': 0.0012699228788479256, 'alpha': 7.398907952349362e-07}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:33,967] Trial 161 finished with value: 0.5713760117772725 and parameters: {'eta': 0.015477851323135786, 'gamma': 8.040786742227305e-08, 'max_depth': 8, 'min_child_weight': 0.003633701109958125, 'subsample': 0.8842208416179389, 'colsample_bytree': 0.6682090055202088, 'lambda': 2.1662175525122815e-06, 'alpha': 2.0894536628444846e-05}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:35,187] Trial 162 finished with value: 0.567728803442466 and parameters: {'eta': 0.016619554363966543, 'gamma': 7.630091045338998e-08, 'max_depth': 8, 'min_child_weight': 0.02608645000668691, 'subsample': 0.8798300515089525, 'colsample_bytree': 0.6537871219655736, 'lambda': 7.954381974484703e-06, 'alpha': 3.2975068827479654e-05}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:36,324] Trial 163 finished with value: 0.569674417815784 and parameters: {'eta': 0.015219717205693014, 'gamma': 1.859919162199281e-07, 'max_depth': 7, 'min_child_weight': 0.1190157545819414, 'subsample': 0.8900660293478037, 'colsample_bytree': 0.6485566974296124, 'lambda': 4.840387359317217e-06, 'alpha': 5.319536697646671e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:37,359] Trial 164 finished with value: 0.5640839373444407 and parameters: {'eta': 0.014613494788994999, 'gamma': 2.8519532149149416e-07, 'max_depth': 6, 'min_child_weight': 0.6627578300401609, 'subsample': 0.8721639178342506, 'colsample_bytree': 0.6448712196701211, 'lambda': 4.5232057417727496e-06, 'alpha': 2.837550848043564e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:38,446] Trial 165 finished with value: 0.5683546620735308 and parameters: {'eta': 0.0196558013030768, 'gamma': 1.7138584956296365e-07, 'max_depth': 7, 'min_child_weight': 0.9693495977928045, 'subsample': 0.8884608432627153, 'colsample_bytree': 0.6330804313815658, 'lambda': 2.761360423612717e-06, 'alpha': 9.479214506481607e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:39,545] Trial 166 finished with value: 0.5673898243283135 and parameters: {'eta': 0.01768911127578241, 'gamma': 2.411727608564807e-08, 'max_depth': 7, 'min_child_weight': 0.15575214394558176, 'subsample': 0.8662130534809356, 'colsample_bytree': 0.6642954716820457, 'lambda': 6.29874268810193e-06, 'alpha': 4.963576512985156e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:40,400] Trial 167 finished with value: 0.5665329579749001 and parameters: {'eta': 0.016044733767170583, 'gamma': 4.8498423187509207e-08, 'max_depth': 6, 'min_child_weight': 0.06848435287136141, 'subsample': 0.9069964396520911, 'colsample_bytree': 0.7374649707922347, 'lambda': 1.2124428455201622e-06, 'alpha': 3.5325170248633154e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:41,178] Trial 168 finished with value: 0.5694301633960226 and parameters: {'eta': 0.011149190678591447, 'gamma': 0.00016142188833867793, 'max_depth': 8, 'min_child_weight': 0.2986653450635482, 'subsample': 0.8804092143155072, 'colsample_bytree': 0.6502442539569468, 'lambda': 1.3042744893092488e-05, 'alpha': 4.543653607221246e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:41,908] Trial 169 finished with value: 0.5693671459047948 and parameters: {'eta': 0.009777169485412556, 'gamma': 2.103343348287464e-07, 'max_depth': 7, 'min_child_weight': 0.12187492322369421, 'subsample': 0.8584759249108767, 'colsample_bytree': 0.7027202357450756, 'lambda': 1.7910037224859365e-06, 'alpha': 2.861629773431169e-05}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:42,802] Trial 170 finished with value: 0.5677783034163318 and parameters: {'eta': 0.05222685822323113, 'gamma': 1.0079533582868701e-08, 'max_depth': 9, 'min_child_weight': 0.03547851535752892, 'subsample': 0.887116850623179, 'colsample_bytree': 0.6908260925071454, 'lambda': 1.0144291936705194e-05, 'alpha': 1.4126398033080127e-05}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:43,598] Trial 171 finished with value: 0.5683610713398424 and parameters: {'eta': 0.0128315472129728, 'gamma': 9.084046794074801e-08, 'max_depth': 8, 'min_child_weight': 0.05324438959167398, 'subsample': 0.895910593915553, 'colsample_bytree': 0.7220506114335444, 'lambda': 3.596508564159849e-06, 'alpha': 6.329431548217021e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:44,363] Trial 172 finished with value: 0.5681925227605423 and parameters: {'eta': 0.014590026195353198, 'gamma': 1.2617678569002736e-07, 'max_depth': 8, 'min_child_weight': 0.5438934469145434, 'subsample': 0.8974600119260201, 'colsample_bytree': 0.67567420250497, 'lambda': 1.7574685915275368e-05, 'alpha': 8.546085838057618e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:45,169] Trial 173 finished with value: 0.5680679008725137 and parameters: {'eta': 0.00902492968622676, 'gamma': 7.350682755050719e-08, 'max_depth': 8, 'min_child_weight': 0.003237407830214373, 'subsample': 0.8756992052714694, 'colsample_bytree': 0.6874708524274172, 'lambda': 0.00023857895813219978, 'alpha': 9.398669961808137e-07}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:45,943] Trial 174 finished with value: 0.5698463414984656 and parameters: {'eta': 0.02189736364944943, 'gamma': 5.066722838214979e-08, 'max_depth': 8, 'min_child_weight': 0.0063490791375033695, 'subsample': 0.8862184574718359, 'colsample_bytree': 0.6383106294069314, 'lambda': 2.326648047727697e-06, 'alpha': 0.09820677916652949}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:46,728] Trial 175 finished with value: 0.5699832861443578 and parameters: {'eta': 0.021853547942151007, 'gamma': 3.24287611060595e-08, 'max_depth': 8, 'min_child_weight': 0.005428897193930659, 'subsample': 0.8858130628367187, 'colsample_bytree': 0.6376030943918702, 'lambda': 4.88355727760841e-06, 'alpha': 1.617111442847056e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:47,597] Trial 176 finished with value: 0.5664373378352482 and parameters: {'eta': 0.022188427246392597, 'gamma': 1.532232795530342e-08, 'max_depth': 9, 'min_child_weight': 0.005313509585558902, 'subsample': 0.8907137113198295, 'colsample_bytree': 0.637058770866815, 'lambda': 6.2222867095230866e-06, 'alpha': 0.00011127272864037076}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:48,376] Trial 177 finished with value: 0.5688463766355369 and parameters: {'eta': 0.03928843702724237, 'gamma': 2.8392854219447014e-08, 'max_depth': 8, 'min_child_weight': 0.006181962995637388, 'subsample': 0.8688598647398847, 'colsample_bytree': 0.6208753556885326, 'lambda': 4.126130376504245e-06, 'alpha': 1.6924658922379729e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:49,264] Trial 178 finished with value: 0.5645621154256086 and parameters: {'eta': 0.020618317152827838, 'gamma': 3.706838759950894e-08, 'max_depth': 9, 'min_child_weight': 0.006945314214982988, 'subsample': 0.9058375159633679, 'colsample_bytree': 0.6252420490829594, 'lambda': 1.4335505008532393e-06, 'alpha': 1.742767492961039e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:50,057] Trial 179 finished with value: 0.5686689514287254 and parameters: {'eta': 0.030188056128670544, 'gamma': 4.6635300401311486e-07, 'max_depth': 8, 'min_child_weight': 0.00443406697770915, 'subsample': 0.9162149450337825, 'colsample_bytree': 0.6146584781020314, 'lambda': 2.7825540664415262e-05, 'alpha': 0.09708149586437735}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:51,366] Trial 180 finished with value: 0.56179621418017 and parameters: {'eta': 0.018310346388408116, 'gamma': 1.8621724125201747e-08, 'max_depth': 9, 'min_child_weight': 0.0060746461122497455, 'subsample': 0.6901910793012574, 'colsample_bytree': 0.6443809232433176, 'lambda': 8.809773225593024e-06, 'alpha': 0.16525728955323335}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:52,544] Trial 181 finished with value: 0.5701965790225123 and parameters: {'eta': 0.02447737116267174, 'gamma': 5.115522379910466e-08, 'max_depth': 8, 'min_child_weight': 0.0053491527581221296, 'subsample': 0.8846337265799729, 'colsample_bytree': 0.6354680091577305, 'lambda': 2.4815380944314983e-06, 'alpha': 0.02473629559799742}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:53,762] Trial 182 finished with value: 0.5702831721793684 and parameters: {'eta': 0.0263021248445498, 'gamma': 5.841425831189268e-08, 'max_depth': 8, 'min_child_weight': 0.005289101560863772, 'subsample': 0.8868653301405555, 'colsample_bytree': 0.6337686164942714, 'lambda': 2.365791453151793e-06, 'alpha': 0.02703142766312091}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:54,983] Trial 183 finished with value: 0.5659531495005734 and parameters: {'eta': 0.027049554172897346, 'gamma': 2.8670597755004124e-08, 'max_depth': 8, 'min_child_weight': 0.0051546265010619695, 'subsample': 0.8767755784270385, 'colsample_bytree': 0.6284310766473689, 'lambda': 3.493837837418036e-06, 'alpha': 0.025645549926983698}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:56,248] Trial 184 finished with value: 0.5689390175029729 and parameters: {'eta': 0.025460928828048613, 'gamma': 5.331867696810294e-08, 'max_depth': 8, 'min_child_weight': 0.004238040813517192, 'subsample': 0.8856906227882991, 'colsample_bytree': 0.6429941859485475, 'lambda': 2.403169412937229e-06, 'alpha': 1.987461257936616e-05}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:57,471] Trial 185 finished with value: 0.5684162634062674 and parameters: {'eta': 0.022065786976359938, 'gamma': 4.392684871338548e-08, 'max_depth': 8, 'min_child_weight': 0.007891012180669328, 'subsample': 0.8666216816402988, 'colsample_bytree': 0.6116838180847309, 'lambda': 1.5157700903785567e-06, 'alpha': 0.015751454532723502}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:58,440] Trial 186 finished with value: 0.5679229723370025 and parameters: {'eta': 0.06567011174117915, 'gamma': 7.084054737436609e-08, 'max_depth': 8, 'min_child_weight': 0.005659185782081876, 'subsample': 0.8812999236005951, 'colsample_bytree': 0.6314671184614423, 'lambda': 5.760183668513318e-06, 'alpha': 0.02879844709473052}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:32:59,222] Trial 187 finished with value: 0.5673795038642457 and parameters: {'eta': 0.03231112382520561, 'gamma': 2.231231500960729e-08, 'max_depth': 8, 'min_child_weight': 0.005081278807279696, 'subsample': 0.8997373557967919, 'colsample_bytree': 0.6595511159859858, 'lambda': 2.896888244636853e-06, 'alpha': 0.06819169877087827}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:00,011] Trial 188 finished with value: 0.5657792542915828 and parameters: {'eta': 0.08573618212501184, 'gamma': 3.708866826872146e-08, 'max_depth': 8, 'min_child_weight': 0.003739200641440742, 'subsample': 0.8883525178367526, 'colsample_bytree': 0.6352248454023893, 'lambda': 1.0360349196023523e-06, 'alpha': 0.018005860482849606}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:00,786] Trial 189 finished with value: 0.568547030710613 and parameters: {'eta': 0.0012290287456266076, 'gamma': 1.0874823410363705e-07, 'max_depth': 8, 'min_child_weight': 0.006915888627261017, 'subsample': 0.8739213692286136, 'colsample_bytree': 0.6007914649056618, 'lambda': 2.084992526292808e-06, 'alpha': 6.092072237718693e-07}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:01,598] Trial 190 finished with value: 0.5694691121609223 and parameters: {'eta': 0.09839266155993498, 'gamma': 6.326443610516734e-08, 'max_depth': 8, 'min_child_weight': 0.01015967838684807, 'subsample': 0.8612528690118801, 'colsample_bytree': 0.6401305575562263, 'lambda': 7.92847267440119e-07, 'alpha': 0.04293171802088801}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:02,496] Trial 191 finished with value: 0.5688967654332842 and parameters: {'eta': 0.02324653832767675, 'gamma': 1.3065422406555965e-07, 'max_depth': 9, 'min_child_weight': 0.006066476940992518, 'subsample': 0.8931863356097866, 'colsample_bytree': 0.6976304418495906, 'lambda': 4.400789058830722e-06, 'alpha': 0.06099866124123671}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:03,285] Trial 192 finished with value: 0.5677573998511543 and parameters: {'eta': 0.019419897009377105, 'gamma': 0.9128456878519075, 'max_depth': 8, 'min_child_weight': 0.004741435800154623, 'subsample': 0.8893116258376994, 'colsample_bytree': 0.7126827895790816, 'lambda': 0.00033438805283956906, 'alpha': 0.1003905069318897}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:04,104] Trial 193 finished with value: 0.5640724245147444 and parameters: {'eta': 0.017603666686120557, 'gamma': 3.021718026217893e-08, 'max_depth': 8, 'min_child_weight': 0.008787107657625368, 'subsample': 0.9023765506576568, 'colsample_bytree': 0.8067087691459695, 'lambda': 1.4356612077360575e-06, 'alpha': 2.2775362443899587e-06}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:05,039] Trial 194 finished with value: 0.5700506641511404 and parameters: {'eta': 0.013480812507840655, 'gamma': 5.2795946424835894e-08, 'max_depth': 9, 'min_child_weight': 0.0042144499194468376, 'subsample': 0.8777358039609906, 'colsample_bytree': 0.8167936509957434, 'lambda': 2.532235022768203e-06, 'alpha': 0.042854802029499414}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:05,975] Trial 195 finished with value: 0.5660058594411452 and parameters: {'eta': 0.013738160320879537, 'gamma': 4.4936973107145726e-08, 'max_depth': 9, 'min_child_weight': 0.004329495400249305, 'subsample': 0.8788032769590662, 'colsample_bytree': 0.8347626118189011, 'lambda': 2.7416103295348605e-06, 'alpha': 0.02527985333366983}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:06,698] Trial 196 finished with value: 0.5697424145236238 and parameters: {'eta': 0.010774763975981021, 'gamma': 8.625480775568914e-08, 'max_depth': 7, 'min_child_weight': 0.005081243544158406, 'subsample': 0.8863409309824295, 'colsample_bytree': 0.6673981244392468, 'lambda': 5.200115807225356e-06, 'alpha': 0.03850099224722619}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:07,500] Trial 197 finished with value: 0.5681964725163388 and parameters: {'eta': 0.011183602072541687, 'gamma': 6.131664088213938e-08, 'max_depth': 8, 'min_child_weight': 0.0034506603596369595, 'subsample': 0.8714604694420068, 'colsample_bytree': 0.7963469300573701, 'lambda': 1.958343945264214e-06, 'alpha': 0.032386335802140405}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:08,459] Trial 198 finished with value: 0.5717225979034453 and parameters: {'eta': 0.009726244241522282, 'gamma': 2.80296347722708e-08, 'max_depth': 8, 'min_child_weight': 0.0053321392913644305, 'subsample': 0.8843882427771669, 'colsample_bytree': 0.6694950249719117, 'lambda': 1.4368352515837742e-05, 'alpha': 0.011543147588916633}. Best is trial 123 with value: 0.5725035630519906.\n",
            "<ipython-input-67-c3fdf1207668>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'eta': trial.suggest_loguniform('eta', 1e-4, 1e-1),\n",
            "<ipython-input-67-c3fdf1207668>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
            "<ipython-input-67-c3fdf1207668>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
            "[I 2024-07-06 04:33:09,689] Trial 199 finished with value: 0.5676466440330462 and parameters: {'eta': 0.007241594350051946, 'gamma': 1.6298456355074763e-08, 'max_depth': 8, 'min_child_weight': 0.0050917788014146, 'subsample': 0.881925255571114, 'colsample_bytree': 0.6709088936533436, 'lambda': 2.22714657297387e-05, 'alpha': 0.006715921259063291}. Best is trial 123 with value: 0.5725035630519906.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = xgb.XGBClassifier(**best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi probabilitas untuk data validasi\n",
        "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Evaluasi model menggunakan Average Precision Score\n",
        "average_precision = average_precision_score(y_val, y_pred_proba)\n",
        "print(f'Average Precision Score: {average_precision:.4f}')\n",
        "\n",
        "# Optional: Evaluasi model menggunakan classification report\n",
        "y_pred = best_model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nkDj2n2TRZH",
        "outputId": "e5b12001-ae03-46c8-952a-d154ff4390a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [04:33:10] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"bagging_fraction\", \"bagging_freq\", \"feature_fraction\", \"min_child_samples\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision Score: 0.5731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.53      0.55      8505\n",
            "         1.0       0.56      0.60      0.58      8463\n",
            "\n",
            "    accuracy                           0.57     16968\n",
            "   macro avg       0.57      0.57      0.57     16968\n",
            "weighted avg       0.57      0.57      0.57     16968\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi probabilitas untuk data uji\n",
        "y_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Simpan hasil prediksi ke CSV\n",
        "submission = pd.DataFrame({\n",
        "    'user_id': data_test['user_id'],\n",
        "    'label': y_pred_proba_test\n",
        "})\n",
        "submission.to_csv('submission2.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "G-BUCIltTg1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22b1e1b-cacd-4db0-90e1-412e80ba0068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9760068721758166, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9760068721758166\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8449801539872025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8449801539872025\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subs = pd.read_csv('/content/submission2.csv')\n",
        "print(subs[subs['label'] >= 0.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_blQcgzThmE",
        "outputId": "cc848244-757e-41d7-99f9-cee664d9d932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user_id     label\n",
            "0             4  0.562787\n",
            "5           107  0.549450\n",
            "9           118  0.527304\n",
            "14          205  0.505689\n",
            "15          208  0.561372\n",
            "...         ...       ...\n",
            "367692  3700418  0.617372\n",
            "367693  3700453  0.517187\n",
            "367697  3700510  0.579014\n",
            "367698  3700517  0.558164\n",
            "367699  3700526  0.601297\n",
            "\n",
            "[125309 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qy2p1ZxUUbhW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}